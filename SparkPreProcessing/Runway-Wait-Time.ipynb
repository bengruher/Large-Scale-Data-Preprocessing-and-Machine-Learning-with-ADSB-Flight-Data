{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9fd355f9-4112-4d1c-a6b2-084fbcbdcaf9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d2ab4585-440f-45ab-b526-c1fe54fb4964",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CSV paths\n",
    "most_recent_csv_path = 's3://<BUCKET_NAME>/flights-csv/full-data/full-data-280k.csv' # all Ben's 26 operators, 6 airlines, has holiday, not dummiefied yet\n",
    "# most_recent_csv_path = 's3://<BUCKET_NAME>/flights-csv/full-data/full-data.csv' # has only 79k rows, with 5 operators, 6 airlines, has a column for holiday => all these still need to be dummified\n",
    "# most_recent_csv_path = 's3://<BUCKET_NAME>/flights-csv//2021-03-11-14-08/full-data.csv' # has about 500k rows, based on Ben's last parquet\n",
    "\n",
    "def file_exists(path):\n",
    "  try:\n",
    "    dbutils.fs.ls(path)\n",
    "    return True\n",
    "  except Exception as e:\n",
    "    if 'java.io.FileNotFoundException' in str(e):\n",
    "      return False\n",
    "    else:\n",
    "      raise\n",
    "      \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pandas(dfSpark):\n",
    "  # Enable Arrow-based columnar data transfers\n",
    "  spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "  # Convert the Spark DataFrame to a Pandas DataFrame using Arrow\n",
    "  return dfSpark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bc686d8b-1b1a-4aa1-ba41-25cf01d96478",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "most_recent_parquet_path = 's3://<BUCKET_NAME>/flights-parquet//2021-03-11-11-10' # Ben - added flight duration\n",
    "# most_recent_parquet_path = 's3://<BUCKET_NAME>/flights-parquet//2021-03-09-16-29' # added OtherDepartures column and filtered airports and weird flight times\n",
    "# most_recent_parquet_path = 's3://<BUCKET_NAME>/flights-parquet//2021-03-07-00-00' # added RWT to original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aaece20a-e83b-443a-b874-80f9abc638bc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Processing Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54367a1b-8638-4ae2-a29d-7da1c435c64d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">False\n",
       "True\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">False\nTrue\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def file_exists(path):\n",
    "  try:\n",
    "    dbutils.fs.ls(path)\n",
    "    return True\n",
    "  except Exception as e:\n",
    "    if 'java.io.FileNotFoundException' in str(e):\n",
    "      return False\n",
    "    else:\n",
    "      raise\n",
    "      \n",
    "print(file_exists(f's3://<BUCKET_NAME>/flights/{2020}-{11}-{31}')) # False\n",
    "print(file_exists(f's3://<BUCKET_NAME>/flights/{2020}-{12}-{31}')) # True\n",
    "\n",
    "# Write to parquet \n",
    "import pytz, datetime\n",
    "def toParquet(data_frame, bucket='s3://<BUCKET_NAME>/flights-parquet/'):\n",
    "  timestamp = datetime.datetime.utcnow().replace(tzinfo=pytz.utc).astimezone(pytz.timezone('US/Pacific')).strftime('%Y-%m-%d-%H-%M')\n",
    "  last_run_parquet_path = f'{bucket}/{timestamp}'\n",
    "  data_frame.write.parquet(last_run_parquet_path)\n",
    "  print(f'Last run parquet path = \\'{last_run_parquet_path}\\'')\n",
    "  assert file_exists(last_run_parquet_path), 'Check output name again'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "19b2810c-7a6e-4b49-a19e-d4e5e9327053",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Day count = 274\n",
       "Missing days = [(2020, 10, 26), (2020, 10, 27)]\n",
       "Missing days count = 2\n",
       "Out[3]: 1698787</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Day count = 274\nMissing days = [(2020, 10, 26), (2020, 10, 27)]\nMissing days count = 2\nOut[3]: 1698787</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Oct - 31 days, Nov - 30 days, Dec 31 days => 31x3 + 30x3 + 31x3 = 276 days\n",
    "df = spark.read.parquet('s3://<BUCKET_NAME>/flights/2020-12-01')\n",
    "\n",
    "days_exist = [(2020, 12, 1)]\n",
    "days_missing = []\n",
    "for year in [2020, 2019, 2018]:\n",
    "  for month in [12, 11, 10]:\n",
    "    for day in range(1,32,1):\n",
    "      if ((year, month, day) == (2020, 12, 1) or (month, day) == (11, 31)):\n",
    "        continue\n",
    "      path = f's3://<BUCKET_NAME>/flights/{year}-{month}-{day:02d}'\n",
    "      if file_exists(path):\n",
    "        days_exist.append((year, month, day))\n",
    "        df_temp = spark.read.parquet(path)\n",
    "        df = df.union(df_temp).dropDuplicates()\n",
    "      else:\n",
    "        days_missing.append((year, month, day))\n",
    "        \n",
    "print(f'Day count = {len(days_exist)}')\n",
    "print(f'Missing days = {days_missing}')\n",
    "print(f'Missing days count = {len(days_missing)}')\n",
    "\n",
    "# Verify: Last run - 274 days => 1,698,787 flights         \n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "93de766f-da5b-43c7-8f3c-1079ee23ebcc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[4]: 1554307</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[4]: 1554307</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "# Expand LatLong columns, rename columns, select columns\n",
    "df2 = df.withColumn('FromLat', df['DepartureLatLong'].getItem(0))\\\n",
    "       .withColumn('FromLong', df['DepartureLatLong'].getItem(1))\\\n",
    "       .withColumn('ToLat', df['ArrivalLatLong'].getItem(0))\\\n",
    "       .withColumn('ToLong', df['ArrivalLatLong'].getItem(1))\\\n",
    "       .withColumnRenamed('DepartureAirport', 'From')\\\n",
    "       .withColumnRenamed('ArrivalAirport', 'To')\\\n",
    "       .filter(F.col('Mil') == 0) \\\n",
    "       .filter(F.col('Species') == 1) \\\n",
    "       .select('Icao', 'Op', 'From', 'To', \\\n",
    "               'StartTime', 'LiftOffTime', \\\n",
    "               'TouchDownTime', 'StopTime', \\\n",
    "               'FromLat', 'FromLong', 'ToLat', 'ToLong') \n",
    "\n",
    "df2.count() # 1,554,307 flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a1312e2e-0617-4b0b-8159-83b6d96de5d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write to csv using pipe \"|\" as delimiter \n",
    "# Because the Operator field sometimes has one or two commas in it to separate city and state\n",
    "import pytz, datetime\n",
    "def toCsv(data_frame, bucket='s3://<BUCKET_NAME>/flights-csv/'): # Spark data_frame\n",
    "  timestamp = datetime.datetime.utcnow().replace(tzinfo=pytz.utc).astimezone(pytz.timezone('US/Pacific')).strftime('%Y-%m-%d-%H-%M')\n",
    "  last_run_csv_path = f'{bucket}/{timestamp}'\n",
    "  data_frame.repartition(1)\\\n",
    "          .write.format('com.databricks.spark.csv')\\\n",
    "          .option('header', 'true')\\\n",
    "          .option('delimiter', '|')\\\n",
    "          .save(last_run_csv_path)\n",
    "  print(f'Last run csv path = \\'{last_run_csv_path}\\'')\n",
    "  assert file_exists(last_run_csv_path), 'Check output name again'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e76137d4-e407-4fe6-a2bb-c3c3a06e4d22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1ae4d00e-f894-49b3-8b03-8d6ad4aad9b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write to csv using pipe \"|\" as delimiter \n",
    "# Because the Operator field sometimes has one or two commas in it to separate city and state\n",
    "from io import StringIO\n",
    "import boto3\n",
    "def toCsv2(df, folder, filename): # Pandas data frame\n",
    "  csv_path = f's3://<BUCKET_NAME>/flights-csv/{folder}'\n",
    "  \n",
    "  csv_buffer = StringIO()\n",
    "  df.to_csv(csv_buffer, sep='|', header=True)\n",
    "  s3_resource = boto3.resource('s3')\n",
    "  s3_resource.Object(csv_path, filename).put(Body=csv_buffer.getvalue())\n",
    "  \n",
    "  print(f'csv path = \\'{csv_path}\\'')\n",
    "  assert file_exists(csv_path), 'Check output name again'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1fa8e04f-a5f9-4227-b274-cf316fecf4d9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Last run parquet path = &#39;s3://runway-wait-time-data/flights-parquet//2021-03-06-23-14&#39;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Last run parquet path = &#39;s3://runway-wait-time-data/flights-parquet//2021-03-06-23-14&#39;\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "toParquet(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8ffc717c-d593-409f-a9f1-2a8bc9389754",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pandas(dfSpark):\n",
    "  # Enable Arrow-based columnar data transfers\n",
    "  spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "  # Convert the Spark DataFrame to a Pandas DataFrame using Arrow\n",
    "  return dfSpark.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "22a3ba08-3d92-4620-afee-caaaec6f6dac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# To convert Pandas DF to Spark DF\n",
    "from pyspark.sql import SQLContext\n",
    "def toSpark(pdDF):\n",
    "  return SQLContext(sc).createDataFrame(pdDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1f6d991d-4612-4fd2-9037-9c7a27d2835f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Feature Eningeering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "424275d5-3f6c-4064-b198-652992c5a506",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 1. Runway Wait Time (RWT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4c3e566c-45c2-47a4-8742-f16e9df301dc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[3]: 1549282</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[3]: 1549282</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfRwt = spark.read.parquet(most_recent_parquet_path)\n",
    "dfRwt.count() # Last run - 274 days => 1,554,307 flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "44eff717-5adc-445c-8a8f-f003dc960546",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[9]: Icao             False\n",
       "Op                True\n",
       "From             False\n",
       "To               False\n",
       "StartTime        False\n",
       "LiftOffTime      False\n",
       "TouchDownTime    False\n",
       "StopTime         False\n",
       "FromLat          False\n",
       "FromLong         False\n",
       "ToLat            False\n",
       "ToLong           False\n",
       "dtype: bool</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[9]: Icao             False\nOp                True\nFrom             False\nTo               False\nStartTime        False\nLiftOffTime      False\nTouchDownTime    False\nStopTime         False\nFromLat          False\nFromLong         False\nToLat            False\nToLong           False\ndtype: bool</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check which columns have null values => only Op column has null values\n",
    "dfpRwt = pandas(dfRwt)\n",
    "dfpRwt.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ce4cce69-a4e9-4f03-9af8-d02c8d91f395",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">27\n",
       "Out[10]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">27\nOut[10]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Icao</th>\n",
       "      <th>Op</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LiftOffTime</th>\n",
       "      <th>TouchDownTime</th>\n",
       "      <th>StopTime</th>\n",
       "      <th>FromLat</th>\n",
       "      <th>FromLong</th>\n",
       "      <th>ToLat</th>\n",
       "      <th>ToLong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160696</th>\n",
       "      <td>A81183</td>\n",
       "      <td>None</td>\n",
       "      <td>OAK</td>\n",
       "      <td>OAK</td>\n",
       "      <td>2020-12-23 00:55:15.223</td>\n",
       "      <td>2020-12-23 21:31:59.150</td>\n",
       "      <td>2020-12-23 23:24:14.179</td>\n",
       "      <td>2020-12-23 23:26:55.336</td>\n",
       "      <td>37.661556</td>\n",
       "      <td>-122.124082</td>\n",
       "      <td>37.659818</td>\n",
       "      <td>-122.121441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191349</th>\n",
       "      <td>AAB698</td>\n",
       "      <td>None</td>\n",
       "      <td>PHX</td>\n",
       "      <td>PHX</td>\n",
       "      <td>2020-11-21 20:16:45.009</td>\n",
       "      <td>2020-11-21 20:41:13.947</td>\n",
       "      <td>2020-11-21 20:42:00.054</td>\n",
       "      <td>2020-11-21 20:42:00.054</td>\n",
       "      <td>33.425577</td>\n",
       "      <td>-112.020988</td>\n",
       "      <td>33.455882</td>\n",
       "      <td>-112.037906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198872</th>\n",
       "      <td>A05B45</td>\n",
       "      <td>None</td>\n",
       "      <td>SJC</td>\n",
       "      <td>SCK</td>\n",
       "      <td>2020-11-20 18:19:32.271</td>\n",
       "      <td>2020-11-20 18:21:44.757</td>\n",
       "      <td>2020-11-20 21:03:19.428</td>\n",
       "      <td>2020-11-20 21:46:00.076</td>\n",
       "      <td>37.330298</td>\n",
       "      <td>-121.815779</td>\n",
       "      <td>37.830791</td>\n",
       "      <td>-121.626731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385860</th>\n",
       "      <td>A05B45</td>\n",
       "      <td>None</td>\n",
       "      <td>NUQ</td>\n",
       "      <td>SCK</td>\n",
       "      <td>2020-11-20 17:02:02.070</td>\n",
       "      <td>2020-11-20 17:05:14.974</td>\n",
       "      <td>2020-11-20 17:28:30.031</td>\n",
       "      <td>2020-11-20 18:18:50.752</td>\n",
       "      <td>37.457291</td>\n",
       "      <td>-122.112277</td>\n",
       "      <td>37.830528</td>\n",
       "      <td>-121.626571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439843</th>\n",
       "      <td>ABD69E</td>\n",
       "      <td>None</td>\n",
       "      <td>ORL</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2020-11-20 14:13:08.600</td>\n",
       "      <td>2020-11-20 14:26:59.439</td>\n",
       "      <td>2020-11-20 19:25:30.239</td>\n",
       "      <td>2020-11-20 14:12:00.527</td>\n",
       "      <td>28.547846</td>\n",
       "      <td>-81.337078</td>\n",
       "      <td>28.546938</td>\n",
       "      <td>-81.336149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Icao</th>\n      <th>Op</th>\n      <th>From</th>\n      <th>To</th>\n      <th>StartTime</th>\n      <th>LiftOffTime</th>\n      <th>TouchDownTime</th>\n      <th>StopTime</th>\n      <th>FromLat</th>\n      <th>FromLong</th>\n      <th>ToLat</th>\n      <th>ToLong</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>160696</th>\n      <td>A81183</td>\n      <td>None</td>\n      <td>OAK</td>\n      <td>OAK</td>\n      <td>2020-12-23 00:55:15.223</td>\n      <td>2020-12-23 21:31:59.150</td>\n      <td>2020-12-23 23:24:14.179</td>\n      <td>2020-12-23 23:26:55.336</td>\n      <td>37.661556</td>\n      <td>-122.124082</td>\n      <td>37.659818</td>\n      <td>-122.121441</td>\n    </tr>\n    <tr>\n      <th>191349</th>\n      <td>AAB698</td>\n      <td>None</td>\n      <td>PHX</td>\n      <td>PHX</td>\n      <td>2020-11-21 20:16:45.009</td>\n      <td>2020-11-21 20:41:13.947</td>\n      <td>2020-11-21 20:42:00.054</td>\n      <td>2020-11-21 20:42:00.054</td>\n      <td>33.425577</td>\n      <td>-112.020988</td>\n      <td>33.455882</td>\n      <td>-112.037906</td>\n    </tr>\n    <tr>\n      <th>198872</th>\n      <td>A05B45</td>\n      <td>None</td>\n      <td>SJC</td>\n      <td>SCK</td>\n      <td>2020-11-20 18:19:32.271</td>\n      <td>2020-11-20 18:21:44.757</td>\n      <td>2020-11-20 21:03:19.428</td>\n      <td>2020-11-20 21:46:00.076</td>\n      <td>37.330298</td>\n      <td>-121.815779</td>\n      <td>37.830791</td>\n      <td>-121.626731</td>\n    </tr>\n    <tr>\n      <th>385860</th>\n      <td>A05B45</td>\n      <td>None</td>\n      <td>NUQ</td>\n      <td>SCK</td>\n      <td>2020-11-20 17:02:02.070</td>\n      <td>2020-11-20 17:05:14.974</td>\n      <td>2020-11-20 17:28:30.031</td>\n      <td>2020-11-20 18:18:50.752</td>\n      <td>37.457291</td>\n      <td>-122.112277</td>\n      <td>37.830528</td>\n      <td>-121.626571</td>\n    </tr>\n    <tr>\n      <th>439843</th>\n      <td>ABD69E</td>\n      <td>None</td>\n      <td>ORL</td>\n      <td>ORL</td>\n      <td>2020-11-20 14:13:08.600</td>\n      <td>2020-11-20 14:26:59.439</td>\n      <td>2020-11-20 19:25:30.239</td>\n      <td>2020-11-20 14:12:00.527</td>\n      <td>28.547846</td>\n      <td>-81.337078</td>\n      <td>28.546938</td>\n      <td>-81.336149</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What flights have no Operator name\n",
    "print(len(dfpRwt[dfpRwt.Op.isnull()]))\n",
    "dfpRwt[dfpRwt.Op.isnull()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e64fb489-3ecf-42ad-8c9d-10615564ae18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "RangeIndex: 1554307 entries, 0 to 1554306\n",
       "Data columns (total 12 columns):\n",
       " #   Column         Non-Null Count    Dtype         \n",
       "---  ------         --------------    -----         \n",
       " 0   Icao           1554307 non-null  object        \n",
       " 1   Op             1554280 non-null  object        \n",
       " 2   From           1554307 non-null  object        \n",
       " 3   To             1554307 non-null  object        \n",
       " 4   StartTime      1554307 non-null  datetime64[ns]\n",
       " 5   LiftOffTime    1554307 non-null  datetime64[ns]\n",
       " 6   TouchDownTime  1554307 non-null  datetime64[ns]\n",
       " 7   StopTime       1554307 non-null  datetime64[ns]\n",
       " 8   FromLat        1554307 non-null  float64       \n",
       " 9   FromLong       1554307 non-null  float64       \n",
       " 10  ToLat          1554307 non-null  float64       \n",
       " 11  ToLong         1554307 non-null  float64       \n",
       "dtypes: datetime64[ns](4), float64(4), object(4)\n",
       "memory usage: 142.3+ MB\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 1554307 entries, 0 to 1554306\nData columns (total 12 columns):\n #   Column         Non-Null Count    Dtype         \n---  ------         --------------    -----         \n 0   Icao           1554307 non-null  object        \n 1   Op             1554280 non-null  object        \n 2   From           1554307 non-null  object        \n 3   To             1554307 non-null  object        \n 4   StartTime      1554307 non-null  datetime64[ns]\n 5   LiftOffTime    1554307 non-null  datetime64[ns]\n 6   TouchDownTime  1554307 non-null  datetime64[ns]\n 7   StopTime       1554307 non-null  datetime64[ns]\n 8   FromLat        1554307 non-null  float64       \n 9   FromLong       1554307 non-null  float64       \n 10  ToLat          1554307 non-null  float64       \n 11  ToLong         1554307 non-null  float64       \ndtypes: datetime64[ns](4), float64(4), object(4)\nmemory usage: 142.3+ MB\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpRwt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8e3a2cb3-109d-42df-8098-6c080a04f87c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">No. flights with negative RWT = 5025\n",
       "% of flights with negative RWT = 0.32%\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">No. flights with negative RWT = 5025\n% of flights with negative RWT = 0.32%\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Could add this to the preprocessing phase\n",
    "import pyspark.sql.functions as F\n",
    "dfRwt2 = dfRwt.withColumn('RunwayWaitTimeInSeconds', F.unix_timestamp(dfRwt.LiftOffTime) - F.unix_timestamp(dfRwt.StartTime))\n",
    "dfNeg = dfRwt2.where('RunwayWaitTimeInSeconds < 0')\n",
    "   \n",
    "# Negative Runway Wait Time (RWT)\n",
    "print(f'No. flights with negative RWT = {dfNeg.count()}') # 5025\n",
    "print(f'% of flights with negative RWT = {round(dfNeg.count() * 100 / dfRwt2.count(), 2)}%') # 0.32%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f66d255f-da7c-40c6-aba0-6d40786decb8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------+-----------------------------------------------------------------------------------------------------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+\n",
       "Icao  |Op                                                                                                                                       |From|To |StartTime              |LiftOffTime            |RunwayWaitTimeInSeconds|\n",
       "+------+-----------------------------------------------------------------------------------------------------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+\n",
       "A5225B|STATE FARM MUTUAL AUTOMOBILE INSURANCE CO     - BLOOMINGTON, IL                                                                          |SFO |COU|2019-11-18 21:01:34.206|2019-11-18 16:58:31.109|-14583                 |\n",
       "A7E1C2|FedEx                                                                                                                                    |LAX |COU|2019-11-11 00:43:41.486|2019-11-10 08:12:28.706|-59473                 |\n",
       "A10785|United Express                                                                                                                           |ORD |TIK|2020-01-01 21:54:23.379|2019-12-31 00:00:05.829|-165258                |\n",
       "A32EF8|JETBLUE AIRWAYS CORP     - LONG ISLAND CITY, NY                                                                                          |ORD |ROC|2019-12-10 23:10:25.765|2019-12-09 00:50:31.019|-166794                |\n",
       "A44262|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |SEA|2019-12-02 22:11:14.412|2019-12-01 01:37:30.07 |-160424                |\n",
       "AA3417|AMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                               |DFW |DFW|2020-12-24 03:46:27.977|2020-12-23 17:17:14.609|-37753                 |\n",
       "AAB001|UNITED AIRLINES INC     - CHICAGO, IL                                                                                                    |SFO |TLV|2019-12-31 13:43:23.602|2019-12-30 06:57:21.444|-110762                |\n",
       "A97639|KALITTA AIR LLC     - YPSILANTI, MI                                                                                                      |LAX |SUU|2019-11-17 09:08:03.506|2019-11-17 00:23:31.26 |-31472                 |\n",
       "A54AB2|AIR WISCONSIN AIRLINES CORP     - APPLETON, WI                                                                                           |ORD |BDL|2019-11-24 23:49:26.697|2019-11-23 00:00:32.6  |-172134                |\n",
       "A7E579|FedEx                                                                                                                                    |SEA |DAY|2019-11-16 14:48:29.046|2019-11-15 04:16:28.815|-124321                |\n",
       "AD474C|Delta Air Lines                                                                                                                          |ORD |MSP|2019-12-22 21:55:24.658|2019-12-20 23:59:54.839|-165330                |\n",
       "ACB468|American Eagle                                                                                                                           |ORD |ORD|2019-12-20 23:36:17.252|2019-12-19 00:00:11.787|-171366                |\n",
       "A5625B|Alaska Airlines                                                                                                                          |SEA |BOI|2019-12-19 23:56:20.723|2019-12-17 23:59:51.578|-172589                |\n",
       "A6F777|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |GRF|2019-11-12 23:57:36.957|2019-11-11 00:18:32.393|-171544                |\n",
       "A09E47|SkyWest Airlines                                                                                                                         |ORD |OKC|2019-11-25 23:52:39.221|2019-11-24 00:00:30.792|-172329                |\n",
       "A04B92|SkyWest Airlines                                                                                                                         |SFO |SFO|2019-11-16 23:48:29.408|2019-11-15 00:00:30.602|-172079                |\n",
       "A1512F|Alaska Airlines                                                                                                                          |SFO |FAT|2019-11-03 23:53:47.015|2019-11-02 00:00:31.434|-172396                |\n",
       "AC3DDA|Consolidated Press Holdings Ltd                                                                                                          |LAX |DRO|2019-12-17 20:45:23.819|2019-12-16 15:37:37.714|-104866                |\n",
       "A2D38E|Alaska Airlines                                                                                                                          |SFO |SFO|2019-12-08 23:35:32.14 |2019-12-07 00:00:37.41 |-171295                |\n",
       "AC9731|American Eagle                                                                                                                           |DFW |SPS|2019-12-28 22:00:41.158|2019-12-27 00:09:24.285|-165077                |\n",
       "A7B92B|UNITED AIRLINES INC     - CHICAGO, IL                                                                                                    |SFO |PUB|2019-11-22 22:34:29.284|2019-11-21 04:41:31.249|-150778                |\n",
       "A4200D|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |LAX|2019-12-25 23:46:24.642|2019-12-24 00:06:22.895|-171602                |\n",
       "A9A9EF|BEMIDJI AVIATION SERVICES INC     - BEMIDJI, MN                                                                                          |DEN |DEN|2020-12-24 17:05:15.595|2020-12-23 14:36:59.479|-95296                 |\n",
       "A6AC39|Alaska Airlines                                                                                                                          |SEA |LAX|2019-12-20 04:57:22.596|2019-12-19 00:00:24.62 |-104218                |\n",
       "A835D1|Alaska Airlines                                                                                                                          |SEA |SEA|2019-12-14 23:59:23.144|2019-12-13 00:28:43.396|-171040                |\n",
       "A57362|Polar Air Cargo                                                                                                                          |LAX |ALB|2019-12-08 00:00:07.175|2019-12-06 01:21:48.789|-167899                |\n",
       "A83F98|Alaska Airlines                                                                                                                          |SFO |HHR|2019-12-22 23:55:21.82 |2019-12-21 00:00:05.602|-172516                |\n",
       "A0FBB7|United Airlines                                                                                                                          |SFO |DAY|2019-12-31 23:32:25.662|2019-12-30 00:00:24.545|-171121                |\n",
       "A9250D|AMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                               |ORD |FMY|2019-11-15 22:23:59.248|2019-11-14 00:00:12.882|-167027                |\n",
       "A041A6|United Express                                                                                                                           |ORD |MFE|2019-12-31 22:08:23.957|2019-12-30 00:34:27.134|-164036                |\n",
       "A7D665|Compass Airlines                                                                                                                         |SEA |SJC|2019-12-11 22:16:30.373|2019-12-10 00:00:21.683|-166569                |\n",
       "AA3839|American Eagle                                                                                                                           |ORD |MKE|2019-12-30 23:24:24.733|2019-12-29 01:01:23.622|-166981                |\n",
       "A067EC|SkyWest Airlines                                                                                                                         |ORD |TYS|2019-11-27 22:31:54.444|2019-11-26 00:18:32.621|-166402                |\n",
       "A96577|Delta Air Lines                                                                                                                          |SFO |IND|2019-12-28 23:26:22.944|2019-12-27 00:00:27.055|-170755                |\n",
       "A2AF91|Delta Connection                                                                                                                         |LAX |OMA|2019-12-25 21:06:28.959|2019-12-24 00:01:32.714|-162296                |\n",
       "A84ABD|Alaska Airlines                                                                                                                          |LAX |MWH|2019-12-13 23:31:18.389|2019-12-12 00:00:12.361|-171066                |\n",
       "A1C229|American Eagle                                                                                                                           |SFO |LAX|2019-12-23 23:46:22.398|2019-12-22 00:00:30.338|-171952                |\n",
       "A10744|United Express                                                                                                                           |ORD |LBB|2019-12-30 22:34:25.846|2019-12-29 16:44:25.565|-107400                |\n",
       "A84E74|Alaska Airlines                                                                                                                          |SFO |SFO|2019-11-10 00:57:35.244|2019-11-08 23:44:28.366|-90787                 |\n",
       "AA7C1C|FEDERAL EXPRESS CORPORATION     - MEMPHIS, TN                                                                                            |SEA |SEA|2019-12-21 18:50:30.607|2019-12-20 00:00:27.261|-154203                |\n",
       "ACC59D|American Eagle                                                                                                                           |ORD |HUF|2019-12-24 23:45:23.086|2019-12-23 00:07:30.598|-171473                |\n",
       "A13608|United Airlines                                                                                                                          |ORD |ORD|2019-11-18 01:47:57.817|2019-11-17 00:38:28.09 |-90569                 |\n",
       "A89D59|United Airlines                                                                                                                          |ORD |GVA|2019-12-24 18:31:24.945|2019-12-23 00:00:24.449|-153060                |\n",
       "A05559|SkyWest Airlines                                                                                                                         |SFO |SLC|2019-12-16 23:53:10.653|2019-12-15 00:11:20.434|-171710                |\n",
       "A83088|Compass Airlines                                                                                                                         |SEA |BOI|2019-12-02 23:59:47.482|2019-11-30 23:59:50.963|-172797                |\n",
       "AB7080|Alaska Airlines                                                                                                                          |SFO |SFO|2019-12-22 23:56:21.381|2019-12-21 01:26:24.818|-167397                |\n",
       "A880B0|Alaska Airlines                                                                                                                          |SEA |CIC|2019-12-28 22:23:08.445|2019-12-27 00:30:35.483|-165153                |\n",
       "A0CBD6|SkyWest Airlines                                                                                                                         |ORD |SFO|2019-11-07 23:55:35.824|2019-11-06 01:09:26.532|-168369                |\n",
       "A174F7|Alaska Airlines                                                                                                                          |SFO |SJC|2019-12-25 23:55:21.196|2019-12-24 00:33:24.145|-170517                |\n",
       "A4FC9A|MAS Air Cargo                                                                                                                            |LAX |LAX|2019-12-30 13:00:23.204|2019-12-29 00:11:27.458|-132536                |\n",
       "A02DDA|SkyWest Airlines                                                                                                                         |ORD |ORD|2019-11-23 22:13:17.801|2019-11-22 00:26:25.884|-164812                |\n",
       "A0B6EA|SkyWest Airlines                                                                                                                         |ORD |ORD|2019-11-19 21:56:51.562|2019-11-18 00:00:07.537|-165404                |\n",
       "A07524|JULIET ROMEO AVIATION LLC     - ANCHORAGE, AK                                                                                            |LAX |LAX|2019-12-18 22:57:32.131|2019-12-18 19:35:21.453|-12131                 |\n",
       "A5E433|Avianca El Salvador                                                                                                                      |LAX |MGA|2020-12-23 19:02:44.694|2020-12-22 02:28:19.462|-146065                |\n",
       "A97282|KALITTA AIR LLC     - YPSILANTI, MI                                                                                                      |LAX |LAX|2019-12-29 02:38:22.152|2019-12-29 00:00:19.578|-9483                  |\n",
       "A08BB4|SkyWest Airlines                                                                                                                         |LAX |SFO|2019-11-20 22:12:57.193|2019-11-19 00:36:31.46 |-164186                |\n",
       "AAF4A2|Dennis Henner Trustee                                                                                                                    |SFO |BUR|2018-11-05 23:33:42.503|2018-11-04 17:47:05.165|-107197                |\n",
       "ACB8A0|American Eagle                                                                                                                           |DFW |GCK|2019-12-21 22:58:21.917|2019-12-19 23:54:01.634|-169460                |\n",
       "A57DC2|SHP-AIR LEASING LLC     - WILMINGTON, NC                                                                                                 |LAX |LAX|2019-12-16 02:24:55.661|2019-12-16 00:00:23.363|-8672                  |\n",
       "AB856C|Alaska Airlines                                                                                                                          |LAX |TCM|2019-12-15 14:16:21.667|2019-12-14 01:19:16.135|-133025                |\n",
       "AA55B5|Delta Connection                                                                                                                         |DFW |MKE|2020-12-23 19:54:43.844|2020-12-22 00:00:00.287|-158083                |\n",
       "A08BB4|SkyWest Airlines                                                                                                                         |LAX |TUS|2019-12-22 22:41:08.169|2019-12-21 00:00:20.813|-168048                |\n",
       "A9CF43|FedEx                                                                                                                                    |LAX |ICT|2019-11-28 15:18:55.738|2019-11-28 00:00:30.895|-55105                 |\n",
       "A5AD44|ATLAS AIR                                                                                                                                |LAX |LAX|2019-12-30 19:53:25.196|2019-12-30 00:30:20.769|-69785                 |\n",
       "A03264|United Express                                                                                                                           |ORD |BNA|2019-12-31 00:29:19.047|2019-12-30 01:00:24.505|-84535                 |\n",
       "AA017C|ABX Air                                                                                                                                  |ORD |ONT|2020-12-23 19:59:26.699|2020-12-22 00:42:13.595|-155833                |\n",
       "A5C725|American Eagle                                                                                                                           |ORD |STL|2019-11-28 15:08:02.438|2019-11-28 00:57:31.296|-51031                 |\n",
       "AABFF4|FEDERAL EXPRESS CORP     - MEMPHIS, TN                                                                                                   |ORD |ORD|2019-11-08 10:05:27.986|2019-11-08 04:32:32.361|-19975                 |\n",
       "A6EC52|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |LAX|2019-12-31 02:57:41.591|2019-12-31 00:00:22.024|-10639                 |\n",
       "A7F6AE|FedEx                                                                                                                                    |LAX |OAK|2019-12-29 15:36:22.73 |2019-12-29 00:04:18.979|-55924                 |\n",
       "A31984|United Express                                                                                                                           |ORD |SKY|2019-12-18 23:45:24.205|2019-12-17 00:00:23.001|-171901                |\n",
       "A39089|JETBLUE AIRWAYS CORP     - LONG ISLAND CITY, NY                                                                                          |ORD |DCA|2019-12-07 23:39:13.553|2019-12-06 00:00:31.294|-171522                |\n",
       "A8291A|Compass Airlines                                                                                                                         |LAX |SJC|2019-12-12 04:38:26.469|2019-12-11 00:37:21.298|-100865                |\n",
       "A36200|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |SFO |SLC|2019-12-19 23:44:25.046|2019-12-18 00:43:24.699|-169261                |\n",
       "A8FEB8|SAF CRJ-200LR MSN 7652 LLC     - PLANO, TX                                                                                               |ORD |DEN|2019-11-20 01:29:35.219|2019-11-19 00:02:31.167|-91624                 |\n",
       "A0A457|SkyWest Airlines                                                                                                                         |LAX |SFO|2019-11-19 16:59:54.851|2019-11-18 00:20:33.186|-146361                |\n",
       "A1B4AB|American Eagle                                                                                                                           |LAX |LAX|2019-11-09 02:56:49.048|2019-11-08 00:00:35.844|-96974                 |\n",
       "A13F5E|CALS LTD     - HARBOR SPRINGS, MI                                                                                                        |LAX |LAX|2019-11-06 03:23:41.268|2019-11-06 02:59:32.369|-1449                  |\n",
       "AC9850|United Express                                                                                                                           |LAX |IND|2019-12-27 23:57:22.976|2019-12-26 00:00:22.695|-172620                |\n",
       "A7E18A|Compass Airlines                                                                                                                         |LAX |LAX|2019-12-15 17:48:04.093|2019-12-14 00:00:22.213|-150462                |\n",
       "A1933C|American Airlines                                                                                                                        |LAX |SJC|2019-12-11 05:23:02.147|2019-12-10 01:19:23.266|-101019                |\n",
       "AD9B94|United Express                                                                                                                           |ORD |LAX|2019-12-09 22:49:31.194|2019-12-08 01:22:32.521|-163619                |\n",
       "AADB37|UNITED AIRLINES INC     - CHICAGO, IL                                                                                                    |SFO |SFO|2019-12-07 22:50:29.877|2019-12-06 15:50:24.343|-111605                |\n",
       "AC2A33|American Airlines                                                                                                                        |DFW |CVG|2019-12-16 23:06:15.11 |2019-12-15 10:28:12.456|-131883                |\n",
       "AB6CC9|Alaska Airlines                                                                                                                          |SFO |BFL|2019-12-19 23:05:23.941|2019-12-18 00:05:45.964|-169178                |\n",
       "AA4A65|FAIRHOLME AVIATION LLC STIEFEL CHARLES ROUNDTREE JET SERVICES LLC ORACLE AVIATION LLC ABBVIE INC PAUL JUDITH A TRUSTEE- OKLAHOMA CITY, OK|SFO |SFO|2019-11-15 19:08:02.86 |2019-11-15 15:08:30.714|-14372                 |\n",
       "A09852|United Airlines                                                                                                                          |ORD |PHL|2019-12-24 23:54:20.995|2019-12-23 00:00:24.623|-172436                |\n",
       "AA21EF|American Eagle                                                                                                                           |ORD |BNA|2019-12-25 23:00:23.068|2019-12-24 00:00:21.468|-169202                |\n",
       "A0DD61|GoJet Airlines                                                                                                                           |ORD |MCI|2019-11-29 23:36:36.603|2019-11-28 00:03:31.37 |-171185                |\n",
       "AC79C7|AMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                               |LAX |DFW|2020-01-01 01:55:23.538|2019-12-31 01:13:19.674|-88924                 |\n",
       "AD9B94|United Express                                                                                                                           |SFO |TUS|2019-12-07 22:53:18.606|2019-12-05 23:55:25.42 |-169073                |\n",
       "A10897|GOJET AIRLINES LLC     - BRIDGETON, MO                                                                                                   |ORD |ORD|2019-12-11 22:44:25.824|2019-12-10 00:14:22.149|-167403                |\n",
       "A880B0|Alaska Airlines                                                                                                                          |SEA |PDX|2019-12-01 22:21:21.62 |2019-11-30 00:00:20.941|-166861                |\n",
       "A6721B|Gama Aviation                                                                                                                            |LAX |LAX|2019-12-24 21:56:25.167|2019-12-24 20:50:22.577|-3963                  |\n",
       "A2DD2A|DHL Air                                                                                                                                  |SFO |DFW|2019-12-19 16:32:31.873|2019-12-18 04:05:22.874|-131229                |\n",
       "A7D2AE|Compass Airlines                                                                                                                         |SEA |SNA|2019-12-30 23:10:15.89 |2019-12-29 00:00:19.537|-169796                |\n",
       "A1A986|American Eagle                                                                                                                           |LAX |LAX|2019-12-21 23:19:14.559|2019-12-20 00:00:18.409|-170336                |\n",
       "A090E7|United Express                                                                                                                           |ORD |PMC|2019-12-20 22:21:12.533|2019-12-19 03:10:27.847|-155445                |\n",
       "A44DDC|AeroMexico                                                                                                                               |DEN |SEA|2020-12-23 19:50:00.423|2020-12-22 00:07:00.06 |-157380                |\n",
       "AB7080|Alaska Airlines                                                                                                                          |SFO |SFO|2019-12-14 22:18:25.063|2019-12-12 23:41:10.342|-167835                |\n",
       "+------+-----------------------------------------------------------------------------------------------------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+\n",
       "only showing top 100 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+------+-----------------------------------------------------------------------------------------------------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+\n|Icao  |Op                                                                                                                                       |From|To |StartTime              |LiftOffTime            |RunwayWaitTimeInSeconds|\n+------+-----------------------------------------------------------------------------------------------------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+\n|A5225B|STATE FARM MUTUAL AUTOMOBILE INSURANCE CO     - BLOOMINGTON, IL                                                                          |SFO |COU|2019-11-18 21:01:34.206|2019-11-18 16:58:31.109|-14583                 |\n|A7E1C2|FedEx                                                                                                                                    |LAX |COU|2019-11-11 00:43:41.486|2019-11-10 08:12:28.706|-59473                 |\n|A10785|United Express                                                                                                                           |ORD |TIK|2020-01-01 21:54:23.379|2019-12-31 00:00:05.829|-165258                |\n|A32EF8|JETBLUE AIRWAYS CORP     - LONG ISLAND CITY, NY                                                                                          |ORD |ROC|2019-12-10 23:10:25.765|2019-12-09 00:50:31.019|-166794                |\n|A44262|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |SEA|2019-12-02 22:11:14.412|2019-12-01 01:37:30.07 |-160424                |\n|AA3417|AMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                               |DFW |DFW|2020-12-24 03:46:27.977|2020-12-23 17:17:14.609|-37753                 |\n|AAB001|UNITED AIRLINES INC     - CHICAGO, IL                                                                                                    |SFO |TLV|2019-12-31 13:43:23.602|2019-12-30 06:57:21.444|-110762                |\n|A97639|KALITTA AIR LLC     - YPSILANTI, MI                                                                                                      |LAX |SUU|2019-11-17 09:08:03.506|2019-11-17 00:23:31.26 |-31472                 |\n|A54AB2|AIR WISCONSIN AIRLINES CORP     - APPLETON, WI                                                                                           |ORD |BDL|2019-11-24 23:49:26.697|2019-11-23 00:00:32.6  |-172134                |\n|A7E579|FedEx                                                                                                                                    |SEA |DAY|2019-11-16 14:48:29.046|2019-11-15 04:16:28.815|-124321                |\n|AD474C|Delta Air Lines                                                                                                                          |ORD |MSP|2019-12-22 21:55:24.658|2019-12-20 23:59:54.839|-165330                |\n|ACB468|American Eagle                                                                                                                           |ORD |ORD|2019-12-20 23:36:17.252|2019-12-19 00:00:11.787|-171366                |\n|A5625B|Alaska Airlines                                                                                                                          |SEA |BOI|2019-12-19 23:56:20.723|2019-12-17 23:59:51.578|-172589                |\n|A6F777|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |GRF|2019-11-12 23:57:36.957|2019-11-11 00:18:32.393|-171544                |\n|A09E47|SkyWest Airlines                                                                                                                         |ORD |OKC|2019-11-25 23:52:39.221|2019-11-24 00:00:30.792|-172329                |\n|A04B92|SkyWest Airlines                                                                                                                         |SFO |SFO|2019-11-16 23:48:29.408|2019-11-15 00:00:30.602|-172079                |\n|A1512F|Alaska Airlines                                                                                                                          |SFO |FAT|2019-11-03 23:53:47.015|2019-11-02 00:00:31.434|-172396                |\n|AC3DDA|Consolidated Press Holdings Ltd                                                                                                          |LAX |DRO|2019-12-17 20:45:23.819|2019-12-16 15:37:37.714|-104866                |\n|A2D38E|Alaska Airlines                                                                                                                          |SFO |SFO|2019-12-08 23:35:32.14 |2019-12-07 00:00:37.41 |-171295                |\n|AC9731|American Eagle                                                                                                                           |DFW |SPS|2019-12-28 22:00:41.158|2019-12-27 00:09:24.285|-165077                |\n|A7B92B|UNITED AIRLINES INC     - CHICAGO, IL                                                                                                    |SFO |PUB|2019-11-22 22:34:29.284|2019-11-21 04:41:31.249|-150778                |\n|A4200D|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |LAX|2019-12-25 23:46:24.642|2019-12-24 00:06:22.895|-171602                |\n|A9A9EF|BEMIDJI AVIATION SERVICES INC     - BEMIDJI, MN                                                                                          |DEN |DEN|2020-12-24 17:05:15.595|2020-12-23 14:36:59.479|-95296                 |\n|A6AC39|Alaska Airlines                                                                                                                          |SEA |LAX|2019-12-20 04:57:22.596|2019-12-19 00:00:24.62 |-104218                |\n|A835D1|Alaska Airlines                                                                                                                          |SEA |SEA|2019-12-14 23:59:23.144|2019-12-13 00:28:43.396|-171040                |\n|A57362|Polar Air Cargo                                                                                                                          |LAX |ALB|2019-12-08 00:00:07.175|2019-12-06 01:21:48.789|-167899                |\n|A83F98|Alaska Airlines                                                                                                                          |SFO |HHR|2019-12-22 23:55:21.82 |2019-12-21 00:00:05.602|-172516                |\n|A0FBB7|United Airlines                                                                                                                          |SFO |DAY|2019-12-31 23:32:25.662|2019-12-30 00:00:24.545|-171121                |\n|A9250D|AMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                               |ORD |FMY|2019-11-15 22:23:59.248|2019-11-14 00:00:12.882|-167027                |\n|A041A6|United Express                                                                                                                           |ORD |MFE|2019-12-31 22:08:23.957|2019-12-30 00:34:27.134|-164036                |\n|A7D665|Compass Airlines                                                                                                                         |SEA |SJC|2019-12-11 22:16:30.373|2019-12-10 00:00:21.683|-166569                |\n|AA3839|American Eagle                                                                                                                           |ORD |MKE|2019-12-30 23:24:24.733|2019-12-29 01:01:23.622|-166981                |\n|A067EC|SkyWest Airlines                                                                                                                         |ORD |TYS|2019-11-27 22:31:54.444|2019-11-26 00:18:32.621|-166402                |\n|A96577|Delta Air Lines                                                                                                                          |SFO |IND|2019-12-28 23:26:22.944|2019-12-27 00:00:27.055|-170755                |\n|A2AF91|Delta Connection                                                                                                                         |LAX |OMA|2019-12-25 21:06:28.959|2019-12-24 00:01:32.714|-162296                |\n|A84ABD|Alaska Airlines                                                                                                                          |LAX |MWH|2019-12-13 23:31:18.389|2019-12-12 00:00:12.361|-171066                |\n|A1C229|American Eagle                                                                                                                           |SFO |LAX|2019-12-23 23:46:22.398|2019-12-22 00:00:30.338|-171952                |\n|A10744|United Express                                                                                                                           |ORD |LBB|2019-12-30 22:34:25.846|2019-12-29 16:44:25.565|-107400                |\n|A84E74|Alaska Airlines                                                                                                                          |SFO |SFO|2019-11-10 00:57:35.244|2019-11-08 23:44:28.366|-90787                 |\n|AA7C1C|FEDERAL EXPRESS CORPORATION     - MEMPHIS, TN                                                                                            |SEA |SEA|2019-12-21 18:50:30.607|2019-12-20 00:00:27.261|-154203                |\n|ACC59D|American Eagle                                                                                                                           |ORD |HUF|2019-12-24 23:45:23.086|2019-12-23 00:07:30.598|-171473                |\n|A13608|United Airlines                                                                                                                          |ORD |ORD|2019-11-18 01:47:57.817|2019-11-17 00:38:28.09 |-90569                 |\n|A89D59|United Airlines                                                                                                                          |ORD |GVA|2019-12-24 18:31:24.945|2019-12-23 00:00:24.449|-153060                |\n|A05559|SkyWest Airlines                                                                                                                         |SFO |SLC|2019-12-16 23:53:10.653|2019-12-15 00:11:20.434|-171710                |\n|A83088|Compass Airlines                                                                                                                         |SEA |BOI|2019-12-02 23:59:47.482|2019-11-30 23:59:50.963|-172797                |\n|AB7080|Alaska Airlines                                                                                                                          |SFO |SFO|2019-12-22 23:56:21.381|2019-12-21 01:26:24.818|-167397                |\n|A880B0|Alaska Airlines                                                                                                                          |SEA |CIC|2019-12-28 22:23:08.445|2019-12-27 00:30:35.483|-165153                |\n|A0CBD6|SkyWest Airlines                                                                                                                         |ORD |SFO|2019-11-07 23:55:35.824|2019-11-06 01:09:26.532|-168369                |\n|A174F7|Alaska Airlines                                                                                                                          |SFO |SJC|2019-12-25 23:55:21.196|2019-12-24 00:33:24.145|-170517                |\n|A4FC9A|MAS Air Cargo                                                                                                                            |LAX |LAX|2019-12-30 13:00:23.204|2019-12-29 00:11:27.458|-132536                |\n|A02DDA|SkyWest Airlines                                                                                                                         |ORD |ORD|2019-11-23 22:13:17.801|2019-11-22 00:26:25.884|-164812                |\n|A0B6EA|SkyWest Airlines                                                                                                                         |ORD |ORD|2019-11-19 21:56:51.562|2019-11-18 00:00:07.537|-165404                |\n|A07524|JULIET ROMEO AVIATION LLC     - ANCHORAGE, AK                                                                                            |LAX |LAX|2019-12-18 22:57:32.131|2019-12-18 19:35:21.453|-12131                 |\n|A5E433|Avianca El Salvador                                                                                                                      |LAX |MGA|2020-12-23 19:02:44.694|2020-12-22 02:28:19.462|-146065                |\n|A97282|KALITTA AIR LLC     - YPSILANTI, MI                                                                                                      |LAX |LAX|2019-12-29 02:38:22.152|2019-12-29 00:00:19.578|-9483                  |\n|A08BB4|SkyWest Airlines                                                                                                                         |LAX |SFO|2019-11-20 22:12:57.193|2019-11-19 00:36:31.46 |-164186                |\n|AAF4A2|Dennis Henner Trustee                                                                                                                    |SFO |BUR|2018-11-05 23:33:42.503|2018-11-04 17:47:05.165|-107197                |\n|ACB8A0|American Eagle                                                                                                                           |DFW |GCK|2019-12-21 22:58:21.917|2019-12-19 23:54:01.634|-169460                |\n|A57DC2|SHP-AIR LEASING LLC     - WILMINGTON, NC                                                                                                 |LAX |LAX|2019-12-16 02:24:55.661|2019-12-16 00:00:23.363|-8672                  |\n|AB856C|Alaska Airlines                                                                                                                          |LAX |TCM|2019-12-15 14:16:21.667|2019-12-14 01:19:16.135|-133025                |\n|AA55B5|Delta Connection                                                                                                                         |DFW |MKE|2020-12-23 19:54:43.844|2020-12-22 00:00:00.287|-158083                |\n|A08BB4|SkyWest Airlines                                                                                                                         |LAX |TUS|2019-12-22 22:41:08.169|2019-12-21 00:00:20.813|-168048                |\n|A9CF43|FedEx                                                                                                                                    |LAX |ICT|2019-11-28 15:18:55.738|2019-11-28 00:00:30.895|-55105                 |\n|A5AD44|ATLAS AIR                                                                                                                                |LAX |LAX|2019-12-30 19:53:25.196|2019-12-30 00:30:20.769|-69785                 |\n|A03264|United Express                                                                                                                           |ORD |BNA|2019-12-31 00:29:19.047|2019-12-30 01:00:24.505|-84535                 |\n|AA017C|ABX Air                                                                                                                                  |ORD |ONT|2020-12-23 19:59:26.699|2020-12-22 00:42:13.595|-155833                |\n|A5C725|American Eagle                                                                                                                           |ORD |STL|2019-11-28 15:08:02.438|2019-11-28 00:57:31.296|-51031                 |\n|AABFF4|FEDERAL EXPRESS CORP     - MEMPHIS, TN                                                                                                   |ORD |ORD|2019-11-08 10:05:27.986|2019-11-08 04:32:32.361|-19975                 |\n|A6EC52|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |LAX |LAX|2019-12-31 02:57:41.591|2019-12-31 00:00:22.024|-10639                 |\n|A7F6AE|FedEx                                                                                                                                    |LAX |OAK|2019-12-29 15:36:22.73 |2019-12-29 00:04:18.979|-55924                 |\n|A31984|United Express                                                                                                                           |ORD |SKY|2019-12-18 23:45:24.205|2019-12-17 00:00:23.001|-171901                |\n|A39089|JETBLUE AIRWAYS CORP     - LONG ISLAND CITY, NY                                                                                          |ORD |DCA|2019-12-07 23:39:13.553|2019-12-06 00:00:31.294|-171522                |\n|A8291A|Compass Airlines                                                                                                                         |LAX |SJC|2019-12-12 04:38:26.469|2019-12-11 00:37:21.298|-100865                |\n|A36200|DELTA AIR LINES INC     - ATLANTA, GA                                                                                                    |SFO |SLC|2019-12-19 23:44:25.046|2019-12-18 00:43:24.699|-169261                |\n|A8FEB8|SAF CRJ-200LR MSN 7652 LLC     - PLANO, TX                                                                                               |ORD |DEN|2019-11-20 01:29:35.219|2019-11-19 00:02:31.167|-91624                 |\n|A0A457|SkyWest Airlines                                                                                                                         |LAX |SFO|2019-11-19 16:59:54.851|2019-11-18 00:20:33.186|-146361                |\n|A1B4AB|American Eagle                                                                                                                           |LAX |LAX|2019-11-09 02:56:49.048|2019-11-08 00:00:35.844|-96974                 |\n|A13F5E|CALS LTD     - HARBOR SPRINGS, MI                                                                                                        |LAX |LAX|2019-11-06 03:23:41.268|2019-11-06 02:59:32.369|-1449                  |\n|AC9850|United Express                                                                                                                           |LAX |IND|2019-12-27 23:57:22.976|2019-12-26 00:00:22.695|-172620                |\n|A7E18A|Compass Airlines                                                                                                                         |LAX |LAX|2019-12-15 17:48:04.093|2019-12-14 00:00:22.213|-150462                |\n|A1933C|American Airlines                                                                                                                        |LAX |SJC|2019-12-11 05:23:02.147|2019-12-10 01:19:23.266|-101019                |\n|AD9B94|United Express                                                                                                                           |ORD |LAX|2019-12-09 22:49:31.194|2019-12-08 01:22:32.521|-163619                |\n|AADB37|UNITED AIRLINES INC     - CHICAGO, IL                                                                                                    |SFO |SFO|2019-12-07 22:50:29.877|2019-12-06 15:50:24.343|-111605                |\n|AC2A33|American Airlines                                                                                                                        |DFW |CVG|2019-12-16 23:06:15.11 |2019-12-15 10:28:12.456|-131883                |\n|AB6CC9|Alaska Airlines                                                                                                                          |SFO |BFL|2019-12-19 23:05:23.941|2019-12-18 00:05:45.964|-169178                |\n|AA4A65|FAIRHOLME AVIATION LLC STIEFEL CHARLES ROUNDTREE JET SERVICES LLC ORACLE AVIATION LLC ABBVIE INC PAUL JUDITH A TRUSTEE- OKLAHOMA CITY, OK|SFO |SFO|2019-11-15 19:08:02.86 |2019-11-15 15:08:30.714|-14372                 |\n|A09852|United Airlines                                                                                                                          |ORD |PHL|2019-12-24 23:54:20.995|2019-12-23 00:00:24.623|-172436                |\n|AA21EF|American Eagle                                                                                                                           |ORD |BNA|2019-12-25 23:00:23.068|2019-12-24 00:00:21.468|-169202                |\n|A0DD61|GoJet Airlines                                                                                                                           |ORD |MCI|2019-11-29 23:36:36.603|2019-11-28 00:03:31.37 |-171185                |\n|AC79C7|AMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                               |LAX |DFW|2020-01-01 01:55:23.538|2019-12-31 01:13:19.674|-88924                 |\n|AD9B94|United Express                                                                                                                           |SFO |TUS|2019-12-07 22:53:18.606|2019-12-05 23:55:25.42 |-169073                |\n|A10897|GOJET AIRLINES LLC     - BRIDGETON, MO                                                                                                   |ORD |ORD|2019-12-11 22:44:25.824|2019-12-10 00:14:22.149|-167403                |\n|A880B0|Alaska Airlines                                                                                                                          |SEA |PDX|2019-12-01 22:21:21.62 |2019-11-30 00:00:20.941|-166861                |\n|A6721B|Gama Aviation                                                                                                                            |LAX |LAX|2019-12-24 21:56:25.167|2019-12-24 20:50:22.577|-3963                  |\n|A2DD2A|DHL Air                                                                                                                                  |SFO |DFW|2019-12-19 16:32:31.873|2019-12-18 04:05:22.874|-131229                |\n|A7D2AE|Compass Airlines                                                                                                                         |SEA |SNA|2019-12-30 23:10:15.89 |2019-12-29 00:00:19.537|-169796                |\n|A1A986|American Eagle                                                                                                                           |LAX |LAX|2019-12-21 23:19:14.559|2019-12-20 00:00:18.409|-170336                |\n|A090E7|United Express                                                                                                                           |ORD |PMC|2019-12-20 22:21:12.533|2019-12-19 03:10:27.847|-155445                |\n|A44DDC|AeroMexico                                                                                                                               |DEN |SEA|2020-12-23 19:50:00.423|2020-12-22 00:07:00.06 |-157380                |\n|AB7080|Alaska Airlines                                                                                                                          |SFO |SFO|2019-12-14 22:18:25.063|2019-12-12 23:41:10.342|-167835                |\n+------+-----------------------------------------------------------------------------------------------------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+\nonly showing top 100 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfNeg.select('Icao', 'Op', 'From', 'To', 'StartTime', 'LiftOffTime', 'RunwayWaitTimeInSeconds')\\\n",
    "     .where(F.col('From').isin({'SEA', 'LAX', 'SFO', 'DEN', 'DFW', 'ORD'}))\\\n",
    "     .show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "65136ca0-0736-4774-997d-a9b0e76dbb30",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[16]: [&#39;Icao&#39;,\n",
       " &#39;Op&#39;,\n",
       " &#39;From&#39;,\n",
       " &#39;To&#39;,\n",
       " &#39;StartTime&#39;,\n",
       " &#39;LiftOffTime&#39;,\n",
       " &#39;TouchDownTime&#39;,\n",
       " &#39;StopTime&#39;,\n",
       " &#39;FromLat&#39;,\n",
       " &#39;FromLong&#39;,\n",
       " &#39;ToLat&#39;,\n",
       " &#39;ToLong&#39;,\n",
       " &#39;RunwayWaitTimeInSeconds&#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[16]: [&#39;Icao&#39;,\n &#39;Op&#39;,\n &#39;From&#39;,\n &#39;To&#39;,\n &#39;StartTime&#39;,\n &#39;LiftOffTime&#39;,\n &#39;TouchDownTime&#39;,\n &#39;StopTime&#39;,\n &#39;FromLat&#39;,\n &#39;FromLong&#39;,\n &#39;ToLat&#39;,\n &#39;ToLong&#39;,\n &#39;RunwayWaitTimeInSeconds&#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfNeg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b7baebba-895b-4402-b903-7596acc821cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "/plots/428c29a4-9dc3-467c-a797-7ce94683cd9e.png",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Negative RWT \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "'%matplotlib inline'\n",
    "sns.distplot(pandas(dfNeg)['RunwayWaitTimeInSeconds'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b225f66d-0b17-4cf8-8458-334dbcae88d4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[18]: 1549282</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[18]: 1549282</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df3 contains flights with non-negative RWT\n",
    "dfRwt3 = dfRwt2.where('RunwayWaitTimeInSeconds >= 0')\n",
    "assert dfRwt3.count() == dfRwt2.count() - dfNeg.count()\n",
    "\n",
    "dfRwt3.count() # 1,549,282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "112e877f-6f42-4789-8547-a88624c65838",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Last run parquet path = &#39;s3://runway-wait-time-data/flights-parquet//2021-03-07-00-00&#39;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Last run parquet path = &#39;s3://runway-wait-time-data/flights-parquet//2021-03-07-00-00&#39;\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "toParquet(dfRwt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1fd6ce1a-964a-4e0e-9d95-9ad43c7242cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">No. flights with RWT longer than 1h = 403875\n",
       "% flights with RWT longer than 1h = 26.07%\n",
       "\n",
       "No. flights with RWT longer than 2h = 205132\n",
       "% flights with RWT longer than 2h = 13.24%\n",
       "\n",
       "No. flights with RWT longer than 3h = 152631\n",
       "% flights with RWT longer than 3h = 9.85%\n",
       "\n",
       "No. flights with RWT longer than 4h = 132924\n",
       "% flights with RWT longer than 4h = 8.58%\n",
       "\n",
       "No. flights with RWT longer than 5h = 122720\n",
       "% flights with RWT longer than 5h = 7.92%\n",
       "\n",
       "No. flights with RWT longer than 6h = 114983\n",
       "% flights with RWT longer than 6h = 7.42%\n",
       "\n",
       "No. flights with RWT longer than 7h = 105930\n",
       "% flights with RWT longer than 7h = 6.84%\n",
       "\n",
       "No. flights with RWT longer than 8h = 94791\n",
       "% flights with RWT longer than 8h = 6.12%\n",
       "\n",
       "No. flights with RWT longer than 9h = 81621\n",
       "% flights with RWT longer than 9h = 5.27%\n",
       "\n",
       "No. flights with RWT longer than 10h = 68069\n",
       "% flights with RWT longer than 10h = 4.39%\n",
       "\n",
       "No. flights with RWT longer than 11h = 54750\n",
       "% flights with RWT longer than 11h = 3.53%\n",
       "\n",
       "No. flights with RWT longer than 12h = 42164\n",
       "% flights with RWT longer than 12h = 2.72%\n",
       "\n",
       "No. flights with RWT longer than 13h = 30424\n",
       "% flights with RWT longer than 13h = 1.96%\n",
       "\n",
       "No. flights with RWT longer than 14h = 21409\n",
       "% flights with RWT longer than 14h = 1.38%\n",
       "\n",
       "No. flights with RWT longer than 15h = 14825\n",
       "% flights with RWT longer than 15h = 0.96%\n",
       "\n",
       "No. flights with RWT longer than 16h = 9973\n",
       "% flights with RWT longer than 16h = 0.64%\n",
       "\n",
       "No. flights with RWT longer than 17h = 6717\n",
       "% flights with RWT longer than 17h = 0.43%\n",
       "\n",
       "No. flights with RWT longer than 18h = 4435\n",
       "% flights with RWT longer than 18h = 0.29%\n",
       "\n",
       "No. flights with RWT longer than 19h = 2763\n",
       "% flights with RWT longer than 19h = 0.18%\n",
       "\n",
       "No. flights with RWT longer than 20h = 1745\n",
       "% flights with RWT longer than 20h = 0.11%\n",
       "\n",
       "No. flights with RWT longer than 21h = 1007\n",
       "% flights with RWT longer than 21h = 0.06%\n",
       "\n",
       "No. flights with RWT longer than 22h = 544\n",
       "% flights with RWT longer than 22h = 0.04%\n",
       "\n",
       "No. flights with RWT longer than 23h = 350\n",
       "% flights with RWT longer than 23h = 0.02%\n",
       "\n",
       "No. flights with RWT longer than 24h = 272\n",
       "% flights with RWT longer than 24h = 0.02%\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">No. flights with RWT longer than 1h = 403875\n% flights with RWT longer than 1h = 26.07%\n\nNo. flights with RWT longer than 2h = 205132\n% flights with RWT longer than 2h = 13.24%\n\nNo. flights with RWT longer than 3h = 152631\n% flights with RWT longer than 3h = 9.85%\n\nNo. flights with RWT longer than 4h = 132924\n% flights with RWT longer than 4h = 8.58%\n\nNo. flights with RWT longer than 5h = 122720\n% flights with RWT longer than 5h = 7.92%\n\nNo. flights with RWT longer than 6h = 114983\n% flights with RWT longer than 6h = 7.42%\n\nNo. flights with RWT longer than 7h = 105930\n% flights with RWT longer than 7h = 6.84%\n\nNo. flights with RWT longer than 8h = 94791\n% flights with RWT longer than 8h = 6.12%\n\nNo. flights with RWT longer than 9h = 81621\n% flights with RWT longer than 9h = 5.27%\n\nNo. flights with RWT longer than 10h = 68069\n% flights with RWT longer than 10h = 4.39%\n\nNo. flights with RWT longer than 11h = 54750\n% flights with RWT longer than 11h = 3.53%\n\nNo. flights with RWT longer than 12h = 42164\n% flights with RWT longer than 12h = 2.72%\n\nNo. flights with RWT longer than 13h = 30424\n% flights with RWT longer than 13h = 1.96%\n\nNo. flights with RWT longer than 14h = 21409\n% flights with RWT longer than 14h = 1.38%\n\nNo. flights with RWT longer than 15h = 14825\n% flights with RWT longer than 15h = 0.96%\n\nNo. flights with RWT longer than 16h = 9973\n% flights with RWT longer than 16h = 0.64%\n\nNo. flights with RWT longer than 17h = 6717\n% flights with RWT longer than 17h = 0.43%\n\nNo. flights with RWT longer than 18h = 4435\n% flights with RWT longer than 18h = 0.29%\n\nNo. flights with RWT longer than 19h = 2763\n% flights with RWT longer than 19h = 0.18%\n\nNo. flights with RWT longer than 20h = 1745\n% flights with RWT longer than 20h = 0.11%\n\nNo. flights with RWT longer than 21h = 1007\n% flights with RWT longer than 21h = 0.06%\n\nNo. flights with RWT longer than 22h = 544\n% flights with RWT longer than 22h = 0.04%\n\nNo. flights with RWT longer than 23h = 350\n% flights with RWT longer than 23h = 0.02%\n\nNo. flights with RWT longer than 24h = 272\n% flights with RWT longer than 24h = 0.02%\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "for hour in range(1,25):\n",
    "  dfTemp = dfRwt3.where(F.col('RunwayWaitTimeInSeconds') > hour*3600)\n",
    "\n",
    "  # Long Runway Wait Time (RWT)\n",
    "  print(f'No. flights with RWT longer than {hour}h = {dfTemp.count()}')\n",
    "  print(f'% flights with RWT longer than {hour}h = {round(dfTemp.count() * 100 / dfRwt3.count(), 2)}%')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "59e52bfb-f082-403f-8d64-b4ef7a464ae7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 2. Add Airport Traffic/Congestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8b990a7f-95eb-4705-bb93-1a3624dc9b68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testDf = spark.read.parquet(most_recent_parquet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3dc57451-7dd2-4a80-b596-0d1d428c1a8f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+\n",
       "  Icao|                  Op|From| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|\n",
       "+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+\n",
       "A54DAD|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 12:57:...|2018-10-31 12:57:...|2018-10-31 12:58:...|2018-10-31 12:58:...|33.459374|-111.725772|33.459374|-111.725772|                      6|\n",
       "A131E1|             Private| PHX|PHX|2018-10-31 19:50:...|2018-10-31 19:58:...|2018-10-31 19:58:...|2018-10-31 20:03:...|33.617729|-111.918694| 33.61805|-111.918526|                    509|\n",
       "A11FC7|     United Airlines| SAN|NXX|2018-10-31 02:53:...|2018-10-31 04:23:...|2018-10-31 08:21:...|2018-10-31 08:34:...|32.734474|-117.203522|40.850008| -75.765901|                   5404|\n",
       "A54D69|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 17:00:...|2018-10-31 17:00:...|2018-10-31 17:01:...|2018-10-31 17:03:...|33.461769|-111.723074|33.462078|-111.723061|                      1|\n",
       "A5CE02|     United Airlines| LGA|OMA|2018-10-31 00:45:...|2018-10-31 14:33:...|2018-10-31 17:18:...|2018-10-31 17:27:...|40.776886| -73.872131|41.144958|  -95.34716|                  49681|\n",
       "+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+\n|  Icao|                  Op|From| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|\n+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+\n|A54DAD|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 12:57:...|2018-10-31 12:57:...|2018-10-31 12:58:...|2018-10-31 12:58:...|33.459374|-111.725772|33.459374|-111.725772|                      6|\n|A131E1|             Private| PHX|PHX|2018-10-31 19:50:...|2018-10-31 19:58:...|2018-10-31 19:58:...|2018-10-31 20:03:...|33.617729|-111.918694| 33.61805|-111.918526|                    509|\n|A11FC7|     United Airlines| SAN|NXX|2018-10-31 02:53:...|2018-10-31 04:23:...|2018-10-31 08:21:...|2018-10-31 08:34:...|32.734474|-117.203522|40.850008| -75.765901|                   5404|\n|A54D69|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 17:00:...|2018-10-31 17:00:...|2018-10-31 17:01:...|2018-10-31 17:03:...|33.461769|-111.723074|33.462078|-111.723061|                      1|\n|A5CE02|     United Airlines| LGA|OMA|2018-10-31 00:45:...|2018-10-31 14:33:...|2018-10-31 17:18:...|2018-10-31 17:27:...|40.776886| -73.872131|41.144958|  -95.34716|                  49681|\n+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "27776b06-725b-45d8-955f-fcbba28447e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------+---------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+-----------------------+---------+-----------+---------+-----------+-----------------------+-----------------------+-----------------------+\n",
       "Icao  |Op                                           |From|To |StartTime              |LiftOffTime            |TouchDownTime          |StopTime               |FromLat  |FromLong   |ToLat    |ToLong     |RunwayWaitTimeInSeconds|DeltaWindowStart       |DeltaWindowEnd         |\n",
       "+------+---------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+-----------------------+---------+-----------+---------+-----------+-----------------------+-----------------------+-----------------------+\n",
       "A54DAD|BANK OF UTAH TRUSTEE     - SALT LAKE CITY, UT|PHX |PHX|2018-10-31 12:57:24.826|2018-10-31 12:57:30.474|2018-10-31 12:58:34.013|2018-10-31 12:58:34.013|33.459374|-111.725772|33.459374|-111.725772|6                      |2018-10-31 12:27:24.826|2018-10-31 13:27:24.826|\n",
       "A131E1|Private                                      |PHX |PHX|2018-10-31 19:50:18.044|2018-10-31 19:58:47.308|2018-10-31 19:58:49.488|2018-10-31 20:03:44.064|33.617729|-111.918694|33.61805 |-111.918526|509                    |2018-10-31 19:20:18.044|2018-10-31 20:20:18.044|\n",
       "A11FC7|United Airlines                              |SAN |NXX|2018-10-31 02:53:26.829|2018-10-31 04:23:30.551|2018-10-31 08:21:34.84 |2018-10-31 08:34:19.322|32.734474|-117.203522|40.850008|-75.765901 |5404                   |2018-10-31 02:23:26.829|2018-10-31 03:23:26.829|\n",
       "A54D69|BANK OF UTAH TRUSTEE     - SALT LAKE CITY, UT|PHX |PHX|2018-10-31 17:00:19.708|2018-10-31 17:00:20.043|2018-10-31 17:01:54.051|2018-10-31 17:03:28.044|33.461769|-111.723074|33.462078|-111.723061|1                      |2018-10-31 16:30:19.708|2018-10-31 17:30:19.708|\n",
       "A5CE02|United Airlines                              |LGA |OMA|2018-10-31 00:45:32.387|2018-10-31 14:33:33.581|2018-10-31 17:18:12.466|2018-10-31 17:27:31.438|40.776886|-73.872131 |41.144958|-95.34716  |49681                  |2018-10-31 00:15:32.387|2018-10-31 01:15:32.387|\n",
       "+------+---------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+-----------------------+---------+-----------+---------+-----------+-----------------------+-----------------------+-----------------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+------+---------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+-----------------------+---------+-----------+---------+-----------+-----------------------+-----------------------+-----------------------+\n|Icao  |Op                                           |From|To |StartTime              |LiftOffTime            |TouchDownTime          |StopTime               |FromLat  |FromLong   |ToLat    |ToLong     |RunwayWaitTimeInSeconds|DeltaWindowStart       |DeltaWindowEnd         |\n+------+---------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+-----------------------+---------+-----------+---------+-----------+-----------------------+-----------------------+-----------------------+\n|A54DAD|BANK OF UTAH TRUSTEE     - SALT LAKE CITY, UT|PHX |PHX|2018-10-31 12:57:24.826|2018-10-31 12:57:30.474|2018-10-31 12:58:34.013|2018-10-31 12:58:34.013|33.459374|-111.725772|33.459374|-111.725772|6                      |2018-10-31 12:27:24.826|2018-10-31 13:27:24.826|\n|A131E1|Private                                      |PHX |PHX|2018-10-31 19:50:18.044|2018-10-31 19:58:47.308|2018-10-31 19:58:49.488|2018-10-31 20:03:44.064|33.617729|-111.918694|33.61805 |-111.918526|509                    |2018-10-31 19:20:18.044|2018-10-31 20:20:18.044|\n|A11FC7|United Airlines                              |SAN |NXX|2018-10-31 02:53:26.829|2018-10-31 04:23:30.551|2018-10-31 08:21:34.84 |2018-10-31 08:34:19.322|32.734474|-117.203522|40.850008|-75.765901 |5404                   |2018-10-31 02:23:26.829|2018-10-31 03:23:26.829|\n|A54D69|BANK OF UTAH TRUSTEE     - SALT LAKE CITY, UT|PHX |PHX|2018-10-31 17:00:19.708|2018-10-31 17:00:20.043|2018-10-31 17:01:54.051|2018-10-31 17:03:28.044|33.461769|-111.723074|33.462078|-111.723061|1                      |2018-10-31 16:30:19.708|2018-10-31 17:30:19.708|\n|A5CE02|United Airlines                              |LGA |OMA|2018-10-31 00:45:32.387|2018-10-31 14:33:33.581|2018-10-31 17:18:12.466|2018-10-31 17:27:31.438|40.776886|-73.872131 |41.144958|-95.34716  |49681                  |2018-10-31 00:15:32.387|2018-10-31 01:15:32.387|\n+------+---------------------------------------------+----+---+-----------------------+-----------------------+-----------------------+-----------------------+---------+-----------+---------+-----------+-----------------------+-----------------------+-----------------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# define UDF based on OP's function\n",
    "TIME_DELTA = 30 # take plus/minus 30 minutes from start time\n",
    "addDelta = (F.udf(lambda dt:  dt + timedelta(minutes=TIME_DELTA),\n",
    "                TimestampType()))\n",
    "subtractDelta = (F.udf(lambda dt:  dt - timedelta(minutes=TIME_DELTA),\n",
    "                TimestampType()))\n",
    "\n",
    "# now apply to timestamp columns\n",
    "deltaDf = testDf.withColumn('DeltaWindowStart', subtractDelta(testDf['StartTime']))\\\n",
    "                .withColumn('DeltaWindowEnd', addDelta(testDf['StartTime']))\n",
    "                            \n",
    "deltaDf.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b8e4afb3-2cfc-4711-bb11-af2478dfd7d8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------+\n",
       "  Icao|                  Op|From| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|    DeltaWindowStart|      DeltaWindowEnd|DateIndicator|\n",
       "+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------+\n",
       "A54DAD|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 12:57:...|2018-10-31 12:57:...|2018-10-31 12:58:...|2018-10-31 12:58:...|33.459374|-111.725772|33.459374|-111.725772|                      6|2018-10-31 12:27:...|2018-10-31 13:27:...|   2018-10-31|\n",
       "A131E1|             Private| PHX|PHX|2018-10-31 19:50:...|2018-10-31 19:58:...|2018-10-31 19:58:...|2018-10-31 20:03:...|33.617729|-111.918694| 33.61805|-111.918526|                    509|2018-10-31 19:20:...|2018-10-31 20:20:...|   2018-10-31|\n",
       "A11FC7|     United Airlines| SAN|NXX|2018-10-31 02:53:...|2018-10-31 04:23:...|2018-10-31 08:21:...|2018-10-31 08:34:...|32.734474|-117.203522|40.850008| -75.765901|                   5404|2018-10-31 02:23:...|2018-10-31 03:23:...|   2018-10-31|\n",
       "A54D69|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 17:00:...|2018-10-31 17:00:...|2018-10-31 17:01:...|2018-10-31 17:03:...|33.461769|-111.723074|33.462078|-111.723061|                      1|2018-10-31 16:30:...|2018-10-31 17:30:...|   2018-10-31|\n",
       "A5CE02|     United Airlines| LGA|OMA|2018-10-31 00:45:...|2018-10-31 14:33:...|2018-10-31 17:18:...|2018-10-31 17:27:...|40.776886| -73.872131|41.144958|  -95.34716|                  49681|2018-10-31 00:15:...|2018-10-31 01:15:...|   2018-10-31|\n",
       "+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------+\n|  Icao|                  Op|From| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|    DeltaWindowStart|      DeltaWindowEnd|DateIndicator|\n+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------+\n|A54DAD|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 12:57:...|2018-10-31 12:57:...|2018-10-31 12:58:...|2018-10-31 12:58:...|33.459374|-111.725772|33.459374|-111.725772|                      6|2018-10-31 12:27:...|2018-10-31 13:27:...|   2018-10-31|\n|A131E1|             Private| PHX|PHX|2018-10-31 19:50:...|2018-10-31 19:58:...|2018-10-31 19:58:...|2018-10-31 20:03:...|33.617729|-111.918694| 33.61805|-111.918526|                    509|2018-10-31 19:20:...|2018-10-31 20:20:...|   2018-10-31|\n|A11FC7|     United Airlines| SAN|NXX|2018-10-31 02:53:...|2018-10-31 04:23:...|2018-10-31 08:21:...|2018-10-31 08:34:...|32.734474|-117.203522|40.850008| -75.765901|                   5404|2018-10-31 02:23:...|2018-10-31 03:23:...|   2018-10-31|\n|A54D69|BANK OF UTAH TRUS...| PHX|PHX|2018-10-31 17:00:...|2018-10-31 17:00:...|2018-10-31 17:01:...|2018-10-31 17:03:...|33.461769|-111.723074|33.462078|-111.723061|                      1|2018-10-31 16:30:...|2018-10-31 17:30:...|   2018-10-31|\n|A5CE02|     United Airlines| LGA|OMA|2018-10-31 00:45:...|2018-10-31 14:33:...|2018-10-31 17:18:...|2018-10-31 17:27:...|40.776886| -73.872131|41.144958|  -95.34716|                  49681|2018-10-31 00:15:...|2018-10-31 01:15:...|   2018-10-31|\n+------+--------------------+----+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create column that indicates the day on which the flight occurred in order to reduce the number of flights that need to be searched for airport congestion. Note that this would result in missing flights that span multiple days but greatly improve performance of this section\n",
    "deltaDfWithDate = deltaDf.withColumn('DateIndicator', F.to_date(F.col('StartTime')))\n",
    "deltaDfWithDate.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4bee533d-78d2-4988-ade0-0faeaac85b4f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+\n",
       "From|DateIndicator|  Icao|                Op| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|    DeltaWindowStart|      DeltaWindowEnd|FlightsWithSameDepartureAirport|\n",
       "+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+\n",
       " ABQ|   2018-10-06|ABF9D5|Southwest Airlines|DEN|2018-10-06 00:08:...|2018-10-06 01:24:...|2018-10-06 02:14:...|2018-10-06 13:49:...|35.047806|-106.614761|39.874935| -104.68708|                   4577|2018-10-05 23:38:...|2018-10-06 00:38:...|           [[ABF9D5, Southwe...|\n",
       " ABQ|   2018-10-06|A35DA8| Frontier Airlines|DEN|2018-10-06 20:54:...|2018-10-06 21:04:...|2018-10-06 21:54:...|2018-10-06 22:10:...|35.048344|-106.618011|39.903416|-104.696106|                    587|2018-10-06 20:24:...|2018-10-06 21:24:...|           [[ABF9D5, Southwe...|\n",
       " ABQ|   2018-10-06|A817B1|   Alaska Airlines|SEA|2018-10-06 00:56:...|2018-10-06 01:03:...|2018-10-06 14:11:...|2018-10-06 16:37:...|35.046268|-106.618736|47.454208|-122.316662|                    420|2018-10-06 00:26:...|2018-10-06 01:26:...|           [[ABF9D5, Southwe...|\n",
       " ABQ|   2018-10-06|A8E75F|             FedEx|LBB|2018-10-06 11:33:...|2018-10-06 13:18:...|2018-10-06 14:05:...|2018-10-06 14:09:...|35.031712|-106.623817| 33.66552|-101.828926|                   6286|2018-10-06 11:03:...|2018-10-06 12:03:...|           [[ABF9D5, Southwe...|\n",
       " ABQ|   2018-10-06|A82A44|   Alaska Airlines|SEA|2018-10-06 02:19:...|2018-10-06 02:24:...|2018-10-06 05:17:...|2018-10-06 12:38:...|35.046284|  -106.6185|47.449127|-122.318018|                    304|2018-10-06 01:49:...|2018-10-06 02:49:...|           [[ABF9D5, Southwe...|\n",
       "+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+\n|From|DateIndicator|  Icao|                Op| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|    DeltaWindowStart|      DeltaWindowEnd|FlightsWithSameDepartureAirport|\n+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+\n| ABQ|   2018-10-06|ABF9D5|Southwest Airlines|DEN|2018-10-06 00:08:...|2018-10-06 01:24:...|2018-10-06 02:14:...|2018-10-06 13:49:...|35.047806|-106.614761|39.874935| -104.68708|                   4577|2018-10-05 23:38:...|2018-10-06 00:38:...|           [[ABF9D5, Southwe...|\n| ABQ|   2018-10-06|A35DA8| Frontier Airlines|DEN|2018-10-06 20:54:...|2018-10-06 21:04:...|2018-10-06 21:54:...|2018-10-06 22:10:...|35.048344|-106.618011|39.903416|-104.696106|                    587|2018-10-06 20:24:...|2018-10-06 21:24:...|           [[ABF9D5, Southwe...|\n| ABQ|   2018-10-06|A817B1|   Alaska Airlines|SEA|2018-10-06 00:56:...|2018-10-06 01:03:...|2018-10-06 14:11:...|2018-10-06 16:37:...|35.046268|-106.618736|47.454208|-122.316662|                    420|2018-10-06 00:26:...|2018-10-06 01:26:...|           [[ABF9D5, Southwe...|\n| ABQ|   2018-10-06|A8E75F|             FedEx|LBB|2018-10-06 11:33:...|2018-10-06 13:18:...|2018-10-06 14:05:...|2018-10-06 14:09:...|35.031712|-106.623817| 33.66552|-101.828926|                   6286|2018-10-06 11:03:...|2018-10-06 12:03:...|           [[ABF9D5, Southwe...|\n| ABQ|   2018-10-06|A82A44|   Alaska Airlines|SEA|2018-10-06 02:19:...|2018-10-06 02:24:...|2018-10-06 05:17:...|2018-10-06 12:38:...|35.046284|  -106.6185|47.449127|-122.318018|                    304|2018-10-06 01:49:...|2018-10-06 02:49:...|           [[ABF9D5, Southwe...|\n+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# deltaDfJoined contains column FlightsWithSameDepartureAirport that contains a list of all flights with the same From airport on the same date\n",
    "deltaDfGroupedByFrom = deltaDfWithDate.withColumn('combined', F.struct(deltaDfWithDate.columns)).groupBy('From', 'DateIndicator').agg(F.collect_list('combined')).withColumnRenamed('collect_list(combined)', 'FlightsWithSameDepartureAirport')\n",
    "deltaDfJoined = deltaDfWithDate.join(deltaDfGroupedByFrom, on=['From', 'DateIndicator'], how='inner')\n",
    "deltaDfJoined.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "edda48a2-c74c-4775-900a-c329cff2b562",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@udf(returnType=IntegerType())\n",
    "def getAirportCongestion(flightList, startTime, endTime, icao):\n",
    "  otherFlights = 0\n",
    "  for flight in flightList:\n",
    "    # if flight is at same time as query flight and is not the same flight (same ICAO), increment number of other flights \n",
    "    if flight['StartTime'] < endTime and flight['StartTime'] > startTime and flight['Icao'] != icao:\n",
    "      otherFlights = otherFlights + 1 \n",
    "  return otherFlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7ab2fe11-60f8-4737-a271-52cad0d887e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+---------------+\n",
       "From|DateIndicator|  Icao|                Op| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|    DeltaWindowStart|      DeltaWindowEnd|FlightsWithSameDepartureAirport|OtherDepartures|\n",
       "+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+---------------+\n",
       " ABQ|   2018-10-06|ABF9D5|Southwest Airlines|DEN|2018-10-06 00:08:...|2018-10-06 01:24:...|2018-10-06 02:14:...|2018-10-06 13:49:...|35.047806|-106.614761|39.874935| -104.68708|                   4577|2018-10-05 23:38:...|2018-10-06 00:38:...|           [[ABF9D5, Southwe...|              0|\n",
       " ABQ|   2018-10-06|A35DA8| Frontier Airlines|DEN|2018-10-06 20:54:...|2018-10-06 21:04:...|2018-10-06 21:54:...|2018-10-06 22:10:...|35.048344|-106.618011|39.903416|-104.696106|                    587|2018-10-06 20:24:...|2018-10-06 21:24:...|           [[ABF9D5, Southwe...|              0|\n",
       " ABQ|   2018-10-06|A817B1|   Alaska Airlines|SEA|2018-10-06 00:56:...|2018-10-06 01:03:...|2018-10-06 14:11:...|2018-10-06 16:37:...|35.046268|-106.618736|47.454208|-122.316662|                    420|2018-10-06 00:26:...|2018-10-06 01:26:...|           [[ABF9D5, Southwe...|              1|\n",
       " ABQ|   2018-10-06|A8E75F|             FedEx|LBB|2018-10-06 11:33:...|2018-10-06 13:18:...|2018-10-06 14:05:...|2018-10-06 14:09:...|35.031712|-106.623817| 33.66552|-101.828926|                   6286|2018-10-06 11:03:...|2018-10-06 12:03:...|           [[ABF9D5, Southwe...|              1|\n",
       " ABQ|   2018-10-06|A82A44|   Alaska Airlines|SEA|2018-10-06 02:19:...|2018-10-06 02:24:...|2018-10-06 05:17:...|2018-10-06 12:38:...|35.046284|  -106.6185|47.449127|-122.318018|                    304|2018-10-06 01:49:...|2018-10-06 02:49:...|           [[ABF9D5, Southwe...|              1|\n",
       "+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+---------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+---------------+\n|From|DateIndicator|  Icao|                Op| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|   FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|    DeltaWindowStart|      DeltaWindowEnd|FlightsWithSameDepartureAirport|OtherDepartures|\n+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+---------------+\n| ABQ|   2018-10-06|ABF9D5|Southwest Airlines|DEN|2018-10-06 00:08:...|2018-10-06 01:24:...|2018-10-06 02:14:...|2018-10-06 13:49:...|35.047806|-106.614761|39.874935| -104.68708|                   4577|2018-10-05 23:38:...|2018-10-06 00:38:...|           [[ABF9D5, Southwe...|              0|\n| ABQ|   2018-10-06|A35DA8| Frontier Airlines|DEN|2018-10-06 20:54:...|2018-10-06 21:04:...|2018-10-06 21:54:...|2018-10-06 22:10:...|35.048344|-106.618011|39.903416|-104.696106|                    587|2018-10-06 20:24:...|2018-10-06 21:24:...|           [[ABF9D5, Southwe...|              0|\n| ABQ|   2018-10-06|A817B1|   Alaska Airlines|SEA|2018-10-06 00:56:...|2018-10-06 01:03:...|2018-10-06 14:11:...|2018-10-06 16:37:...|35.046268|-106.618736|47.454208|-122.316662|                    420|2018-10-06 00:26:...|2018-10-06 01:26:...|           [[ABF9D5, Southwe...|              1|\n| ABQ|   2018-10-06|A8E75F|             FedEx|LBB|2018-10-06 11:33:...|2018-10-06 13:18:...|2018-10-06 14:05:...|2018-10-06 14:09:...|35.031712|-106.623817| 33.66552|-101.828926|                   6286|2018-10-06 11:03:...|2018-10-06 12:03:...|           [[ABF9D5, Southwe...|              1|\n| ABQ|   2018-10-06|A82A44|   Alaska Airlines|SEA|2018-10-06 02:19:...|2018-10-06 02:24:...|2018-10-06 05:17:...|2018-10-06 12:38:...|35.046284|  -106.6185|47.449127|-122.318018|                    304|2018-10-06 01:49:...|2018-10-06 02:49:...|           [[ABF9D5, Southwe...|              1|\n+----+-------------+------+------------------+---+--------------------+--------------------+--------------------+--------------------+---------+-----------+---------+-----------+-----------------------+--------------------+--------------------+-------------------------------+---------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "congestionDf = deltaDfJoined.withColumn('OtherDepartures', getAirportCongestion(F.col('FlightsWithSameDepartureAirport'), F.col('DeltaWindowStart'), F.col('DeltaWindowEnd'), F.col('Icao'))) \n",
    "congestionDf.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8659effa-d6ce-4368-8d9b-7a052508c636",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "",
       "errorSummary": "Cancelled",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "'%matplotlib inline'\n",
    "congestionDf.where(F.col('RunwayWaitTimeInSeconds') < 10000).limit(1000).toPandas().plot.scatter(x='OtherDepartures', y='RunwayWaitTimeInSeconds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "53ab0509-960e-4d2d-abc7-0ca067a384bb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Filtering Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "deb68274-c782-4d39-ae73-acd0c0bab040",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 15 biggest and busiest airports in the US + 11 other notables\n",
    "airportList = ['LAX', 'ATL', 'ORD', 'DFW', 'DEN', 'JFK', 'SFO', 'LAS', 'SEA', 'CLT', 'MCO', 'MIA', 'PHX', 'EWR', 'IAH', 'DTW', 'IAD', 'MSP', 'LGA', 'PDX', 'TPA', 'BOS', 'SLC', 'PHL', 'FLL', 'MDW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bfc64984-be44-47d0-bfe4-011231026add",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[18]: 854446</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[18]: 854446</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "congestionDfFilteredByAirport = congestionDf.filter(F.col('From').isin(airportList))\n",
    "congestionDfFilteredByAirport.count() # 854,446"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5027ede5-594c-4a88-8771-f310dc97e3be",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Filtering Unreasonable Flight Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "45262ec9-fa21-4bc7-a71b-8743d7763484",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+-------+------------------+\n",
       "summary|    FlightDuration|\n",
       "+-------+------------------+\n",
       "  count|            854446|\n",
       "   mean| 6213.572851882975|\n",
       " stddev|15728.875402249041|\n",
       "    min|           -172561|\n",
       "    max|            166800|\n",
       "+-------+------------------+\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+-------+------------------+\n|summary|    FlightDuration|\n+-------+------------------+\n|  count|            854446|\n|   mean| 6213.572851882975|\n| stddev|15728.875402249041|\n|    min|           -172561|\n|    max|            166800|\n+-------+------------------+\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at flight times\n",
    "import pyspark.sql.functions as F\n",
    "df2 = congestionDfFilteredByAirport.withColumn('FlightDuration', F.unix_timestamp(congestionDfFilteredByAirport.TouchDownTime) - F.unix_timestamp(congestionDfFilteredByAirport.LiftOffTime))\n",
    "df2.select('FlightDuration').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "229665b5-07bd-4985-b09f-6d50c4f3f839",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[25]: 557701</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[25]: 557701</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we have flights ranging from negative values to 47 hours long - needs filtering!\n",
    "# min = 15 mins = 900 seconds\n",
    "# max = 19 hours = 68,400 seconds\n",
    "df3 = df2.filter( (F.col('FlightDuration') > 900) & (F.col('FlightDuration') < 68400) )\n",
    "df3.count() #557,701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2e759b73-e492-4f1f-83b0-9abdd177ca76",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[26]: [&#39;From&#39;,\n",
       " &#39;DateIndicator&#39;,\n",
       " &#39;Icao&#39;,\n",
       " &#39;Op&#39;,\n",
       " &#39;To&#39;,\n",
       " &#39;StartTime&#39;,\n",
       " &#39;LiftOffTime&#39;,\n",
       " &#39;TouchDownTime&#39;,\n",
       " &#39;StopTime&#39;,\n",
       " &#39;FromLat&#39;,\n",
       " &#39;FromLong&#39;,\n",
       " &#39;ToLat&#39;,\n",
       " &#39;ToLong&#39;,\n",
       " &#39;RunwayWaitTimeInSeconds&#39;,\n",
       " &#39;DeltaWindowStart&#39;,\n",
       " &#39;DeltaWindowEnd&#39;,\n",
       " &#39;FlightsWithSameDepartureAirport&#39;,\n",
       " &#39;OtherDepartures&#39;,\n",
       " &#39;FlightDuration&#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[26]: [&#39;From&#39;,\n &#39;DateIndicator&#39;,\n &#39;Icao&#39;,\n &#39;Op&#39;,\n &#39;To&#39;,\n &#39;StartTime&#39;,\n &#39;LiftOffTime&#39;,\n &#39;TouchDownTime&#39;,\n &#39;StopTime&#39;,\n &#39;FromLat&#39;,\n &#39;FromLong&#39;,\n &#39;ToLat&#39;,\n &#39;ToLong&#39;,\n &#39;RunwayWaitTimeInSeconds&#39;,\n &#39;DeltaWindowStart&#39;,\n &#39;DeltaWindowEnd&#39;,\n &#39;FlightsWithSameDepartureAirport&#39;,\n &#39;OtherDepartures&#39;,\n &#39;FlightDuration&#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "56ccbd14-7518-4cf1-97d1-9d3b9458d0e9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "colsToDrop = ('DateIndicator', 'DeltaWindowStart', 'DeltaWindowEnd', 'FlightsWithSameDepartureAirport')\n",
    "df4 = df3.drop(*colsToDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ce44fd12-9a90-459c-9f75-1dc8fb3d9e83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[28]: [&#39;From&#39;,\n",
       " &#39;Icao&#39;,\n",
       " &#39;Op&#39;,\n",
       " &#39;To&#39;,\n",
       " &#39;StartTime&#39;,\n",
       " &#39;LiftOffTime&#39;,\n",
       " &#39;TouchDownTime&#39;,\n",
       " &#39;StopTime&#39;,\n",
       " &#39;FromLat&#39;,\n",
       " &#39;FromLong&#39;,\n",
       " &#39;ToLat&#39;,\n",
       " &#39;ToLong&#39;,\n",
       " &#39;RunwayWaitTimeInSeconds&#39;,\n",
       " &#39;OtherDepartures&#39;,\n",
       " &#39;FlightDuration&#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[28]: [&#39;From&#39;,\n &#39;Icao&#39;,\n &#39;Op&#39;,\n &#39;To&#39;,\n &#39;StartTime&#39;,\n &#39;LiftOffTime&#39;,\n &#39;TouchDownTime&#39;,\n &#39;StopTime&#39;,\n &#39;FromLat&#39;,\n &#39;FromLong&#39;,\n &#39;ToLat&#39;,\n &#39;ToLong&#39;,\n &#39;RunwayWaitTimeInSeconds&#39;,\n &#39;OtherDepartures&#39;,\n &#39;FlightDuration&#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "653bce8a-fda7-4524-85c5-e9cd9b80bd15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Last run parquet path = &#39;s3://runway-wait-time-data/flights-parquet//2021-03-11-11-10&#39;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Last run parquet path = &#39;s3://runway-wait-time-data/flights-parquet//2021-03-11-11-10&#39;\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "toParquet(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ee8404ef-6b23-4d72-91d3-e10874802b17",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### 3. Getting weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4dc5d5dc-5ad4-485d-8a9c-538933186128",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Collecting meteostat\n",
       "  Downloading meteostat-1.1.1.tar.gz (11 kB)\n",
       "Collecting pandas&gt;=1.1\n",
       "  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
       "Requirement already satisfied: pytz in /databricks/python3/lib/python3.7/site-packages (from meteostat) (2019.3)\n",
       "Requirement already satisfied: numpy in /databricks/python3/lib/python3.7/site-packages (from meteostat) (1.18.1)\n",
       "Requirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.7/site-packages (from pandas&gt;=1.1-&gt;meteostat) (2.8.1)\n",
       "Requirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=1.1-&gt;meteostat) (1.14.0)\n",
       "Building wheels for collected packages: meteostat\n",
       "  Building wheel for meteostat (setup.py): started\n",
       "  Building wheel for meteostat (setup.py): finished with status &#39;done&#39;\n",
       "  Created wheel for meteostat: filename=meteostat-1.1.1-py3-none-any.whl size=15528 sha256=cdb1dcc6fa76a3a0c81d0fa2ff4e31918e971ceb2d7284e1ae71f1b71c32b960\n",
       "  Stored in directory: /home/root/.cache/pip/wheels/21/b0/11/b84ba37a06a41e37e26d99147327fb32af1662bf9b366dc616\n",
       "Successfully built meteostat\n",
       "Installing collected packages: pandas, meteostat\n",
       "  Attempting uninstall: pandas\n",
       "    Found existing installation: pandas 1.0.1\n",
       "    Not uninstalling pandas at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4eb309b9-8291-4ddf-a7d5-a4ddd9d29904\n",
       "    Can&#39;t uninstall &#39;pandas&#39;. No files were found to uninstall.\n",
       "Successfully installed meteostat-1.1.1 pandas-1.2.3\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting meteostat\n  Downloading meteostat-1.1.1.tar.gz (11 kB)\nCollecting pandas&gt;=1.1\n  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.7/site-packages (from meteostat) (2019.3)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.7/site-packages (from meteostat) (1.18.1)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.7/site-packages (from pandas&gt;=1.1-&gt;meteostat) (2.8.1)\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=1.1-&gt;meteostat) (1.14.0)\nBuilding wheels for collected packages: meteostat\n  Building wheel for meteostat (setup.py): started\n  Building wheel for meteostat (setup.py): finished with status &#39;done&#39;\n  Created wheel for meteostat: filename=meteostat-1.1.1-py3-none-any.whl size=15528 sha256=cdb1dcc6fa76a3a0c81d0fa2ff4e31918e971ceb2d7284e1ae71f1b71c32b960\n  Stored in directory: /home/root/.cache/pip/wheels/21/b0/11/b84ba37a06a41e37e26d99147327fb32af1662bf9b366dc616\nSuccessfully built meteostat\nInstalling collected packages: pandas, meteostat\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.0.1\n    Not uninstalling pandas at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4eb309b9-8291-4ddf-a7d5-a4ddd9d29904\n    Can&#39;t uninstall &#39;pandas&#39;. No files were found to uninstall.\nSuccessfully installed meteostat-1.1.1 pandas-1.2.3\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install meteostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dcb86f9b-9d17-4b0f-9007-13baeed50dea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[1]: {&#39;time&#39;: [Timestamp(&#39;2020-12-31 06:00:00&#39;)],\n",
       " &#39;temp&#39;: [-3.6],\n",
       " &#39;dwpt&#39;: [-11.9],\n",
       " &#39;rhum&#39;: [52.9],\n",
       " &#39;prcp&#39;: [0.0],\n",
       " &#39;snow&#39;: [nan],\n",
       " &#39;wdir&#39;: [340.0],\n",
       " &#39;wspd&#39;: [9.3],\n",
       " &#39;wpgt&#39;: [nan],\n",
       " &#39;pres&#39;: [1018.6],\n",
       " &#39;tsun&#39;: [nan],\n",
       " &#39;coco&#39;: [2.0]}</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[1]: {&#39;time&#39;: [Timestamp(&#39;2020-12-31 06:00:00&#39;)],\n &#39;temp&#39;: [-3.6],\n &#39;dwpt&#39;: [-11.9],\n &#39;rhum&#39;: [52.9],\n &#39;prcp&#39;: [0.0],\n &#39;snow&#39;: [nan],\n &#39;wdir&#39;: [340.0],\n &#39;wspd&#39;: [9.3],\n &#39;wpgt&#39;: [nan],\n &#39;pres&#39;: [1018.6],\n &#39;tsun&#39;: [nan],\n &#39;coco&#39;: [2.0]}</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example\n",
    "# Import Meteostat library and dependencies\n",
    "from datetime import datetime\n",
    "from meteostat import Point, Hourly\n",
    "\n",
    "# Set time period\n",
    "start = datetime(2020, 12, 31, 5, 36)\n",
    "end = datetime(2020, 12, 31, 6, 37)\n",
    "\n",
    "# Get hourly data\n",
    "data = Hourly(Point(39.864498, -104.687622), start, end)\n",
    "data = data.fetch()\n",
    "\n",
    "# Print DataFrame\n",
    "data.reset_index().to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7683e570-8341-48ff-b906-ad7ace98b99b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[8]: [Timestamp(&#39;2018-12-31 04:00:00&#39;),\n",
       " 49.82,\n",
       " 7.2,\n",
       " 83.8,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 270.0,\n",
       " 11.0,\n",
       " 0.0,\n",
       " 1017.3,\n",
       " 0.0,\n",
       " &#39;Cloudy&#39;]</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[8]: [Timestamp(&#39;2018-12-31 04:00:00&#39;),\n 49.82,\n 7.2,\n 83.8,\n 0.0,\n 0.0,\n 270.0,\n 11.0,\n 0.0,\n 1017.3,\n 0.0,\n &#39;Cloudy&#39;]</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AC1E56\tFedEx\tOAK\tOAK\t2018-12-31 05:36:35.721\t2018-12-31 05:36:51.373\t2018-12-31 05:37:15.593\t2018-12-31 05:37:15.593\t1\tFalse\t37.716611\t-122.221408\t37.716611\t-122.221408\n",
    "from datetime import datetime, timedelta\n",
    "from meteostat import Point, Daily\n",
    "import math\n",
    "\n",
    "def weather(startTime, liftOffTime, lat, long): \n",
    "  # for now, assume if it spans multiple hours => use weather data from the first hour\n",
    "  start, end = startTime, liftOffTime # assume startTime < liftOffTime\n",
    "  start = start - timedelta(hours=1)\n",
    "  end = start + timedelta(hours=1)\n",
    "     \n",
    "  location = Point(lat, long)\n",
    "\n",
    "  data = Hourly(location, start, end)\n",
    "  data = data.fetch()\n",
    "  if len(data) > 1:\n",
    "    result = data.reset_index().loc[[0]].to_dict('list')\n",
    "  else:\n",
    "    result = data.reset_index().to_dict('list')\n",
    "  \n",
    "  if (len(result['temp']) > 0 and result['temp'][0]):\n",
    "    result['temp'][0] = round((result['temp'][0] * 1.8) + 32, 2)\n",
    "  \n",
    "  for var in ['snow', 'wpgt', 'tsun']:\n",
    "    if (len(result[var]) > 0 and math.isnan(result[var][0])):\n",
    "      result[var][0] = 0.0\n",
    "\n",
    "  #  Make sure the scheme data type for ConditionCode match as well. Either DoubleType or StringType\n",
    "  condition_codes = {1: 'Clear', 2: 'Fair', 3: 'Cloudy', \\\n",
    "                     4:\t'Overcast', 5: 'Fog', 6: 'Freezing Fog', \\\n",
    "                     7:\t'Light Rain', 8: 'Rain', 9:\t'Heavy Rain', \\\n",
    "                     10: 'Freezing Rain', 11: 'Heavy Freezing Rain', \\\n",
    "                     12: 'Sleet', 13: 'Heavy Sleet', 14: 'Light Snowfall', \\\n",
    "                     15: 'Snowfall', 16: 'Heavy Snowfall', 17: 'Rain Shower', \\\n",
    "                     18: 'Heavy Rain Shower', 19: 'Sleet Shower', 20: 'Heavy Sleet Shower', \\\n",
    "                     21: 'Snow Shower', 22: 'Heavy Snow Shower', 23: 'Lightning', \\\n",
    "                     24: 'Hail', 25: 'Thunderstorm', 26: 'Heavy Thunderstorm', 27: 'Storm'}\n",
    "  \n",
    "  if ( (len(result['coco']) > 0) and (not math.isnan(result['coco'][0])) ):\n",
    "    if int(result['coco'][0]) in condition_codes:\n",
    "      result['coco'][0] = condition_codes[int(result['coco'][0])]\n",
    "    else:\n",
    "      result['coco'][0] = 'Unknown'\n",
    "    \n",
    "  keys = ['time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']\n",
    "  results = [result[key][0] if (key in result and len(result[key]) > 0) else None for key in keys]\n",
    "  return results\n",
    "#   return {keys[i] : results[i] for i in range(len(keys))}\n",
    "\n",
    "#   return result\n",
    "\n",
    "weather(datetime(2018, 12, 31, 5, 0, 0), datetime(2018, 12, 31, 6, 7, 0, 16), 37.716611, -122.221408)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a91ca52e-7d9b-4289-a211-4d262bbcc5bf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&gt;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&gt;\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfWeather = spark.read.options(delimiter='|', inferSchema='True', header='True')\\\n",
    "                      .csv(most_recent_csv_path)\n",
    "print(type(dfWeather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "07f6910a-02da-4234-b1c6-d5e5671048f0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[8]: 557701</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[8]: 557701</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfWeather.count() # 557,701"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "aee98eb5-52e7-4042-828c-77c1ca4d1fe5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather = pandas(dfWeather)\n",
    "print(type(dfpWeather))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cbdc96f4-9717-45b0-b722-03440b4a9403",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[10]: 557701</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[10]: 557701</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(dfpWeather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8cc059bd-e45f-4d9c-86cc-576d6e8ed10e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[11]: Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;],\n",
       "      dtype=&#39;object&#39;)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[11]: Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;],\n      dtype=&#39;object&#39;)</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "332cea4e-a427-4bd0-944d-b66acbf61d65",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[12]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[12]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Icao</th>\n",
       "      <th>Op</th>\n",
       "      <th>To</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LiftOffTime</th>\n",
       "      <th>TouchDownTime</th>\n",
       "      <th>StopTime</th>\n",
       "      <th>FromLat</th>\n",
       "      <th>FromLong</th>\n",
       "      <th>ToLat</th>\n",
       "      <th>ToLong</th>\n",
       "      <th>RunwayWaitTimeInSeconds</th>\n",
       "      <th>OtherDepartures</th>\n",
       "      <th>FlightDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A5427B</td>\n",
       "      <td>Delta Connection</td>\n",
       "      <td>MGE</td>\n",
       "      <td>2019-12-04 12:52:59.365</td>\n",
       "      <td>2019-12-04 12:52:59.365</td>\n",
       "      <td>2019-12-04 14:23:54.729</td>\n",
       "      <td>2019-12-04 17:23:59.988</td>\n",
       "      <td>33.631804</td>\n",
       "      <td>-84.411049</td>\n",
       "      <td>33.652496</td>\n",
       "      <td>-84.905371</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A3DF4A</td>\n",
       "      <td>Frontier Airlines</td>\n",
       "      <td>COS</td>\n",
       "      <td>2019-12-24 15:02:23.902</td>\n",
       "      <td>2019-12-24 16:31:20.110</td>\n",
       "      <td>2019-12-24 22:23:22.434</td>\n",
       "      <td>2019-12-24 22:30:22.430</td>\n",
       "      <td>33.645304</td>\n",
       "      <td>-84.406285</td>\n",
       "      <td>38.791700</td>\n",
       "      <td>-104.687912</td>\n",
       "      <td>5337</td>\n",
       "      <td>0</td>\n",
       "      <td>21122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A35283</td>\n",
       "      <td>Frontier Airlines</td>\n",
       "      <td>LAX</td>\n",
       "      <td>2019-12-24 13:24:22.657</td>\n",
       "      <td>2019-12-24 15:28:21.577</td>\n",
       "      <td>2019-12-24 19:32:52.881</td>\n",
       "      <td>2019-12-24 19:38:21.952</td>\n",
       "      <td>33.638030</td>\n",
       "      <td>-84.422350</td>\n",
       "      <td>33.936535</td>\n",
       "      <td>-118.390789</td>\n",
       "      <td>7439</td>\n",
       "      <td>0</td>\n",
       "      <td>14671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABC573</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2019-12-24 00:06:22.204</td>\n",
       "      <td>2019-12-24 02:09:21.282</td>\n",
       "      <td>2019-12-24 06:46:17.404</td>\n",
       "      <td>2019-12-24 06:48:36.247</td>\n",
       "      <td>33.644024</td>\n",
       "      <td>-84.422336</td>\n",
       "      <td>37.621674</td>\n",
       "      <td>-122.376037</td>\n",
       "      <td>7379</td>\n",
       "      <td>1</td>\n",
       "      <td>16616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A13B66</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>WAL</td>\n",
       "      <td>2019-12-24 00:34:21.210</td>\n",
       "      <td>2019-12-24 16:30:21.212</td>\n",
       "      <td>2019-12-24 17:47:38.693</td>\n",
       "      <td>2019-12-24 17:49:17.903</td>\n",
       "      <td>33.635777</td>\n",
       "      <td>-84.416773</td>\n",
       "      <td>38.068139</td>\n",
       "      <td>-75.513452</td>\n",
       "      <td>57360</td>\n",
       "      <td>1</td>\n",
       "      <td>4637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>From</th>\n      <th>Icao</th>\n      <th>Op</th>\n      <th>To</th>\n      <th>StartTime</th>\n      <th>LiftOffTime</th>\n      <th>TouchDownTime</th>\n      <th>StopTime</th>\n      <th>FromLat</th>\n      <th>FromLong</th>\n      <th>ToLat</th>\n      <th>ToLong</th>\n      <th>RunwayWaitTimeInSeconds</th>\n      <th>OtherDepartures</th>\n      <th>FlightDuration</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ATL</td>\n      <td>A5427B</td>\n      <td>Delta Connection</td>\n      <td>MGE</td>\n      <td>2019-12-04 12:52:59.365</td>\n      <td>2019-12-04 12:52:59.365</td>\n      <td>2019-12-04 14:23:54.729</td>\n      <td>2019-12-04 17:23:59.988</td>\n      <td>33.631804</td>\n      <td>-84.411049</td>\n      <td>33.652496</td>\n      <td>-84.905371</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5455</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ATL</td>\n      <td>A3DF4A</td>\n      <td>Frontier Airlines</td>\n      <td>COS</td>\n      <td>2019-12-24 15:02:23.902</td>\n      <td>2019-12-24 16:31:20.110</td>\n      <td>2019-12-24 22:23:22.434</td>\n      <td>2019-12-24 22:30:22.430</td>\n      <td>33.645304</td>\n      <td>-84.406285</td>\n      <td>38.791700</td>\n      <td>-104.687912</td>\n      <td>5337</td>\n      <td>0</td>\n      <td>21122</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ATL</td>\n      <td>A35283</td>\n      <td>Frontier Airlines</td>\n      <td>LAX</td>\n      <td>2019-12-24 13:24:22.657</td>\n      <td>2019-12-24 15:28:21.577</td>\n      <td>2019-12-24 19:32:52.881</td>\n      <td>2019-12-24 19:38:21.952</td>\n      <td>33.638030</td>\n      <td>-84.422350</td>\n      <td>33.936535</td>\n      <td>-118.390789</td>\n      <td>7439</td>\n      <td>0</td>\n      <td>14671</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ATL</td>\n      <td>ABC573</td>\n      <td>Delta Air Lines</td>\n      <td>SFO</td>\n      <td>2019-12-24 00:06:22.204</td>\n      <td>2019-12-24 02:09:21.282</td>\n      <td>2019-12-24 06:46:17.404</td>\n      <td>2019-12-24 06:48:36.247</td>\n      <td>33.644024</td>\n      <td>-84.422336</td>\n      <td>37.621674</td>\n      <td>-122.376037</td>\n      <td>7379</td>\n      <td>1</td>\n      <td>16616</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATL</td>\n      <td>A13B66</td>\n      <td>JetBlue Airways</td>\n      <td>WAL</td>\n      <td>2019-12-24 00:34:21.210</td>\n      <td>2019-12-24 16:30:21.212</td>\n      <td>2019-12-24 17:47:38.693</td>\n      <td>2019-12-24 17:49:17.903</td>\n      <td>33.635777</td>\n      <td>-84.416773</td>\n      <td>38.068139</td>\n      <td>-75.513452</td>\n      <td>57360</td>\n      <td>1</td>\n      <td>4637</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9047adde-520a-4592-85f0-654c8061b5e8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "RangeIndex: 557701 entries, 0 to 557700\n",
       "Data columns (total 15 columns):\n",
       " #   Column                   Non-Null Count   Dtype         \n",
       "---  ------                   --------------   -----         \n",
       " 0   From                     557701 non-null  object        \n",
       " 1   Icao                     557701 non-null  object        \n",
       " 2   Op                       557687 non-null  object        \n",
       " 3   To                       557701 non-null  object        \n",
       " 4   StartTime                557701 non-null  datetime64[ns]\n",
       " 5   LiftOffTime              557701 non-null  datetime64[ns]\n",
       " 6   TouchDownTime            557701 non-null  datetime64[ns]\n",
       " 7   StopTime                 557701 non-null  datetime64[ns]\n",
       " 8   FromLat                  557701 non-null  float64       \n",
       " 9   FromLong                 557701 non-null  float64       \n",
       " 10  ToLat                    557701 non-null  float64       \n",
       " 11  ToLong                   557701 non-null  float64       \n",
       " 12  RunwayWaitTimeInSeconds  557701 non-null  int32         \n",
       " 13  OtherDepartures          557701 non-null  int32         \n",
       " 14  FlightDuration           557701 non-null  int32         \n",
       "dtypes: datetime64[ns](4), float64(4), int32(3), object(4)\n",
       "memory usage: 57.4+ MB\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 557701 entries, 0 to 557700\nData columns (total 15 columns):\n #   Column                   Non-Null Count   Dtype         \n---  ------                   --------------   -----         \n 0   From                     557701 non-null  object        \n 1   Icao                     557701 non-null  object        \n 2   Op                       557687 non-null  object        \n 3   To                       557701 non-null  object        \n 4   StartTime                557701 non-null  datetime64[ns]\n 5   LiftOffTime              557701 non-null  datetime64[ns]\n 6   TouchDownTime            557701 non-null  datetime64[ns]\n 7   StopTime                 557701 non-null  datetime64[ns]\n 8   FromLat                  557701 non-null  float64       \n 9   FromLong                 557701 non-null  float64       \n 10  ToLat                    557701 non-null  float64       \n 11  ToLong                   557701 non-null  float64       \n 12  RunwayWaitTimeInSeconds  557701 non-null  int32         \n 13  OtherDepartures          557701 non-null  int32         \n 14  FlightDuration           557701 non-null  int32         \ndtypes: datetime64[ns](4), float64(4), int32(3), object(4)\nmemory usage: 57.4+ MB\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2febc9c1-4d9c-472f-9817-d59f933a8b7c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[14]: 557687</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[14]: 557687</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Remove Op = None\n",
    "dfpWeather2 = dfpWeather[dfpWeather['Op'].notnull()]\n",
    "len(dfpWeather2)                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e37626d4-e54e-4617-85b1-d4c33f7f32d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Delta Air Lines\n",
    "# Alaska Airlines\n",
    "# JetBlue Airways\n",
    "# American Airlines\n",
    "# Southwest Airlines\n",
    "# United Airlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a0afbd85-5a03-43d6-ba33-ab737c99a163",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[16]: Delta Air Lines                                                                                                                 44568\n",
       "Delta Connection                                                                                                                18962\n",
       "DELTA AIR LINES INC     - ATLANTA, GA                                                                                           10176\n",
       "Delta Airlines                                                                                                                    462\n",
       "SkyWest Airlines (Delta Connection)                                                                                               210\n",
       "Skywest  Delta Connection                                                                                                         187\n",
       "Skywest Airlines (Delta Connection)                                                                                               176\n",
       "DELTA AIR LINES INC DEPT 595 AIRCRAFT REGISTRATIONS    - ATLANTA, GA                                                              146\n",
       "Delta Private Jets                                                                                                                 63\n",
       "Delta Air Lines (SkyTeam Livery)                                                                                                   49\n",
       "Endeavor Air (Delta Connection)                                                                                                    40\n",
       "DELTA AIR LINES INC     - ALLANTA, GA                                                                                              36\n",
       "DELTA AIR LINES INC DEPT 595 AIRCRAFT REGISTRATION    - ATLANTA, GA                                                                32\n",
       "Endeavor Air  Delta Connection                                                                                                     32\n",
       "SkyWest (Delta Connection)                                                                                                         29\n",
       "SkyWest Delta Connection                                                                                                           28\n",
       "DELTA AIRLINES INC DEPT 595 AIRCRAFT REGISTRATIONS    - ATLANTA, GA                                                                25\n",
       "Delta                                                                                                                              15\n",
       "Delta Connection (Endeavor Air)                                                                                                    14\n",
       "Endeavor Air   Delta Connection                                                                                                     9\n",
       "NETJETS SALES INC COMET I LLC TRINITY AIR LLC GILLIS STRATTON DELTA PEGASUS MANAGEMENT LLC COTTRILL LANCE- OKLAHOMA CITY, OK        9\n",
       "DELTA RIM INC     - GREENVILLE, MS                                                                                                  6\n",
       "DELTA AIR LINES     - ATLANTA, GA                                                                                                   5\n",
       "GoJet   Delta Connection                                                                                                            5\n",
       "CRAFTS LARRY Z     - DELTA, UT                                                                                                      5\n",
       "Delta Point LLC                                                                                                                     3\n",
       "DELTA JET LTD     - SOMERVILLE, MA                                                                                                  2\n",
       "DELTA LEASING LLC     - NASHVILLE, TN                                                                                               2\n",
       "DELTA AIRLINES INC     - ATLANTA, GA                                                                                                2\n",
       "NEW TECH MARKETING INTERNATIONAL INC JOBSIGHT DELTA INC    - AURORA, IL                                                             1\n",
       "DELTA BRAVO LLC     - LAS VEGAS, NV                                                                                                 1\n",
       "Delta Southern Resource Leasing LLC                                                                                                 1\n",
       "DELTA SIERRA LLC     - FREMONT, NE                                                                                                  1\n",
       "Delta Rim Inc                                                                                                                       1\n",
       "Delta Gaston Beta LLC                                                                                                               1\n",
       "Delta Air lines                                                                                                                     1\n",
       "LOVE TO FLY AVIATION LLC DELTA-X AVIATION LLC NOLOGO AIR INC   - HEALDSBURG, CA                                                     1\n",
       "Delta Investment Group LLC                                                                                                          1\n",
       "Name: Op, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[16]: Delta Air Lines                                                                                                                 44568\nDelta Connection                                                                                                                18962\nDELTA AIR LINES INC     - ATLANTA, GA                                                                                           10176\nDelta Airlines                                                                                                                    462\nSkyWest Airlines (Delta Connection)                                                                                               210\nSkywest  Delta Connection                                                                                                         187\nSkywest Airlines (Delta Connection)                                                                                               176\nDELTA AIR LINES INC DEPT 595 AIRCRAFT REGISTRATIONS    - ATLANTA, GA                                                              146\nDelta Private Jets                                                                                                                 63\nDelta Air Lines (SkyTeam Livery)                                                                                                   49\nEndeavor Air (Delta Connection)                                                                                                    40\nDELTA AIR LINES INC     - ALLANTA, GA                                                                                              36\nDELTA AIR LINES INC DEPT 595 AIRCRAFT REGISTRATION    - ATLANTA, GA                                                                32\nEndeavor Air  Delta Connection                                                                                                     32\nSkyWest (Delta Connection)                                                                                                         29\nSkyWest Delta Connection                                                                                                           28\nDELTA AIRLINES INC DEPT 595 AIRCRAFT REGISTRATIONS    - ATLANTA, GA                                                                25\nDelta                                                                                                                              15\nDelta Connection (Endeavor Air)                                                                                                    14\nEndeavor Air   Delta Connection                                                                                                     9\nNETJETS SALES INC COMET I LLC TRINITY AIR LLC GILLIS STRATTON DELTA PEGASUS MANAGEMENT LLC COTTRILL LANCE- OKLAHOMA CITY, OK        9\nDELTA RIM INC     - GREENVILLE, MS                                                                                                  6\nDELTA AIR LINES     - ATLANTA, GA                                                                                                   5\nGoJet   Delta Connection                                                                                                            5\nCRAFTS LARRY Z     - DELTA, UT                                                                                                      5\nDelta Point LLC                                                                                                                     3\nDELTA JET LTD     - SOMERVILLE, MA                                                                                                  2\nDELTA LEASING LLC     - NASHVILLE, TN                                                                                               2\nDELTA AIRLINES INC     - ATLANTA, GA                                                                                                2\nNEW TECH MARKETING INTERNATIONAL INC JOBSIGHT DELTA INC    - AURORA, IL                                                             1\nDELTA BRAVO LLC     - LAS VEGAS, NV                                                                                                 1\nDelta Southern Resource Leasing LLC                                                                                                 1\nDELTA SIERRA LLC     - FREMONT, NE                                                                                                  1\nDelta Rim Inc                                                                                                                       1\nDelta Gaston Beta LLC                                                                                                               1\nDelta Air lines                                                                                                                     1\nLOVE TO FLY AVIATION LLC DELTA-X AVIATION LLC NOLOGO AIR INC   - HEALDSBURG, CA                                                     1\nDelta Investment Group LLC                                                                                                          1\nName: Op, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Delta \n",
    "dfpWeather2[dfpWeather2['Op'].str.upper().str.contains('DELTA')]['Op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8e3d12be-c778-4580-b380-46cd7a53e375",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "  self.obj[item] = s\n",
       "Out[17]: 537586</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/pandas/core/indexing.py:965: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self.obj[item] = s\nOut[17]: 537586</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Delta\n",
    "valid_delta = ['Delta Air Lines', 'DELTA AIR LINES INC     - ATLANTA, GA', 'Delta Airlines']\n",
    "\n",
    "condNotContainsDelta = ~(dfpWeather2['Op'].str.upper().str.contains('DELTA'))\n",
    "condContainsValidDelta = dfpWeather2[dfpWeather2['Op'].str.upper().str.contains('DELTA')]['Op'].isin(valid_delta)\n",
    "\n",
    "dfpWeather3 = dfpWeather2[condNotContainsDelta | condContainsValidDelta]\n",
    "\n",
    "# dfpWeather3['Op'] = dfpWeather3['Op'].apply(lambda x: 'Delta Air Lines' if 'DELTA' in x.upper() else x)\n",
    "dfpWeather3.loc[dfpWeather3['Op'].str.contains('delta', case=False), 'Op'] = 'Delta Air Lines'\n",
    "\n",
    "len(dfpWeather3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ecad0840-5aed-47a2-a373-cfa3d1fbd2a3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[18]: 1                                Frontier Airlines\n",
       "2                                Frontier Airlines\n",
       "3                                  Delta Air Lines\n",
       "4                                  JetBlue Airways\n",
       "5                                  Delta Air Lines\n",
       "                            ...                   \n",
       "557696                             JetBlue Airways\n",
       "557697                        Sun Country Airlines\n",
       "557698    AFS INVESTMENTS 57 LLC     - NORWALK, CT\n",
       "557699                             Spirit Airlines\n",
       "557700                             JetBlue Airways\n",
       "Name: Op, Length: 537586, dtype: object</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[18]: 1                                Frontier Airlines\n2                                Frontier Airlines\n3                                  Delta Air Lines\n4                                  JetBlue Airways\n5                                  Delta Air Lines\n                            ...                   \n557696                             JetBlue Airways\n557697                        Sun Country Airlines\n557698    AFS INVESTMENTS 57 LLC     - NORWALK, CT\n557699                             Spirit Airlines\n557700                             JetBlue Airways\nName: Op, Length: 537586, dtype: object</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather3['Op']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5f1fa572-d72f-4aa7-9700-ba995b67928a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[19]: Alaska Airlines                                       30003\n",
       "AIRCRAFT GUARANTY CORP TRUSTEE     - ONALASKA, TX       225\n",
       "ALASKA AIRLINES                                         173\n",
       "Alaskan Airlines                                         48\n",
       "Alaska Airlines (Salmon-Thirty-Salmon Livery)            45\n",
       "Alaska Airlines (75th Anniv Livery)                      42\n",
       "MIDWEST NATIONAL SERVICES INC     - ONALASKA, WI          7\n",
       "WORTHINGTON FORD OF ALASKA INC     - ANCHORAGE, AK        6\n",
       "ALASKA AVIATION TOXICOLOGY INC     - FAIRBANKS, AK        2\n",
       "MDSFEST INC     - ONALASKA, WI                            1\n",
       "Name: Op, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[19]: Alaska Airlines                                       30003\nAIRCRAFT GUARANTY CORP TRUSTEE     - ONALASKA, TX       225\nALASKA AIRLINES                                         173\nAlaskan Airlines                                         48\nAlaska Airlines (Salmon-Thirty-Salmon Livery)            45\nAlaska Airlines (75th Anniv Livery)                      42\nMIDWEST NATIONAL SERVICES INC     - ONALASKA, WI          7\nWORTHINGTON FORD OF ALASKA INC     - ANCHORAGE, AK        6\nALASKA AVIATION TOXICOLOGY INC     - FAIRBANKS, AK        2\nMDSFEST INC     - ONALASKA, WI                            1\nName: Op, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alaska: variants made up of only a very small fraction -> ignored\n",
    "dfpWeather3[dfpWeather3['Op'].str.upper().str.contains('ALASKA')]['Op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7c37a3bb-4cc2-48d9-a06d-9821007c1400",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[20]: 537037</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[20]: 537037</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Alaska\n",
    "valid_alaska = ['Alaska Airlines']\n",
    "\n",
    "condNotContainsAlaska = ~(dfpWeather3['Op'].str.contains('Alaska', case=False))\n",
    "condContainsValidAlaska = dfpWeather3[dfpWeather3['Op'].str.contains('Alaska', case=False)]['Op'].isin(valid_alaska)\n",
    "\n",
    "dfpWeather4 = dfpWeather3[condNotContainsAlaska | condContainsValidAlaska]\n",
    "# dfpWeather4.loc[dfpWeather4['Op'].str.contains('alaska', case=False), 'Op'] = 'Alaska Airlines'\n",
    "\n",
    "len(dfpWeather4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "564fb4d0-b9f8-496d-9e6e-95e998e0a09d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[21]: American Airlines                                                                                                                                                       76536\n",
       "American Eagle                                                                                                                                                          13320\n",
       "AMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                                                               7380\n",
       "American Eagle - Envoy Air                                                                                                                                               3354\n",
       "AMERICAN AIRLINES INC     - FT WORTH, TX                                                                                                                                  515\n",
       "Envoy Air (American Eagle)                                                                                                                                                260\n",
       "American Airlines (Piedmont Heritage Livery)                                                                                                                              129\n",
       "AMERICAN AIRCRAFT &amp; MARINE LLC     - INDIANAPOLIS, IN                                                                                                                      68\n",
       "AMERICAN ACADEMY HOLDINGS INC     - DOVER, DE                                                                                                                              48\n",
       "AMERICAN AIRLINES INC     - DFW AIRPORT, TX                                                                                                                                28\n",
       "American Airlines (OneWorld Livery)                                                                                                                                        28\n",
       "American Airpower Heritage Flying Museum                                                                                                                                   13\n",
       "NETJETS SALES INC AMERICAN WARRIOR INC SHAW INDUSTRIES INC STEVE PARRISH CONSULTING GROUP LLC RAITT JOHN R GOLDSTEIN GROUP INC- OKLAHOMA CITY, OK                           9\n",
       "AMERICAN AIRPOWER HERITAGE FLY MUSEU     - DALLAS, TX                                                                                                                       9\n",
       "AMERICAN AIRPOWER HERITAGE FLYING MUSEUM INC     - DALLAS, TX                                                                                                               7\n",
       "AMERICAN AIRPOWER HERITAGE FLYING MUSEUM     - DALLAS, TX                                                                                                                   7\n",
       "AMERICAN AVIATION INC     - SALT LAKE CITY, UT                                                                                                                              6\n",
       "AMERICAN EXPRESS TRAVEL RELATED SERVICE CO INC     - NEWBURGH, NY                                                                                                           6\n",
       "EQUITY AMERICAN FINANCIAL SERVICES INC HERDA LARISSA HERDA STEPHEN WELLS FARGO BANK NORTHWEST NA TRUSTEE GRINDSTONE MANAGEMENT LLC CROWN AVIATION INC- CLEVELAND, OH        4\n",
       "AMERICAN CAREER COLLEGE INC C &amp; A AVIATION LLC DARTBROOK PARTNERS LLC HASTAROTH LLC WEST COAST AVIATION SERVICES LLC WJL ENTERPRISES LLC- SANTA ANA, CA                     4\n",
       "NETJETS SALES INC BRAHMAN CAPITAL CORP CAMERON INTERNATIONAL CORP CLOVER AVIATION LLC TULLY DANIEL P EURO AMERICAN JETPLANE LLC- OKLAHOMA CITY, OK                          4\n",
       "AMERICAN INTERNATIONAL GROUP INC     - TETERBORO, NJ                                                                                                                        4\n",
       "AMERICAN LUBRICANTS &amp; CHEMICALS LLC     - MARIETTA, OH                                                                                                                      3\n",
       "Aerownership North American Services Inc                                                                                                                                    3\n",
       "NORTH AMERICAN FINANCIAL     - WOODBURN, OR                                                                                                                                 3\n",
       "Envoy Air (American Airlines)                                                                                                                                               3\n",
       "NATIVE AMERICAN AIR SERVICE INC     - ENGLEWOOD, CO                                                                                                                         3\n",
       "PSA Airlines (American Eagle)                                                                                                                                               3\n",
       "AMERICAN AIRPOWER HERITAGE FLY MUSM     - MIDLAND, TX                                                                                                                       2\n",
       "NETJETS SALES INC WEBBER DEVELOPMENT COMPANY LLC MICROSOFT FINANCING CORPORATION AMERICAN SECURITIES LLC MARQUIS JET HOLDINGS INC - OKLAHOMA CITY, OK                       2\n",
       "SIERRA AMERICAN CORP     - WILMINGTON, DE                                                                                                                                   2\n",
       "AMERICAN MINE RESEARCH INC     - ROCKY GAP, VA                                                                                                                              1\n",
       "American Aviation Inc                                                                                                                                                       1\n",
       "American International Group Inc                                                                                                                                            1\n",
       "AMERICAN AIRPLANE EXCHANGE DBA AMERICAN AIRCRAFT SALES    - SANTA ANA, CA                                                                                                   1\n",
       "NORTH AMERICAN AIR CHARTER CORP     - OSTERVILLE, MA                                                                                                                        1\n",
       "AMERICAN FAMILY MUTUAL INSURANCE CO     - MADISON, WI                                                                                                                       1\n",
       "AMERICAN BUILDERS &amp; CONTRACTORS SUPPLY CO INC     - BELOIT, WI                                                                                                              1\n",
       "AMERICAN AIRPOWER HERITAGE FLYING     - MIDLAND, TX                                                                                                                         1\n",
       "AMERICAN CAMPUS COMMUNITIES SERVICES INC     - AUSTIN, TX                                                                                                                   1\n",
       "American Jet International                                                                                                                                                  1\n",
       "AMERICAN AIR CHARTER INC     - BOCA RATON, FL                                                                                                                               1\n",
       "AMERICAN EQUITY INVESTMENT PROPERTIES LC     - WEST DES MOINES, IA                                                                                                          1\n",
       "American Electric Power Service Corp                                                                                                                                        1\n",
       "American Express Travel Co                                                                                                                                                  1\n",
       "Name: Op, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[21]: American Airlines                                                                                                                                                       76536\nAmerican Eagle                                                                                                                                                          13320\nAMERICAN AIRLINES INC     - FORT WORTH, TX                                                                                                                               7380\nAmerican Eagle - Envoy Air                                                                                                                                               3354\nAMERICAN AIRLINES INC     - FT WORTH, TX                                                                                                                                  515\nEnvoy Air (American Eagle)                                                                                                                                                260\nAmerican Airlines (Piedmont Heritage Livery)                                                                                                                              129\nAMERICAN AIRCRAFT &amp; MARINE LLC     - INDIANAPOLIS, IN                                                                                                                      68\nAMERICAN ACADEMY HOLDINGS INC     - DOVER, DE                                                                                                                              48\nAMERICAN AIRLINES INC     - DFW AIRPORT, TX                                                                                                                                28\nAmerican Airlines (OneWorld Livery)                                                                                                                                        28\nAmerican Airpower Heritage Flying Museum                                                                                                                                   13\nNETJETS SALES INC AMERICAN WARRIOR INC SHAW INDUSTRIES INC STEVE PARRISH CONSULTING GROUP LLC RAITT JOHN R GOLDSTEIN GROUP INC- OKLAHOMA CITY, OK                           9\nAMERICAN AIRPOWER HERITAGE FLY MUSEU     - DALLAS, TX                                                                                                                       9\nAMERICAN AIRPOWER HERITAGE FLYING MUSEUM INC     - DALLAS, TX                                                                                                               7\nAMERICAN AIRPOWER HERITAGE FLYING MUSEUM     - DALLAS, TX                                                                                                                   7\nAMERICAN AVIATION INC     - SALT LAKE CITY, UT                                                                                                                              6\nAMERICAN EXPRESS TRAVEL RELATED SERVICE CO INC     - NEWBURGH, NY                                                                                                           6\nEQUITY AMERICAN FINANCIAL SERVICES INC HERDA LARISSA HERDA STEPHEN WELLS FARGO BANK NORTHWEST NA TRUSTEE GRINDSTONE MANAGEMENT LLC CROWN AVIATION INC- CLEVELAND, OH        4\nAMERICAN CAREER COLLEGE INC C &amp; A AVIATION LLC DARTBROOK PARTNERS LLC HASTAROTH LLC WEST COAST AVIATION SERVICES LLC WJL ENTERPRISES LLC- SANTA ANA, CA                     4\nNETJETS SALES INC BRAHMAN CAPITAL CORP CAMERON INTERNATIONAL CORP CLOVER AVIATION LLC TULLY DANIEL P EURO AMERICAN JETPLANE LLC- OKLAHOMA CITY, OK                          4\nAMERICAN INTERNATIONAL GROUP INC     - TETERBORO, NJ                                                                                                                        4\nAMERICAN LUBRICANTS &amp; CHEMICALS LLC     - MARIETTA, OH                                                                                                                      3\nAerownership North American Services Inc                                                                                                                                    3\nNORTH AMERICAN FINANCIAL     - WOODBURN, OR                                                                                                                                 3\nEnvoy Air (American Airlines)                                                                                                                                               3\nNATIVE AMERICAN AIR SERVICE INC     - ENGLEWOOD, CO                                                                                                                         3\nPSA Airlines (American Eagle)                                                                                                                                               3\nAMERICAN AIRPOWER HERITAGE FLY MUSM     - MIDLAND, TX                                                                                                                       2\nNETJETS SALES INC WEBBER DEVELOPMENT COMPANY LLC MICROSOFT FINANCING CORPORATION AMERICAN SECURITIES LLC MARQUIS JET HOLDINGS INC - OKLAHOMA CITY, OK                       2\nSIERRA AMERICAN CORP     - WILMINGTON, DE                                                                                                                                   2\nAMERICAN MINE RESEARCH INC     - ROCKY GAP, VA                                                                                                                              1\nAmerican Aviation Inc                                                                                                                                                       1\nAmerican International Group Inc                                                                                                                                            1\nAMERICAN AIRPLANE EXCHANGE DBA AMERICAN AIRCRAFT SALES    - SANTA ANA, CA                                                                                                   1\nNORTH AMERICAN AIR CHARTER CORP     - OSTERVILLE, MA                                                                                                                        1\nAMERICAN FAMILY MUTUAL INSURANCE CO     - MADISON, WI                                                                                                                       1\nAMERICAN BUILDERS &amp; CONTRACTORS SUPPLY CO INC     - BELOIT, WI                                                                                                              1\nAMERICAN AIRPOWER HERITAGE FLYING     - MIDLAND, TX                                                                                                                         1\nAMERICAN CAMPUS COMMUNITIES SERVICES INC     - AUSTIN, TX                                                                                                                   1\nAmerican Jet International                                                                                                                                                  1\nAMERICAN AIR CHARTER INC     - BOCA RATON, FL                                                                                                                               1\nAMERICAN EQUITY INVESTMENT PROPERTIES LC     - WEST DES MOINES, IA                                                                                                          1\nAmerican Electric Power Service Corp                                                                                                                                        1\nAmerican Express Travel Co                                                                                                                                                  1\nName: Op, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# American\n",
    "dfpWeather4[dfpWeather4['Op'].str.contains('American', case=False)]['Op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fc85a1bb-2999-44ec-9750-af92b09cd799",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[22]: 519176</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[22]: 519176</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# American\n",
    "valid_american = ['American Airlines', 'AMERICAN AIRLINES INC     - FORT WORTH, TX']\n",
    "\n",
    "condNotContainsAmerican = ~(dfpWeather4['Op'].str.contains('American', case=False))\n",
    "condContainsValidAmerican = dfpWeather4[dfpWeather4['Op'].str.contains('American', case=False)]['Op'].isin(valid_american)\n",
    "\n",
    "dfpWeather5 = dfpWeather4[condNotContainsAmerican | condContainsValidAmerican]\n",
    "dfpWeather5.loc[dfpWeather5['Op'].str.contains('American', case=False), 'Op'] = 'American Airlines'\n",
    "\n",
    "len(dfpWeather5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b6486377-f691-4032-8e5a-693c9c224f7d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[23]: JetBlue Airways                                    18557\n",
       "JETBLUE AIRWAYS CORP     - LONG ISLAND CITY, NY      967\n",
       "JetBlue                                              171\n",
       "Name: Op, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[23]: JetBlue Airways                                    18557\nJETBLUE AIRWAYS CORP     - LONG ISLAND CITY, NY      967\nJetBlue                                              171\nName: Op, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# JetBlue: take all\n",
    "dfpWeather5[dfpWeather5['Op'].str.contains('JetBlue', case=False)]['Op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6f4a3129-fd7c-417c-9ae5-d37358541708",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[24]: 519176</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[24]: 519176</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# JetBlue\n",
    "dfpWeather5.loc[dfpWeather5['Op'].str.contains('JetBlue', case=False), 'Op'] = 'JetBlue Airways'\n",
    "\n",
    "len(dfpWeather5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5d33159c-02aa-4c1a-911b-a742dcb7aeec",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[25]: Southwest Airlines                                                                                                                             46648\n",
       "SOUTHWEST AIRLINES CO     - DALLAS, TX                                                                                                           608\n",
       "SouthWest Airlines                                                                                                                               228\n",
       "Southwest Airlines (Classic Gold Livery)                                                                                                          74\n",
       "Southwest Airlines (Tennessee One Livery)                                                                                                         64\n",
       "IMAGE AIR OF SOUTHWEST FLORIDA LLC     - BLOOMINGTON, IL                                                                                          61\n",
       "Southwest Airlines (Shark Week Livery)                                                                                                            55\n",
       "Southwest Airlines (Colorado One Livery)                                                                                                          46\n",
       "Southwest Airlines (New Mexico One Livery)                                                                                                        32\n",
       "Southwest Airlines (Nevada One Livery)                                                                                                            31\n",
       "Southwest Airlines (Illinois One Livery)                                                                                                          22\n",
       "SOUTHWEST GAS CORP     - LAS VEGAS, NV                                                                                                            16\n",
       "SOUTHWEST AVIATION SOLUTIONS LLC     - LAS VEGAS, NV                                                                                              16\n",
       "WELLS FARGO BANK NORTHWEST NA TRUSTEE EMPIRE SOUTHWEST LLC FIS INC HEXAGON INC HURON TRAVEL LLC LINDQUIST PROPERTIES LLC- OKLAHOMA CITY, OK       13\n",
       "Cutter Southwest Aircraft Sales LLC                                                                                                                8\n",
       "CUTTER SOUTHWEST AIRCRAFT SALES LLC     - PHOENIX, AZ                                                                                              7\n",
       "Southwest Aircraft Charter LC                                                                                                                      2\n",
       "CUTTER SOUTHWEST AIRCRFT SALES LLC     - PHOENIX, AZ                                                                                               2\n",
       "Southwest Aviation Specialities LLC                                                                                                                1\n",
       "SOUTHWEST AVIATION SPECIALTIES LLC     - TULSA, OK                                                                                                 1\n",
       "SOUTHWEST AIRCRAFT CHARTER LC     - MESA, AZ                                                                                                       1\n",
       "Name: Op, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[25]: Southwest Airlines                                                                                                                             46648\nSOUTHWEST AIRLINES CO     - DALLAS, TX                                                                                                           608\nSouthWest Airlines                                                                                                                               228\nSouthwest Airlines (Classic Gold Livery)                                                                                                          74\nSouthwest Airlines (Tennessee One Livery)                                                                                                         64\nIMAGE AIR OF SOUTHWEST FLORIDA LLC     - BLOOMINGTON, IL                                                                                          61\nSouthwest Airlines (Shark Week Livery)                                                                                                            55\nSouthwest Airlines (Colorado One Livery)                                                                                                          46\nSouthwest Airlines (New Mexico One Livery)                                                                                                        32\nSouthwest Airlines (Nevada One Livery)                                                                                                            31\nSouthwest Airlines (Illinois One Livery)                                                                                                          22\nSOUTHWEST GAS CORP     - LAS VEGAS, NV                                                                                                            16\nSOUTHWEST AVIATION SOLUTIONS LLC     - LAS VEGAS, NV                                                                                              16\nWELLS FARGO BANK NORTHWEST NA TRUSTEE EMPIRE SOUTHWEST LLC FIS INC HEXAGON INC HURON TRAVEL LLC LINDQUIST PROPERTIES LLC- OKLAHOMA CITY, OK       13\nCutter Southwest Aircraft Sales LLC                                                                                                                8\nCUTTER SOUTHWEST AIRCRAFT SALES LLC     - PHOENIX, AZ                                                                                              7\nSouthwest Aircraft Charter LC                                                                                                                      2\nCUTTER SOUTHWEST AIRCRFT SALES LLC     - PHOENIX, AZ                                                                                               2\nSouthwest Aviation Specialities LLC                                                                                                                1\nSOUTHWEST AVIATION SPECIALTIES LLC     - TULSA, OK                                                                                                 1\nSOUTHWEST AIRCRAFT CHARTER LC     - MESA, AZ                                                                                                       1\nName: Op, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Southwest: ignore all other variants\n",
    "dfpWeather5[dfpWeather5['Op'].str.contains('Southwest', case=False)]['Op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "54532d8d-bc41-4223-98a3-2135afc12f5d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[26]: 517888</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[26]: 517888</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Southwest\n",
    "valid_southwest = ['Southwest Airlines']\n",
    "\n",
    "condNotContainsSouthwest = ~(dfpWeather5['Op'].str.contains('Southwest', case=False))\n",
    "condContainsValidSouthwest = dfpWeather5[dfpWeather5['Op'].str.contains('Southwest', case=False)]['Op'].isin(valid_southwest)\n",
    "\n",
    "dfpWeather6 = dfpWeather5[condNotContainsSouthwest | condContainsValidSouthwest]\n",
    "dfpWeather6.loc[dfpWeather6['Op'].str.contains('Southwest', case=False), 'Op'] = 'Southwest Airlines'\n",
    "\n",
    "len(dfpWeather6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "da0a9873-2704-4eba-93b2-3f194268476c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[27]: United Airlines                                                                                                                                                             45766\n",
       "United Express                                                                                                                                                              11498\n",
       "United Parcel Service                                                                                                                                                        7142\n",
       "UNITED AIRLINES INC     - CHICAGO, IL                                                                                                                                        2222\n",
       "SkyWest Airlines (United Express)                                                                                                                                             181\n",
       "UNITED AIRLINES INC ATTN: TREASURER    - CHICAGO, IL                                                                                                                           68\n",
       "UNITED PARCEL SERVICE CO     - LOUISVILLE, KY                                                                                                                                  67\n",
       "UNITED FLYING CLUB INC     - BELMONT, CA                                                                                                                                       50\n",
       "United Airliens                                                                                                                                                                50\n",
       "United Express   CommutAir                                                                                                                                                     29\n",
       "United Express - GoJet                                                                                                                                                         13\n",
       "United Healthcare Services                                                                                                                                                      9\n",
       "United States Dept of Commerce (NOAA)                                                                                                                                           6\n",
       "United Group Aviation LLC                                                                                                                                                       4\n",
       "UNITED STATES DEPARTMENT OF COMMERCE     - MCADILL AFB, FL                                                                                                                      3\n",
       "NETJETS SALES INC HUNT AVIATION SERVICES LLC UNITED DISTRIBUTORS INC STEERS ROBERT H 3JC CORP CAC ENTERPRISES LLC- OKLAHOMA CITY, OK                                            3\n",
       "UNITED TECHNOLOGIES CORP     - HARTFORD, CT                                                                                                                                     3\n",
       "UNITED SERVICES AUTOMOBLIE ASSOCIATION                                                                                                                                          2\n",
       "UNITED HEALTHCARE SERVICES INC     - LATROBE, PA                                                                                                                                1\n",
       "United States Department of Interior                                                                                                                                            1\n",
       "United States Marshals Service                                                                                                                                                  1\n",
       "PEOPLES UNITED BANK AFFILIATED MANAGERS GROUP INC KAPLAN ROBERT S MURRAY STEPHEN B DBA MURRAY LAW FIRM ZIFF BROTHERS INVESTMENTS LLC 1530 MANAGEMENT LLC- PORTSMOUTH, NH        1\n",
       "EXECUTIVE AIRSHARE CORP UNITED STATES BEEF CORP ALLRED AIRCRAFT LLC JONES DEVELOPMENT CO LLC JACKSON AIRCRAFT LLC - WICHITA, KS                                                 1\n",
       "UNITED STATES AIR FORCE OWNER PETERSON AERO CLUB - OPERATOR    - COLORADO SPRINGS, CO                                                                                           1\n",
       "UNITED AERONAUTICAL CORP     - NORTH HOLLYWOOD, CA                                                                                                                              1\n",
       "UNITED GROUP AVIATION LLC     - MIAMI GARDENS, FL                                                                                                                               1\n",
       "UNITED HEALTHCARE SERVICES INC     - SAINT PAUL, MN                                                                                                                             1\n",
       "Name: Op, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[27]: United Airlines                                                                                                                                                             45766\nUnited Express                                                                                                                                                              11498\nUnited Parcel Service                                                                                                                                                        7142\nUNITED AIRLINES INC     - CHICAGO, IL                                                                                                                                        2222\nSkyWest Airlines (United Express)                                                                                                                                             181\nUNITED AIRLINES INC ATTN: TREASURER    - CHICAGO, IL                                                                                                                           68\nUNITED PARCEL SERVICE CO     - LOUISVILLE, KY                                                                                                                                  67\nUNITED FLYING CLUB INC     - BELMONT, CA                                                                                                                                       50\nUnited Airliens                                                                                                                                                                50\nUnited Express   CommutAir                                                                                                                                                     29\nUnited Express - GoJet                                                                                                                                                         13\nUnited Healthcare Services                                                                                                                                                      9\nUnited States Dept of Commerce (NOAA)                                                                                                                                           6\nUnited Group Aviation LLC                                                                                                                                                       4\nUNITED STATES DEPARTMENT OF COMMERCE     - MCADILL AFB, FL                                                                                                                      3\nNETJETS SALES INC HUNT AVIATION SERVICES LLC UNITED DISTRIBUTORS INC STEERS ROBERT H 3JC CORP CAC ENTERPRISES LLC- OKLAHOMA CITY, OK                                            3\nUNITED TECHNOLOGIES CORP     - HARTFORD, CT                                                                                                                                     3\nUNITED SERVICES AUTOMOBLIE ASSOCIATION                                                                                                                                          2\nUNITED HEALTHCARE SERVICES INC     - LATROBE, PA                                                                                                                                1\nUnited States Department of Interior                                                                                                                                            1\nUnited States Marshals Service                                                                                                                                                  1\nPEOPLES UNITED BANK AFFILIATED MANAGERS GROUP INC KAPLAN ROBERT S MURRAY STEPHEN B DBA MURRAY LAW FIRM ZIFF BROTHERS INVESTMENTS LLC 1530 MANAGEMENT LLC- PORTSMOUTH, NH        1\nEXECUTIVE AIRSHARE CORP UNITED STATES BEEF CORP ALLRED AIRCRAFT LLC JONES DEVELOPMENT CO LLC JACKSON AIRCRAFT LLC - WICHITA, KS                                                 1\nUNITED STATES AIR FORCE OWNER PETERSON AERO CLUB - OPERATOR    - COLORADO SPRINGS, CO                                                                                           1\nUNITED AERONAUTICAL CORP     - NORTH HOLLYWOOD, CA                                                                                                                              1\nUNITED GROUP AVIATION LLC     - MIAMI GARDENS, FL                                                                                                                               1\nUNITED HEALTHCARE SERVICES INC     - SAINT PAUL, MN                                                                                                                             1\nName: Op, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# United: ignore all other variants\n",
    "dfpWeather6[dfpWeather6['Op'].str.contains('United', case=False)]['Op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2baeadf0-1c74-40ce-bd43-f82b1b3ce43d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[28]: 498751</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[28]: 498751</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# United\n",
    "valid_united = ['United Airlines', 'UNITED AIRLINES INC     - CHICAGO, IL']\n",
    "\n",
    "condNotContainsUnited = ~(dfpWeather6['Op'].str.contains('United', case=False))\n",
    "condContainsValidUnited = dfpWeather6[dfpWeather6['Op'].str.contains('United', case=False)]['Op'].isin(valid_united)\n",
    "\n",
    "dfpWeather7 = dfpWeather6[condNotContainsUnited | condContainsValidUnited]\n",
    "dfpWeather7.loc[dfpWeather7['Op'].str.contains('United', case=False), 'Op'] = 'United Airlines'\n",
    "\n",
    "len(dfpWeather7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d744af28-010d-4dea-8b42-1f4233b1b74a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[29]: 283456</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[29]: 283456</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "airlines = ['American Airlines', 'Delta Air Lines', 'United Airlines', 'Southwest Airlines', 'Alaska Airlines', 'JetBlue Airways']\n",
    "\n",
    "dfpWeather8 = dfpWeather7[dfpWeather7['Op'].isin(airlines)]\n",
    "len(dfpWeather8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "63300fb1-8fbc-401f-ad66-a6256b840493",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[30]: American Airlines     83916\n",
       "Delta Air Lines       55206\n",
       "United Airlines       47988\n",
       "Southwest Airlines    46648\n",
       "Alaska Airlines       30003\n",
       "JetBlue Airways       19695\n",
       "Name: Op, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[30]: American Airlines     83916\nDelta Air Lines       55206\nUnited Airlines       47988\nSouthwest Airlines    46648\nAlaska Airlines       30003\nJetBlue Airways       19695\nName: Op, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather8['Op'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9e7871d3-57ad-469c-a7cb-aafa20084e80",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[39]: LAX    29411\n",
       "PHX    25887\n",
       "DEN    23493\n",
       "SFO    23443\n",
       "LAS    23042\n",
       "SLC    22029\n",
       "DFW    21337\n",
       "SEA    21213\n",
       "ORD    17181\n",
       "PHL    13725\n",
       "JFK    11341\n",
       "LGA    10308\n",
       "EWR     9401\n",
       "MSP     6301\n",
       "MCO     5767\n",
       "BOS     5194\n",
       "TPA     3928\n",
       "PDX     3800\n",
       "MIA     2180\n",
       "IAD     1998\n",
       "FLL      759\n",
       "MDW      641\n",
       "CLT      635\n",
       "ATL      353\n",
       "DTW       47\n",
       "IAH       42\n",
       "Name: From, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[39]: LAX    29411\nPHX    25887\nDEN    23493\nSFO    23443\nLAS    23042\nSLC    22029\nDFW    21337\nSEA    21213\nORD    17181\nPHL    13725\nJFK    11341\nLGA    10308\nEWR     9401\nMSP     6301\nMCO     5767\nBOS     5194\nTPA     3928\nPDX     3800\nMIA     2180\nIAD     1998\nFLL      759\nMDW      641\nCLT      635\nATL      353\nDTW       47\nIAH       42\nName: From, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather8['From'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a5398975-3a7a-48be-86ec-4dd899b0691b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[35]: 283456</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[35]: 283456</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(dfpWeather8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "229d4d2c-18b3-495d-9a8f-c49fd22374fb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Thanksgiving days: [&#39;2020-11-30&#39;, &#39;2020-11-29&#39;, &#39;2020-11-28&#39;, &#39;2020-11-27&#39;, &#39;2020-11-26&#39;, &#39;2020-11-25&#39;, &#39;2020-11-24&#39;, &#39;2019-11-30&#39;, &#39;2019-11-29&#39;, &#39;2019-11-28&#39;, &#39;2019-11-27&#39;, &#39;2019-11-26&#39;, &#39;2019-11-25&#39;, &#39;2019-11-24&#39;, &#39;2018-11-30&#39;, &#39;2018-11-29&#39;, &#39;2018-11-28&#39;, &#39;2018-11-27&#39;, &#39;2018-11-26&#39;, &#39;2018-11-25&#39;, &#39;2018-11-24&#39;]\n",
       "Christmas days: [&#39;2020-12-31&#39;, &#39;2020-12-30&#39;, &#39;2020-12-29&#39;, &#39;2020-12-28&#39;, &#39;2020-12-27&#39;, &#39;2020-12-26&#39;, &#39;2020-12-25&#39;, &#39;2020-12-24&#39;, &#39;2020-12-23&#39;, &#39;2020-12-22&#39;, &#39;2020-12-21&#39;, &#39;2020-12-20&#39;, &#39;2020-12-19&#39;, &#39;2020-12-18&#39;, &#39;2019-12-31&#39;, &#39;2019-12-30&#39;, &#39;2019-12-29&#39;, &#39;2019-12-28&#39;, &#39;2019-12-27&#39;, &#39;2019-12-26&#39;, &#39;2019-12-25&#39;, &#39;2019-12-24&#39;, &#39;2019-12-23&#39;, &#39;2019-12-22&#39;, &#39;2019-12-21&#39;, &#39;2019-12-20&#39;, &#39;2019-12-19&#39;, &#39;2019-12-18&#39;, &#39;2018-12-31&#39;, &#39;2018-12-30&#39;, &#39;2018-12-29&#39;, &#39;2018-12-28&#39;, &#39;2018-12-27&#39;, &#39;2018-12-26&#39;, &#39;2018-12-25&#39;, &#39;2018-12-24&#39;, &#39;2018-12-23&#39;, &#39;2018-12-22&#39;, &#39;2018-12-21&#39;, &#39;2018-12-20&#39;, &#39;2018-12-19&#39;, &#39;2018-12-18&#39;]\n",
       "/local_disk0/tmp/1615587451351-0/PythonShell.py:17: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "  import matplotlib as mpl\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Thanksgiving days: [&#39;2020-11-30&#39;, &#39;2020-11-29&#39;, &#39;2020-11-28&#39;, &#39;2020-11-27&#39;, &#39;2020-11-26&#39;, &#39;2020-11-25&#39;, &#39;2020-11-24&#39;, &#39;2019-11-30&#39;, &#39;2019-11-29&#39;, &#39;2019-11-28&#39;, &#39;2019-11-27&#39;, &#39;2019-11-26&#39;, &#39;2019-11-25&#39;, &#39;2019-11-24&#39;, &#39;2018-11-30&#39;, &#39;2018-11-29&#39;, &#39;2018-11-28&#39;, &#39;2018-11-27&#39;, &#39;2018-11-26&#39;, &#39;2018-11-25&#39;, &#39;2018-11-24&#39;]\nChristmas days: [&#39;2020-12-31&#39;, &#39;2020-12-30&#39;, &#39;2020-12-29&#39;, &#39;2020-12-28&#39;, &#39;2020-12-27&#39;, &#39;2020-12-26&#39;, &#39;2020-12-25&#39;, &#39;2020-12-24&#39;, &#39;2020-12-23&#39;, &#39;2020-12-22&#39;, &#39;2020-12-21&#39;, &#39;2020-12-20&#39;, &#39;2020-12-19&#39;, &#39;2020-12-18&#39;, &#39;2019-12-31&#39;, &#39;2019-12-30&#39;, &#39;2019-12-29&#39;, &#39;2019-12-28&#39;, &#39;2019-12-27&#39;, &#39;2019-12-26&#39;, &#39;2019-12-25&#39;, &#39;2019-12-24&#39;, &#39;2019-12-23&#39;, &#39;2019-12-22&#39;, &#39;2019-12-21&#39;, &#39;2019-12-20&#39;, &#39;2019-12-19&#39;, &#39;2019-12-18&#39;, &#39;2018-12-31&#39;, &#39;2018-12-30&#39;, &#39;2018-12-29&#39;, &#39;2018-12-28&#39;, &#39;2018-12-27&#39;, &#39;2018-12-26&#39;, &#39;2018-12-25&#39;, &#39;2018-12-24&#39;, &#39;2018-12-23&#39;, &#39;2018-12-22&#39;, &#39;2018-12-21&#39;, &#39;2018-12-20&#39;, &#39;2018-12-19&#39;, &#39;2018-12-18&#39;]\n/local_disk0/tmp/1615587451351-0/PythonShell.py:17: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  import matplotlib as mpl\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "thanksgiving_days = [str(year) + '-11-' + str(day) for year in [2020, 2019, 2018] for day in range(30, 30-7, -1)]\n",
    "\n",
    "print(f'Thanksgiving days: {thanksgiving_days}')\n",
    "\n",
    "christmas_days = [str(year) + '-12-' + str(day) for year in [2020, 2019, 2018] for day in range(31, 31-14, -1)]\n",
    "\n",
    "print(f'Christmas days: {christmas_days}')\n",
    "\n",
    "def day_type(day):\n",
    "  if day in thanksgiving_days:\n",
    "    return 'Thanksgiving'\n",
    "  elif day in christmas_days:\n",
    "    return 'Christmas'\n",
    "  else:\n",
    "    return 'Regular'\n",
    "\n",
    "dfpWeather8['DayType'] = dfpWeather8['StartTime'].apply(lambda x: day_type(x.strftime('%Y-%m-%d')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "845a31b2-18d4-47d6-a381-43fa4970239c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[56]: Regular         210559\n",
       "Christmas        51346\n",
       "Thanksgiving     21551\n",
       "Name: DayType, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[56]: Regular         210559\nChristmas        51346\nThanksgiving     21551\nName: DayType, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather8['DayType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "893a28f8-255a-4bd0-b802-9ebc8c4cc327",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[57]: Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;],\n",
       "      dtype=&#39;object&#39;)</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[57]: Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;],\n      dtype=&#39;object&#39;)</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather8.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0d6092c6-6a3c-4271-82bc-e976144dcf52",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[49]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[49]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Icao</th>\n",
       "      <th>To</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LiftOffTime</th>\n",
       "      <th>TouchDownTime</th>\n",
       "      <th>StopTime</th>\n",
       "      <th>FromLat</th>\n",
       "      <th>FromLong</th>\n",
       "      <th>ToLat</th>\n",
       "      <th>ToLong</th>\n",
       "      <th>RunwayWaitTimeInSeconds</th>\n",
       "      <th>OtherDepartures</th>\n",
       "      <th>FlightDuration</th>\n",
       "      <th>From_ATL</th>\n",
       "      <th>From_BOS</th>\n",
       "      <th>From_CLT</th>\n",
       "      <th>From_DEN</th>\n",
       "      <th>From_DFW</th>\n",
       "      <th>From_DTW</th>\n",
       "      <th>From_EWR</th>\n",
       "      <th>From_FLL</th>\n",
       "      <th>From_IAD</th>\n",
       "      <th>From_IAH</th>\n",
       "      <th>From_JFK</th>\n",
       "      <th>From_LAS</th>\n",
       "      <th>From_LAX</th>\n",
       "      <th>From_LGA</th>\n",
       "      <th>From_MCO</th>\n",
       "      <th>From_MDW</th>\n",
       "      <th>From_MIA</th>\n",
       "      <th>From_MSP</th>\n",
       "      <th>From_ORD</th>\n",
       "      <th>From_PDX</th>\n",
       "      <th>From_PHL</th>\n",
       "      <th>From_PHX</th>\n",
       "      <th>From_SEA</th>\n",
       "      <th>From_SFO</th>\n",
       "      <th>From_SLC</th>\n",
       "      <th>From_TPA</th>\n",
       "      <th>Op_Alaska Airlines</th>\n",
       "      <th>Op_American Airlines</th>\n",
       "      <th>Op_Delta Air Lines</th>\n",
       "      <th>Op_JetBlue Airways</th>\n",
       "      <th>Op_Southwest Airlines</th>\n",
       "      <th>Op_United Airlines</th>\n",
       "      <th>DayType_Christmas</th>\n",
       "      <th>DayType_Regular</th>\n",
       "      <th>DayType_Thanksgiving</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABC573</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2019-12-24 00:06:22.204</td>\n",
       "      <td>2019-12-24 02:09:21.282</td>\n",
       "      <td>2019-12-24 06:46:17.404</td>\n",
       "      <td>2019-12-24 06:48:36.247</td>\n",
       "      <td>33.644024</td>\n",
       "      <td>-84.422336</td>\n",
       "      <td>37.621674</td>\n",
       "      <td>-122.376037</td>\n",
       "      <td>7379</td>\n",
       "      <td>1</td>\n",
       "      <td>16616</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A13B66</td>\n",
       "      <td>WAL</td>\n",
       "      <td>2019-12-24 00:34:21.210</td>\n",
       "      <td>2019-12-24 16:30:21.212</td>\n",
       "      <td>2019-12-24 17:47:38.693</td>\n",
       "      <td>2019-12-24 17:49:17.903</td>\n",
       "      <td>33.635777</td>\n",
       "      <td>-84.416773</td>\n",
       "      <td>38.068139</td>\n",
       "      <td>-75.513452</td>\n",
       "      <td>57360</td>\n",
       "      <td>1</td>\n",
       "      <td>4637</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A44D3F</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2020-10-19 01:13:53.937</td>\n",
       "      <td>2020-10-19 01:15:59.356</td>\n",
       "      <td>2020-10-19 03:05:43.827</td>\n",
       "      <td>2020-10-19 03:08:58.907</td>\n",
       "      <td>33.645816</td>\n",
       "      <td>-84.438171</td>\n",
       "      <td>35.390885</td>\n",
       "      <td>-97.588952</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>6584</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A3F133</td>\n",
       "      <td>GRR</td>\n",
       "      <td>2020-10-19 11:39:27.973</td>\n",
       "      <td>2020-10-19 13:13:43.158</td>\n",
       "      <td>2020-10-19 14:38:29.470</td>\n",
       "      <td>2020-10-19 16:07:09.267</td>\n",
       "      <td>33.641743</td>\n",
       "      <td>-84.438772</td>\n",
       "      <td>42.879295</td>\n",
       "      <td>-85.521379</td>\n",
       "      <td>5656</td>\n",
       "      <td>2</td>\n",
       "      <td>5086</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A260ED</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2020-10-19 12:05:21.766</td>\n",
       "      <td>2020-10-19 12:07:13.023</td>\n",
       "      <td>2020-10-19 13:59:24.776</td>\n",
       "      <td>2020-10-19 17:31:00.279</td>\n",
       "      <td>33.645412</td>\n",
       "      <td>-84.437331</td>\n",
       "      <td>29.643860</td>\n",
       "      <td>-95.272091</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>6731</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557691</th>\n",
       "      <td>AA9AB6</td>\n",
       "      <td>TPA</td>\n",
       "      <td>2020-12-29 18:31:43.577</td>\n",
       "      <td>2020-12-29 18:37:14.022</td>\n",
       "      <td>2020-12-29 21:57:59.401</td>\n",
       "      <td>2020-12-29 23:27:00.774</td>\n",
       "      <td>27.984075</td>\n",
       "      <td>-82.531007</td>\n",
       "      <td>27.980095</td>\n",
       "      <td>-82.541818</td>\n",
       "      <td>331</td>\n",
       "      <td>4</td>\n",
       "      <td>12045</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557692</th>\n",
       "      <td>ABE124</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2020-12-29 16:28:06.785</td>\n",
       "      <td>2020-12-29 16:35:30.432</td>\n",
       "      <td>2020-12-29 20:42:59.568</td>\n",
       "      <td>2020-12-29 23:55:23.300</td>\n",
       "      <td>27.984089</td>\n",
       "      <td>-82.531251</td>\n",
       "      <td>32.843685</td>\n",
       "      <td>-96.854768</td>\n",
       "      <td>444</td>\n",
       "      <td>7</td>\n",
       "      <td>14849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557694</th>\n",
       "      <td>ABC40D</td>\n",
       "      <td>BWI</td>\n",
       "      <td>2020-12-29 13:51:14.460</td>\n",
       "      <td>2020-12-29 15:07:14.934</td>\n",
       "      <td>2020-12-29 16:57:59.692</td>\n",
       "      <td>2020-12-29 16:59:30.256</td>\n",
       "      <td>27.984680</td>\n",
       "      <td>-82.531693</td>\n",
       "      <td>39.179166</td>\n",
       "      <td>-76.674500</td>\n",
       "      <td>4560</td>\n",
       "      <td>7</td>\n",
       "      <td>6645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557696</th>\n",
       "      <td>A1A3A9</td>\n",
       "      <td>JFK</td>\n",
       "      <td>2020-12-29 15:08:59.389</td>\n",
       "      <td>2020-12-29 17:31:13.621</td>\n",
       "      <td>2020-12-29 19:41:43.771</td>\n",
       "      <td>2020-12-29 23:07:14.487</td>\n",
       "      <td>27.976089</td>\n",
       "      <td>-82.531740</td>\n",
       "      <td>40.651634</td>\n",
       "      <td>-73.779663</td>\n",
       "      <td>8534</td>\n",
       "      <td>11</td>\n",
       "      <td>7830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557700</th>\n",
       "      <td>A6A3C2</td>\n",
       "      <td>EWR</td>\n",
       "      <td>2020-12-29 03:05:14.370</td>\n",
       "      <td>2020-12-29 13:04:58.720</td>\n",
       "      <td>2020-12-29 15:10:13.448</td>\n",
       "      <td>2020-12-29 15:17:14.513</td>\n",
       "      <td>27.976879</td>\n",
       "      <td>-82.531621</td>\n",
       "      <td>40.697188</td>\n",
       "      <td>-74.163036</td>\n",
       "      <td>35984</td>\n",
       "      <td>4</td>\n",
       "      <td>7515</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>283456 rows  48 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Icao</th>\n      <th>To</th>\n      <th>StartTime</th>\n      <th>LiftOffTime</th>\n      <th>TouchDownTime</th>\n      <th>StopTime</th>\n      <th>FromLat</th>\n      <th>FromLong</th>\n      <th>ToLat</th>\n      <th>ToLong</th>\n      <th>RunwayWaitTimeInSeconds</th>\n      <th>OtherDepartures</th>\n      <th>FlightDuration</th>\n      <th>From_ATL</th>\n      <th>From_BOS</th>\n      <th>From_CLT</th>\n      <th>From_DEN</th>\n      <th>From_DFW</th>\n      <th>From_DTW</th>\n      <th>From_EWR</th>\n      <th>From_FLL</th>\n      <th>From_IAD</th>\n      <th>From_IAH</th>\n      <th>From_JFK</th>\n      <th>From_LAS</th>\n      <th>From_LAX</th>\n      <th>From_LGA</th>\n      <th>From_MCO</th>\n      <th>From_MDW</th>\n      <th>From_MIA</th>\n      <th>From_MSP</th>\n      <th>From_ORD</th>\n      <th>From_PDX</th>\n      <th>From_PHL</th>\n      <th>From_PHX</th>\n      <th>From_SEA</th>\n      <th>From_SFO</th>\n      <th>From_SLC</th>\n      <th>From_TPA</th>\n      <th>Op_Alaska Airlines</th>\n      <th>Op_American Airlines</th>\n      <th>Op_Delta Air Lines</th>\n      <th>Op_JetBlue Airways</th>\n      <th>Op_Southwest Airlines</th>\n      <th>Op_United Airlines</th>\n      <th>DayType_Christmas</th>\n      <th>DayType_Regular</th>\n      <th>DayType_Thanksgiving</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>ABC573</td>\n      <td>SFO</td>\n      <td>2019-12-24 00:06:22.204</td>\n      <td>2019-12-24 02:09:21.282</td>\n      <td>2019-12-24 06:46:17.404</td>\n      <td>2019-12-24 06:48:36.247</td>\n      <td>33.644024</td>\n      <td>-84.422336</td>\n      <td>37.621674</td>\n      <td>-122.376037</td>\n      <td>7379</td>\n      <td>1</td>\n      <td>16616</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>A13B66</td>\n      <td>WAL</td>\n      <td>2019-12-24 00:34:21.210</td>\n      <td>2019-12-24 16:30:21.212</td>\n      <td>2019-12-24 17:47:38.693</td>\n      <td>2019-12-24 17:49:17.903</td>\n      <td>33.635777</td>\n      <td>-84.416773</td>\n      <td>38.068139</td>\n      <td>-75.513452</td>\n      <td>57360</td>\n      <td>1</td>\n      <td>4637</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>A44D3F</td>\n      <td>OKC</td>\n      <td>2020-10-19 01:13:53.937</td>\n      <td>2020-10-19 01:15:59.356</td>\n      <td>2020-10-19 03:05:43.827</td>\n      <td>2020-10-19 03:08:58.907</td>\n      <td>33.645816</td>\n      <td>-84.438171</td>\n      <td>35.390885</td>\n      <td>-97.588952</td>\n      <td>126</td>\n      <td>0</td>\n      <td>6584</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>A3F133</td>\n      <td>GRR</td>\n      <td>2020-10-19 11:39:27.973</td>\n      <td>2020-10-19 13:13:43.158</td>\n      <td>2020-10-19 14:38:29.470</td>\n      <td>2020-10-19 16:07:09.267</td>\n      <td>33.641743</td>\n      <td>-84.438772</td>\n      <td>42.879295</td>\n      <td>-85.521379</td>\n      <td>5656</td>\n      <td>2</td>\n      <td>5086</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>A260ED</td>\n      <td>HOU</td>\n      <td>2020-10-19 12:05:21.766</td>\n      <td>2020-10-19 12:07:13.023</td>\n      <td>2020-10-19 13:59:24.776</td>\n      <td>2020-10-19 17:31:00.279</td>\n      <td>33.645412</td>\n      <td>-84.437331</td>\n      <td>29.643860</td>\n      <td>-95.272091</td>\n      <td>112</td>\n      <td>3</td>\n      <td>6731</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>557691</th>\n      <td>AA9AB6</td>\n      <td>TPA</td>\n      <td>2020-12-29 18:31:43.577</td>\n      <td>2020-12-29 18:37:14.022</td>\n      <td>2020-12-29 21:57:59.401</td>\n      <td>2020-12-29 23:27:00.774</td>\n      <td>27.984075</td>\n      <td>-82.531007</td>\n      <td>27.980095</td>\n      <td>-82.541818</td>\n      <td>331</td>\n      <td>4</td>\n      <td>12045</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>557692</th>\n      <td>ABE124</td>\n      <td>DAL</td>\n      <td>2020-12-29 16:28:06.785</td>\n      <td>2020-12-29 16:35:30.432</td>\n      <td>2020-12-29 20:42:59.568</td>\n      <td>2020-12-29 23:55:23.300</td>\n      <td>27.984089</td>\n      <td>-82.531251</td>\n      <td>32.843685</td>\n      <td>-96.854768</td>\n      <td>444</td>\n      <td>7</td>\n      <td>14849</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>557694</th>\n      <td>ABC40D</td>\n      <td>BWI</td>\n      <td>2020-12-29 13:51:14.460</td>\n      <td>2020-12-29 15:07:14.934</td>\n      <td>2020-12-29 16:57:59.692</td>\n      <td>2020-12-29 16:59:30.256</td>\n      <td>27.984680</td>\n      <td>-82.531693</td>\n      <td>39.179166</td>\n      <td>-76.674500</td>\n      <td>4560</td>\n      <td>7</td>\n      <td>6645</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>557696</th>\n      <td>A1A3A9</td>\n      <td>JFK</td>\n      <td>2020-12-29 15:08:59.389</td>\n      <td>2020-12-29 17:31:13.621</td>\n      <td>2020-12-29 19:41:43.771</td>\n      <td>2020-12-29 23:07:14.487</td>\n      <td>27.976089</td>\n      <td>-82.531740</td>\n      <td>40.651634</td>\n      <td>-73.779663</td>\n      <td>8534</td>\n      <td>11</td>\n      <td>7830</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>557700</th>\n      <td>A6A3C2</td>\n      <td>EWR</td>\n      <td>2020-12-29 03:05:14.370</td>\n      <td>2020-12-29 13:04:58.720</td>\n      <td>2020-12-29 15:10:13.448</td>\n      <td>2020-12-29 15:17:14.513</td>\n      <td>27.976879</td>\n      <td>-82.531621</td>\n      <td>40.697188</td>\n      <td>-74.163036</td>\n      <td>35984</td>\n      <td>4</td>\n      <td>7515</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>283456 rows  48 columns</p>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for dummy variables, Do this as the veryy last step\n",
    "# pd.get_dummies(data=dfpWeather8, columns=['From', 'Op', 'DayType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0e83ee98-2ee4-4b04-95eb-4d7a211a8960",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "bytes_to_write = dfpWeather8.to_csv(None, sep='|', index=False).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open('s3://<BUCKET_NAME>/flights-csv/full-data/full-data-280k.csv', 'wb') as f:\n",
    "    f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "402a308d-899c-40a5-b9da-2e3789d3581c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[32]: 79623</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[32]: 79623</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dfpWeather9 = dfpWeather8[dfpWeather8['From'].isin(['LAX', 'ATL', 'ORD', 'DFW', 'JFK'])]\n",
    "# len(dfpWeather9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "331c964c-87c8-41a9-b176-c1edf3fc80ad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[53]: LAX    29411\n",
       "PHX    25887\n",
       "DEN    23493\n",
       "SFO    23443\n",
       "LAS    23042\n",
       "SLC    22029\n",
       "DFW    21337\n",
       "SEA    21213\n",
       "ORD    17181\n",
       "PHL    13725\n",
       "JFK    11341\n",
       "LGA    10308\n",
       "EWR     9401\n",
       "MSP     6301\n",
       "MCO     5767\n",
       "BOS     5194\n",
       "TPA     3928\n",
       "PDX     3800\n",
       "MIA     2180\n",
       "IAD     1998\n",
       "FLL      759\n",
       "MDW      641\n",
       "CLT      635\n",
       "ATL      353\n",
       "DTW       47\n",
       "IAH       42\n",
       "Name: From, dtype: int64</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[53]: LAX    29411\nPHX    25887\nDEN    23493\nSFO    23443\nLAS    23042\nSLC    22029\nDFW    21337\nSEA    21213\nORD    17181\nPHL    13725\nJFK    11341\nLGA    10308\nEWR     9401\nMSP     6301\nMCO     5767\nBOS     5194\nTPA     3928\nPDX     3800\nMIA     2180\nIAD     1998\nFLL      759\nMDW      641\nCLT      635\nATL      353\nDTW       47\nIAH       42\nName: From, dtype: int64</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather8['From'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5492f750-4e50-4d39-8be6-bd9ff60959a1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "Processed: \n",
    "\n",
    "Unprocessed: \n",
    "\n",
    "\n",
    "Priority: 'LAX', 'ATL', 'ORD', 'DFW', 'JFK'\n",
    "\n",
    "Remaining:\n",
    "\n",
    "LAX    29411\n",
    "\n",
    "SLC    22029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "af1eb943-d131-4c6e-bf4e-92eeafb41324",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&gt;\n",
       "283456\n",
       "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "283456\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&gt;\n283456\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n283456\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pandas(dfSpark):\n",
    "  # Enable Arrow-based columnar data transfers\n",
    "  spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "\n",
    "  # Convert the Spark DataFrame to a Pandas DataFrame using Arrow\n",
    "  return dfSpark.toPandas()\n",
    "\n",
    "\n",
    "dfWeather8 = spark.read.options(delimiter='|', inferSchema='True', header='True')\\\n",
    "                      .csv('s3://<BUCKET_NAME>/flights-csv/full-data/full-data-280k.csv')\n",
    "print(type(dfWeather8))\n",
    "print(dfWeather8.count())\n",
    "dfpWeather8 = pandas(dfWeather8)\n",
    "print(type(dfpWeather8))\n",
    "print(len(dfpWeather8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "85118c6f-363d-4784-93e8-960d90cd77cc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[9]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[9]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Icao</th>\n",
       "      <th>Op</th>\n",
       "      <th>To</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LiftOffTime</th>\n",
       "      <th>TouchDownTime</th>\n",
       "      <th>StopTime</th>\n",
       "      <th>FromLat</th>\n",
       "      <th>FromLong</th>\n",
       "      <th>ToLat</th>\n",
       "      <th>ToLong</th>\n",
       "      <th>RunwayWaitTimeInSeconds</th>\n",
       "      <th>OtherDepartures</th>\n",
       "      <th>FlightDuration</th>\n",
       "      <th>DayType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABC573</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2019-12-24 00:06:22.204</td>\n",
       "      <td>2019-12-24 02:09:21.282</td>\n",
       "      <td>2019-12-24 06:46:17.404</td>\n",
       "      <td>2019-12-24 06:48:36.247</td>\n",
       "      <td>33.644024</td>\n",
       "      <td>-84.422336</td>\n",
       "      <td>37.621674</td>\n",
       "      <td>-122.376037</td>\n",
       "      <td>7379</td>\n",
       "      <td>1</td>\n",
       "      <td>16616</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A13B66</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>WAL</td>\n",
       "      <td>2019-12-24 00:34:21.210</td>\n",
       "      <td>2019-12-24 16:30:21.212</td>\n",
       "      <td>2019-12-24 17:47:38.693</td>\n",
       "      <td>2019-12-24 17:49:17.903</td>\n",
       "      <td>33.635777</td>\n",
       "      <td>-84.416773</td>\n",
       "      <td>38.068139</td>\n",
       "      <td>-75.513452</td>\n",
       "      <td>57360</td>\n",
       "      <td>1</td>\n",
       "      <td>4637</td>\n",
       "      <td>Christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A44D3F</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2020-10-19 01:13:53.937</td>\n",
       "      <td>2020-10-19 01:15:59.356</td>\n",
       "      <td>2020-10-19 03:05:43.827</td>\n",
       "      <td>2020-10-19 03:08:58.907</td>\n",
       "      <td>33.645816</td>\n",
       "      <td>-84.438171</td>\n",
       "      <td>35.390885</td>\n",
       "      <td>-97.588952</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>6584</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A3F133</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>GRR</td>\n",
       "      <td>2020-10-19 11:39:27.973</td>\n",
       "      <td>2020-10-19 13:13:43.158</td>\n",
       "      <td>2020-10-19 14:38:29.470</td>\n",
       "      <td>2020-10-19 16:07:09.267</td>\n",
       "      <td>33.641743</td>\n",
       "      <td>-84.438772</td>\n",
       "      <td>42.879295</td>\n",
       "      <td>-85.521379</td>\n",
       "      <td>5656</td>\n",
       "      <td>2</td>\n",
       "      <td>5086</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A260ED</td>\n",
       "      <td>Southwest Airlines</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2020-10-19 12:05:21.766</td>\n",
       "      <td>2020-10-19 12:07:13.023</td>\n",
       "      <td>2020-10-19 13:59:24.776</td>\n",
       "      <td>2020-10-19 17:31:00.279</td>\n",
       "      <td>33.645412</td>\n",
       "      <td>-84.437331</td>\n",
       "      <td>29.643860</td>\n",
       "      <td>-95.272091</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>6731</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266148</th>\n",
       "      <td>ATL</td>\n",
       "      <td>AA7833</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>EWR</td>\n",
       "      <td>2020-10-13 02:16:14.264</td>\n",
       "      <td>2020-10-13 02:19:15.162</td>\n",
       "      <td>2020-10-13 03:53:59.593</td>\n",
       "      <td>2020-10-13 03:59:15.265</td>\n",
       "      <td>33.634702</td>\n",
       "      <td>-84.407873</td>\n",
       "      <td>40.693565</td>\n",
       "      <td>-74.164124</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>5684</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266149</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A8EAEA</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>LAS</td>\n",
       "      <td>2020-10-13 01:12:42.916</td>\n",
       "      <td>2020-10-13 01:25:44.663</td>\n",
       "      <td>2020-10-13 05:13:29.549</td>\n",
       "      <td>2020-10-13 06:42:58.385</td>\n",
       "      <td>33.635819</td>\n",
       "      <td>-84.425454</td>\n",
       "      <td>36.073655</td>\n",
       "      <td>-115.138194</td>\n",
       "      <td>782</td>\n",
       "      <td>1</td>\n",
       "      <td>13665</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266150</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A441D6</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>RDU</td>\n",
       "      <td>2020-11-08 13:19:48.490</td>\n",
       "      <td>2020-11-08 14:59:00.472</td>\n",
       "      <td>2020-11-08 15:54:14.745</td>\n",
       "      <td>2020-11-08 17:18:59.358</td>\n",
       "      <td>33.647771</td>\n",
       "      <td>-84.422178</td>\n",
       "      <td>35.885090</td>\n",
       "      <td>-78.788853</td>\n",
       "      <td>5952</td>\n",
       "      <td>0</td>\n",
       "      <td>3314</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266151</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A437CE</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>EWR</td>\n",
       "      <td>2020-11-21 02:03:13.373</td>\n",
       "      <td>2020-11-21 02:08:58.885</td>\n",
       "      <td>2020-11-21 03:43:59.029</td>\n",
       "      <td>2020-11-21 03:46:59.981</td>\n",
       "      <td>33.635784</td>\n",
       "      <td>-84.443707</td>\n",
       "      <td>40.684456</td>\n",
       "      <td>-74.171994</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "      <td>5701</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266152</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A919CD</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>MIA</td>\n",
       "      <td>2020-12-17 00:46:14.486</td>\n",
       "      <td>2020-12-17 00:56:13.639</td>\n",
       "      <td>2020-12-17 02:20:44.670</td>\n",
       "      <td>2020-12-17 14:41:59.126</td>\n",
       "      <td>33.635807</td>\n",
       "      <td>-84.418688</td>\n",
       "      <td>25.787240</td>\n",
       "      <td>-80.287309</td>\n",
       "      <td>599</td>\n",
       "      <td>0</td>\n",
       "      <td>5071</td>\n",
       "      <td>Regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>353 rows  16 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>From</th>\n      <th>Icao</th>\n      <th>Op</th>\n      <th>To</th>\n      <th>StartTime</th>\n      <th>LiftOffTime</th>\n      <th>TouchDownTime</th>\n      <th>StopTime</th>\n      <th>FromLat</th>\n      <th>FromLong</th>\n      <th>ToLat</th>\n      <th>ToLong</th>\n      <th>RunwayWaitTimeInSeconds</th>\n      <th>OtherDepartures</th>\n      <th>FlightDuration</th>\n      <th>DayType</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ATL</td>\n      <td>ABC573</td>\n      <td>Delta Air Lines</td>\n      <td>SFO</td>\n      <td>2019-12-24 00:06:22.204</td>\n      <td>2019-12-24 02:09:21.282</td>\n      <td>2019-12-24 06:46:17.404</td>\n      <td>2019-12-24 06:48:36.247</td>\n      <td>33.644024</td>\n      <td>-84.422336</td>\n      <td>37.621674</td>\n      <td>-122.376037</td>\n      <td>7379</td>\n      <td>1</td>\n      <td>16616</td>\n      <td>Christmas</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ATL</td>\n      <td>A13B66</td>\n      <td>JetBlue Airways</td>\n      <td>WAL</td>\n      <td>2019-12-24 00:34:21.210</td>\n      <td>2019-12-24 16:30:21.212</td>\n      <td>2019-12-24 17:47:38.693</td>\n      <td>2019-12-24 17:49:17.903</td>\n      <td>33.635777</td>\n      <td>-84.416773</td>\n      <td>38.068139</td>\n      <td>-75.513452</td>\n      <td>57360</td>\n      <td>1</td>\n      <td>4637</td>\n      <td>Christmas</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ATL</td>\n      <td>A44D3F</td>\n      <td>Delta Air Lines</td>\n      <td>OKC</td>\n      <td>2020-10-19 01:13:53.937</td>\n      <td>2020-10-19 01:15:59.356</td>\n      <td>2020-10-19 03:05:43.827</td>\n      <td>2020-10-19 03:08:58.907</td>\n      <td>33.645816</td>\n      <td>-84.438171</td>\n      <td>35.390885</td>\n      <td>-97.588952</td>\n      <td>126</td>\n      <td>0</td>\n      <td>6584</td>\n      <td>Regular</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ATL</td>\n      <td>A3F133</td>\n      <td>Delta Air Lines</td>\n      <td>GRR</td>\n      <td>2020-10-19 11:39:27.973</td>\n      <td>2020-10-19 13:13:43.158</td>\n      <td>2020-10-19 14:38:29.470</td>\n      <td>2020-10-19 16:07:09.267</td>\n      <td>33.641743</td>\n      <td>-84.438772</td>\n      <td>42.879295</td>\n      <td>-85.521379</td>\n      <td>5656</td>\n      <td>2</td>\n      <td>5086</td>\n      <td>Regular</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATL</td>\n      <td>A260ED</td>\n      <td>Southwest Airlines</td>\n      <td>HOU</td>\n      <td>2020-10-19 12:05:21.766</td>\n      <td>2020-10-19 12:07:13.023</td>\n      <td>2020-10-19 13:59:24.776</td>\n      <td>2020-10-19 17:31:00.279</td>\n      <td>33.645412</td>\n      <td>-84.437331</td>\n      <td>29.643860</td>\n      <td>-95.272091</td>\n      <td>112</td>\n      <td>3</td>\n      <td>6731</td>\n      <td>Regular</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>266148</th>\n      <td>ATL</td>\n      <td>AA7833</td>\n      <td>Delta Air Lines</td>\n      <td>EWR</td>\n      <td>2020-10-13 02:16:14.264</td>\n      <td>2020-10-13 02:19:15.162</td>\n      <td>2020-10-13 03:53:59.593</td>\n      <td>2020-10-13 03:59:15.265</td>\n      <td>33.634702</td>\n      <td>-84.407873</td>\n      <td>40.693565</td>\n      <td>-74.164124</td>\n      <td>181</td>\n      <td>0</td>\n      <td>5684</td>\n      <td>Regular</td>\n    </tr>\n    <tr>\n      <th>266149</th>\n      <td>ATL</td>\n      <td>A8EAEA</td>\n      <td>Delta Air Lines</td>\n      <td>LAS</td>\n      <td>2020-10-13 01:12:42.916</td>\n      <td>2020-10-13 01:25:44.663</td>\n      <td>2020-10-13 05:13:29.549</td>\n      <td>2020-10-13 06:42:58.385</td>\n      <td>33.635819</td>\n      <td>-84.425454</td>\n      <td>36.073655</td>\n      <td>-115.138194</td>\n      <td>782</td>\n      <td>1</td>\n      <td>13665</td>\n      <td>Regular</td>\n    </tr>\n    <tr>\n      <th>266150</th>\n      <td>ATL</td>\n      <td>A441D6</td>\n      <td>Delta Air Lines</td>\n      <td>RDU</td>\n      <td>2020-11-08 13:19:48.490</td>\n      <td>2020-11-08 14:59:00.472</td>\n      <td>2020-11-08 15:54:14.745</td>\n      <td>2020-11-08 17:18:59.358</td>\n      <td>33.647771</td>\n      <td>-84.422178</td>\n      <td>35.885090</td>\n      <td>-78.788853</td>\n      <td>5952</td>\n      <td>0</td>\n      <td>3314</td>\n      <td>Regular</td>\n    </tr>\n    <tr>\n      <th>266151</th>\n      <td>ATL</td>\n      <td>A437CE</td>\n      <td>Delta Air Lines</td>\n      <td>EWR</td>\n      <td>2020-11-21 02:03:13.373</td>\n      <td>2020-11-21 02:08:58.885</td>\n      <td>2020-11-21 03:43:59.029</td>\n      <td>2020-11-21 03:46:59.981</td>\n      <td>33.635784</td>\n      <td>-84.443707</td>\n      <td>40.684456</td>\n      <td>-74.171994</td>\n      <td>345</td>\n      <td>0</td>\n      <td>5701</td>\n      <td>Regular</td>\n    </tr>\n    <tr>\n      <th>266152</th>\n      <td>ATL</td>\n      <td>A919CD</td>\n      <td>Delta Air Lines</td>\n      <td>MIA</td>\n      <td>2020-12-17 00:46:14.486</td>\n      <td>2020-12-17 00:56:13.639</td>\n      <td>2020-12-17 02:20:44.670</td>\n      <td>2020-12-17 14:41:59.126</td>\n      <td>33.635807</td>\n      <td>-84.418688</td>\n      <td>25.787240</td>\n      <td>-80.287309</td>\n      <td>599</td>\n      <td>0</td>\n      <td>5071</td>\n      <td>Regular</td>\n    </tr>\n  </tbody>\n</table>\n<p>353 rows  16 columns</p>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather8Atl = dfpWeather8[dfpWeather8['From'] == 'ATL']\n",
    "dfpWeather8Atl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1bea5972-a83a-43fe-a4a8-918a054c7b83",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[33]: 353</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[33]: 353</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(dfpWeather8Atl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "95f51727-8206-44f8-9ea7-6369e012c6a7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Export to CSV function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4290b69e-43cc-4b14-8e9b-bdeb041eacae",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Collecting s3fs\n",
       "  Downloading s3fs-0.5.2-py3-none-any.whl (22 kB)\n",
       "Collecting aiobotocore&gt;=1.0.1\n",
       "  Downloading aiobotocore-1.2.2.tar.gz (48 kB)\n",
       "Collecting fsspec&gt;=0.8.0\n",
       "  Downloading fsspec-0.8.7-py3-none-any.whl (103 kB)\n",
       "Collecting botocore&lt;1.19.53,&gt;=1.19.52\n",
       "  Downloading botocore-1.19.52-py2.py3-none-any.whl (7.2 MB)\n",
       "Collecting aiohttp&gt;=3.3.1\n",
       "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
       "Collecting wrapt&gt;=1.10.10\n",
       "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
       "Collecting aioitertools&gt;=0.5.1\n",
       "  Downloading aioitertools-0.7.1-py3-none-any.whl (20 kB)\n",
       "Collecting multidict&lt;7.0,&gt;=4.5\n",
       "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
       "Collecting typing-extensions&gt;=3.6.5\n",
       "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
       "Collecting async-timeout&lt;4.0,&gt;=3.0\n",
       "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
       "Collecting yarl&lt;2.0,&gt;=1.0\n",
       "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
       "Collecting attrs&gt;=17.3.0\n",
       "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
       "Requirement already satisfied: chardet&lt;5.0,&gt;=2.0 in /usr/lib/python3/dist-packages (from aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (3.0.4)\n",
       "Requirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (0.10.0)\n",
       "Requirement already satisfied: urllib3&lt;1.27,&gt;=1.25.4 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.25.8)\n",
       "Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8.1)\n",
       "Collecting importlib-metadata\n",
       "  Downloading importlib_metadata-3.7.2-py3-none-any.whl (11 kB)\n",
       "Requirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.14.0)\n",
       "Requirement already satisfied: idna&gt;=2.0 in /databricks/python3/lib/python3.7/site-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8)\n",
       "Collecting zipp&gt;=0.5\n",
       "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
       "Building wheels for collected packages: aiobotocore, wrapt\n",
       "  Building wheel for aiobotocore (setup.py): started\n",
       "  Building wheel for aiobotocore (setup.py): finished with status &#39;done&#39;\n",
       "  Created wheel for aiobotocore: filename=aiobotocore-1.2.2-py3-none-any.whl size=45731 sha256=e51895fef088be40d9f59b340483f45fb223aabae0a6e0310fceaf875019e2b9\n",
       "  Stored in directory: /home/root/.cache/pip/wheels/2c/46/86/839f72195fdae70cd5286a9824841c7ea9ca514f4ac2eb43eb\n",
       "  Building wheel for wrapt (setup.py): started\n",
       "  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n",
       "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68708 sha256=5a27b801bafd77ff0ac7324b617a30672dfe5adb69f1272ac0be96a00a422f4a\n",
       "  Stored in directory: /home/root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
       "Successfully built aiobotocore wrapt\n",
       "Installing collected packages: typing-extensions, multidict, zipp, yarl, attrs, async-timeout, wrapt, importlib-metadata, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n",
       "  Attempting uninstall: botocore\n",
       "    Found existing installation: botocore 1.15.0\n",
       "    Not uninstalling botocore at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4eb309b9-8291-4ddf-a7d5-a4ddd9d29904\n",
       "    Can&#39;t uninstall &#39;botocore&#39;. No files were found to uninstall.\n",
       "ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
       "boto3 1.12.0 requires botocore&lt;1.16.0,&gt;=1.15.0, but you have botocore 1.19.52 which is incompatible.\n",
       "Successfully installed aiobotocore-1.2.2 aiohttp-3.7.4.post0 aioitertools-0.7.1 async-timeout-3.0.1 attrs-20.3.0 botocore-1.19.52 fsspec-0.8.7 importlib-metadata-3.7.2 multidict-5.1.0 s3fs-0.5.2 typing-extensions-3.7.4.3 wrapt-1.12.1 yarl-1.6.3 zipp-3.4.1\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting s3fs\n  Downloading s3fs-0.5.2-py3-none-any.whl (22 kB)\nCollecting aiobotocore&gt;=1.0.1\n  Downloading aiobotocore-1.2.2.tar.gz (48 kB)\nCollecting fsspec&gt;=0.8.0\n  Downloading fsspec-0.8.7-py3-none-any.whl (103 kB)\nCollecting botocore&lt;1.19.53,&gt;=1.19.52\n  Downloading botocore-1.19.52-py2.py3-none-any.whl (7.2 MB)\nCollecting aiohttp&gt;=3.3.1\n  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\nCollecting wrapt&gt;=1.10.10\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting aioitertools&gt;=0.5.1\n  Downloading aioitertools-0.7.1-py3-none-any.whl (20 kB)\nCollecting multidict&lt;7.0,&gt;=4.5\n  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\nCollecting typing-extensions&gt;=3.6.5\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting async-timeout&lt;4.0,&gt;=3.0\n  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\nCollecting yarl&lt;2.0,&gt;=1.0\n  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\nCollecting attrs&gt;=17.3.0\n  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\nRequirement already satisfied: chardet&lt;5.0,&gt;=2.0 in /usr/lib/python3/dist-packages (from aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (3.0.4)\nRequirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (0.10.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.25.4 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.25.8)\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8.1)\nCollecting importlib-metadata\n  Downloading importlib_metadata-3.7.2-py3-none-any.whl (11 kB)\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.14.0)\nRequirement already satisfied: idna&gt;=2.0 in /databricks/python3/lib/python3.7/site-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\nBuilding wheels for collected packages: aiobotocore, wrapt\n  Building wheel for aiobotocore (setup.py): started\n  Building wheel for aiobotocore (setup.py): finished with status &#39;done&#39;\n  Created wheel for aiobotocore: filename=aiobotocore-1.2.2-py3-none-any.whl size=45731 sha256=e51895fef088be40d9f59b340483f45fb223aabae0a6e0310fceaf875019e2b9\n  Stored in directory: /home/root/.cache/pip/wheels/2c/46/86/839f72195fdae70cd5286a9824841c7ea9ca514f4ac2eb43eb\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68708 sha256=5a27b801bafd77ff0ac7324b617a30672dfe5adb69f1272ac0be96a00a422f4a\n  Stored in directory: /home/root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built aiobotocore wrapt\nInstalling collected packages: typing-extensions, multidict, zipp, yarl, attrs, async-timeout, wrapt, importlib-metadata, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.15.0\n    Not uninstalling botocore at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-4eb309b9-8291-4ddf-a7d5-a4ddd9d29904\n    Can&#39;t uninstall &#39;botocore&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nboto3 1.12.0 requires botocore&lt;1.16.0,&gt;=1.15.0, but you have botocore 1.19.52 which is incompatible.\nSuccessfully installed aiobotocore-1.2.2 aiohttp-3.7.4.post0 aioitertools-0.7.1 async-timeout-3.0.1 attrs-20.3.0 botocore-1.19.52 fsspec-0.8.7 importlib-metadata-3.7.2 multidict-5.1.0 s3fs-0.5.2 typing-extensions-3.7.4.3 wrapt-1.12.1 yarl-1.6.3 zipp-3.4.1\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "213e00a1-0638-4986-ac26-70881e7e6052",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "bytes_to_write = dfpWeather9.to_csv(None, sep='|', index=False).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open('s3://<BUCKET_NAME>/flights-csv/full-data/full-data.csv', 'wb') as f:\n",
    "    f.write(bytes_to_write)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "75437921-b0fc-4cc8-bd1e-805a084091e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weatherDict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "91468489-b24e-4566-90a1-6cca84fbd2c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[68]: 454</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[68]: 454</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(weatherDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "145b2d13-64bd-4edd-bc94-571aa822d8c6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">time - 2018-12-31 04:00:00\n",
       "temp - 49.82\n",
       "dwpt - 7.2\n",
       "rhum - 83.8\n",
       "prcp - 0.0\n",
       "snow - 0.0\n",
       "wdir - 270.0\n",
       "wspd - 11.0\n",
       "wpgt - 0.0\n",
       "pres - 1017.3\n",
       "tsun - 0.0\n",
       "coco - Cloudy\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">time - 2018-12-31 04:00:00\ntemp - 49.82\ndwpt - 7.2\nrhum - 83.8\nprcp - 0.0\nsnow - 0.0\nwdir - 270.0\nwspd - 11.0\nwpgt - 0.0\npres - 1017.3\ntsun - 0.0\ncoco - Cloudy\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# AC1E56\tFedEx\tOAK\tOAK\t2018-12-31 05:36:35.721\t2018-12-31 05:36:51.373\t2018-12-31 05:37:15.593\t2018-12-31 05:37:15.593\t1\tFalse\t37.716611\t-122.221408\t37.716611\t-122.221408\n",
    "from datetime import datetime, timedelta\n",
    "from meteostat import Point, Daily\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def weather2(startTime, liftOffTime, lat, long, key): \n",
    "#   start, end = startTime, liftOffTime \n",
    "  start, end = pd.to_datetime(startTime), pd.to_datetime(liftOffTime)\n",
    "  start = start - timedelta(hours=1)\n",
    "  end = start + timedelta(hours=1)\n",
    "  lookupKey = (start.year, start.month, start.day, start.hour, end.year, end.month, end.day, end.hour, int(lat), int(long))\n",
    "  \n",
    "  if lookupKey not in weatherDict:\n",
    "    location = Point(lat, long)\n",
    "\n",
    "    data = Hourly(location, start, end)\n",
    "    data = data.fetch()   \n",
    "    \n",
    "    if data.index.nlevels > 1:\n",
    "      print(f'levels = {data.index.nlevels}')\n",
    "      print(lookupKey)\n",
    "      print(data)\n",
    "      weatherDict[lookupKey] = {}\n",
    "      return np.nan\n",
    "      \n",
    "  \n",
    "    if len(data) > 1:\n",
    "      result = data.reset_index().loc[[0]].to_dict('list')\n",
    "    else:\n",
    "      result = data.reset_index().to_dict('list')\n",
    "\n",
    "    if (len(result['temp']) > 0 and result['temp'][0]):\n",
    "      result['temp'][0] = round((result['temp'][0] * 1.8) + 32, 2)\n",
    "\n",
    "    for var in ['snow', 'wpgt', 'tsun']:\n",
    "      if (len(result[var]) > 0 and np.isnan(result[var][0])):\n",
    "        result[var][0] = 0.0\n",
    "\n",
    "    #  Make sure the scheme data type for ConditionCode match as well. Either DoubleType or StringType\n",
    "    condition_codes = {1: 'Clear', 2: 'Fair', 3: 'Cloudy', \\\n",
    "                       4:\t'Overcast', 5: 'Fog', 6: 'Freezing Fog', \\\n",
    "                       7:\t'Light Rain', 8: 'Rain', 9:\t'Heavy Rain', \\\n",
    "                       10: 'Freezing Rain', 11: 'Heavy Freezing Rain', \\\n",
    "                       12: 'Sleet', 13: 'Heavy Sleet', 14: 'Light Snowfall', \\\n",
    "                       15: 'Snowfall', 16: 'Heavy Snowfall', 17: 'Rain Shower', \\\n",
    "                       18: 'Heavy Rain Shower', 19: 'Sleet Shower', 20: 'Heavy Sleet Shower', \\\n",
    "                       21: 'Snow Shower', 22: 'Heavy Snow Shower', 23: 'Lightning', \\\n",
    "                       24: 'Hail', 25: 'Thunderstorm', 26: 'Heavy Thunderstorm', 27: 'Storm'}\n",
    "\n",
    "    if ( (len(result['coco']) > 0) and (not np.isnan(result['coco'][0])) ):\n",
    "      if int(result['coco'][0]) in condition_codes:\n",
    "        result['coco'][0] = condition_codes[int(result['coco'][0])]\n",
    "      else:\n",
    "        result['coco'][0] = 'Unknown'\n",
    "    \n",
    "    keys = ['time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']\n",
    "    results = [result[key][0] if (key in result and len(result[key]) > 0) else None for key in keys]\n",
    "    weatherDict[lookupKey] = {keys[i] : results[i] for i in range(len(keys))}\n",
    "\n",
    "  return weatherDict[lookupKey][key] if len(weatherDict[lookupKey]) > 0 else np.nan\n",
    "\n",
    "for key in ['time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']:\n",
    "  print(f'{key} - {weather2(datetime(2018, 12, 31, 5, 0, 0), datetime(2018, 12, 31, 6, 7, 0, 16), 37.716611, -122.221408, key)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cfa54c50-fd6f-4538-ad52-2667a1fc2850",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "Int64Index: 353 entries, 0 to 266152\n",
       "Data columns (total 16 columns):\n",
       " #   Column                   Non-Null Count  Dtype  \n",
       "---  ------                   --------------  -----  \n",
       " 0   From                     353 non-null    object \n",
       " 1   Icao                     353 non-null    object \n",
       " 2   Op                       353 non-null    object \n",
       " 3   To                       353 non-null    object \n",
       " 4   StartTime                353 non-null    object \n",
       " 5   LiftOffTime              353 non-null    object \n",
       " 6   TouchDownTime            353 non-null    object \n",
       " 7   StopTime                 353 non-null    object \n",
       " 8   FromLat                  353 non-null    float64\n",
       " 9   FromLong                 353 non-null    float64\n",
       " 10  ToLat                    353 non-null    float64\n",
       " 11  ToLong                   353 non-null    float64\n",
       " 12  RunwayWaitTimeInSeconds  353 non-null    int32  \n",
       " 13  OtherDepartures          353 non-null    int32  \n",
       " 14  FlightDuration           353 non-null    int32  \n",
       " 15  DayType                  353 non-null    object \n",
       "dtypes: float64(4), int32(3), object(9)\n",
       "memory usage: 42.7+ KB\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 353 entries, 0 to 266152\nData columns (total 16 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   From                     353 non-null    object \n 1   Icao                     353 non-null    object \n 2   Op                       353 non-null    object \n 3   To                       353 non-null    object \n 4   StartTime                353 non-null    object \n 5   LiftOffTime              353 non-null    object \n 6   TouchDownTime            353 non-null    object \n 7   StopTime                 353 non-null    object \n 8   FromLat                  353 non-null    float64\n 9   FromLong                 353 non-null    float64\n 10  ToLat                    353 non-null    float64\n 11  ToLong                   353 non-null    float64\n 12  RunwayWaitTimeInSeconds  353 non-null    int32  \n 13  OtherDepartures          353 non-null    int32  \n 14  FlightDuration           353 non-null    int32  \n 15  DayType                  353 non-null    object \ndtypes: float64(4), int32(3), object(9)\nmemory usage: 42.7+ KB\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpWeather8Atl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "130a2abc-173f-4ddf-b295-19479886ed17",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n",
       "/local_disk0/tmp/1615587451351-0/PythonShell.py:4: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "  # Databricks Python Shell\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;Temperature&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "Int64Index: 353 entries, 0 to 266152\n",
       "Data columns (total 17 columns):\n",
       " #   Column                   Non-Null Count  Dtype  \n",
       "---  ------                   --------------  -----  \n",
       " 0   From                     353 non-null    object \n",
       " 1   Icao                     353 non-null    object \n",
       " 2   Op                       353 non-null    object \n",
       " 3   To                       353 non-null    object \n",
       " 4   StartTime                353 non-null    object \n",
       " 5   LiftOffTime              353 non-null    object \n",
       " 6   TouchDownTime            353 non-null    object \n",
       " 7   StopTime                 353 non-null    object \n",
       " 8   FromLat                  353 non-null    float64\n",
       " 9   FromLong                 353 non-null    float64\n",
       " 10  ToLat                    353 non-null    float64\n",
       " 11  ToLong                   353 non-null    float64\n",
       " 12  RunwayWaitTimeInSeconds  353 non-null    int32  \n",
       " 13  OtherDepartures          353 non-null    int32  \n",
       " 14  FlightDuration           353 non-null    int32  \n",
       " 15  DayType                  353 non-null    object \n",
       " 16  Temperature              353 non-null    object \n",
       "dtypes: float64(4), int32(3), object(10)\n",
       "memory usage: 45.5+ KB\n",
       "None\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n&lt;class &#39;pandas._libs.tslibs.timestamps.Timestamp&#39;&gt;\n/local_disk0/tmp/1615587451351-0/PythonShell.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  # Databricks Python Shell\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;Temperature&#39;],\n      dtype=&#39;object&#39;)\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 353 entries, 0 to 266152\nData columns (total 17 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   From                     353 non-null    object \n 1   Icao                     353 non-null    object \n 2   Op                       353 non-null    object \n 3   To                       353 non-null    object \n 4   StartTime                353 non-null    object \n 5   LiftOffTime              353 non-null    object \n 6   TouchDownTime            353 non-null    object \n 7   StopTime                 353 non-null    object \n 8   FromLat                  353 non-null    float64\n 9   FromLong                 353 non-null    float64\n 10  ToLat                    353 non-null    float64\n 11  ToLong                   353 non-null    float64\n 12  RunwayWaitTimeInSeconds  353 non-null    int32  \n 13  OtherDepartures          353 non-null    int32  \n 14  FlightDuration           353 non-null    int32  \n 15  DayType                  353 non-null    object \n 16  Temperature              353 non-null    object \ndtypes: float64(4), int32(3), object(10)\nmemory usage: 45.5+ KB\nNone\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dfpWeather8Atl['Temperature'] = np.vectorize(weather2, otypes=[\"O\"]) (dfpWeather8Atl['StartTime'], dfpWeather8Atl['LiftOffTime'], dfpWeather8Atl['FromLat'], dfpWeather8Atl['FromLong'], 'temp')\n",
    "\n",
    "print(dfpWeather8Atl.columns)\n",
    "print(dfpWeather8Atl.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8d15932a-181c-4346-88ef-6767598431ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">dwpt\n",
       "/local_disk0/tmp/1615587451351-0/PythonShell.py:7: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "  # registered under __main__, which will be replaced by a dummy module in the interactive shell.\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "Int64Index: 353 entries, 0 to 266152\n",
       "Data columns (total 27 columns):\n",
       " #   Column                   Non-Null Count  Dtype  \n",
       "---  ------                   --------------  -----  \n",
       " 0   From                     353 non-null    object \n",
       " 1   Icao                     353 non-null    object \n",
       " 2   Op                       353 non-null    object \n",
       " 3   To                       353 non-null    object \n",
       " 4   StartTime                353 non-null    object \n",
       " 5   LiftOffTime              353 non-null    object \n",
       " 6   TouchDownTime            353 non-null    object \n",
       " 7   StopTime                 353 non-null    object \n",
       " 8   FromLat                  353 non-null    float64\n",
       " 9   FromLong                 353 non-null    float64\n",
       " 10  ToLat                    353 non-null    float64\n",
       " 11  ToLong                   353 non-null    float64\n",
       " 12  RunwayWaitTimeInSeconds  353 non-null    int32  \n",
       " 13  OtherDepartures          353 non-null    int32  \n",
       " 14  FlightDuration           353 non-null    int32  \n",
       " 15  DayType                  353 non-null    object \n",
       " 16  Temperature              353 non-null    object \n",
       " 17  Dewpoint                 353 non-null    object \n",
       " 18  RelativeHumidity         353 non-null    object \n",
       " 19  Precipitation            353 non-null    object \n",
       " 20  SnowLevel                353 non-null    object \n",
       " 21  WindDirection            353 non-null    object \n",
       " 22  WindSpeed                353 non-null    object \n",
       " 23  PeakWindGust             353 non-null    object \n",
       " 24  AirPressure              353 non-null    object \n",
       " 25  Sunshine                 353 non-null    object \n",
       " 26  ConditionCode            350 non-null    object \n",
       "dtypes: float64(4), int32(3), object(20)\n",
       "memory usage: 73.1+ KB\n",
       "None\n",
       "Out[28]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">dwpt\n/local_disk0/tmp/1615587451351-0/PythonShell.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  # registered under __main__, which will be replaced by a dummy module in the interactive shell.\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 353 entries, 0 to 266152\nData columns (total 27 columns):\n #   Column                   Non-Null Count  Dtype  \n---  ------                   --------------  -----  \n 0   From                     353 non-null    object \n 1   Icao                     353 non-null    object \n 2   Op                       353 non-null    object \n 3   To                       353 non-null    object \n 4   StartTime                353 non-null    object \n 5   LiftOffTime              353 non-null    object \n 6   TouchDownTime            353 non-null    object \n 7   StopTime                 353 non-null    object \n 8   FromLat                  353 non-null    float64\n 9   FromLong                 353 non-null    float64\n 10  ToLat                    353 non-null    float64\n 11  ToLong                   353 non-null    float64\n 12  RunwayWaitTimeInSeconds  353 non-null    int32  \n 13  OtherDepartures          353 non-null    int32  \n 14  FlightDuration           353 non-null    int32  \n 15  DayType                  353 non-null    object \n 16  Temperature              353 non-null    object \n 17  Dewpoint                 353 non-null    object \n 18  RelativeHumidity         353 non-null    object \n 19  Precipitation            353 non-null    object \n 20  SnowLevel                353 non-null    object \n 21  WindDirection            353 non-null    object \n 22  WindSpeed                353 non-null    object \n 23  PeakWindGust             353 non-null    object \n 24  AirPressure              353 non-null    object \n 25  Sunshine                 353 non-null    object \n 26  ConditionCode            350 non-null    object \ndtypes: float64(4), int32(3), object(20)\nmemory usage: 73.1+ KB\nNone\nOut[28]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From</th>\n",
       "      <th>Icao</th>\n",
       "      <th>Op</th>\n",
       "      <th>To</th>\n",
       "      <th>StartTime</th>\n",
       "      <th>LiftOffTime</th>\n",
       "      <th>TouchDownTime</th>\n",
       "      <th>StopTime</th>\n",
       "      <th>FromLat</th>\n",
       "      <th>FromLong</th>\n",
       "      <th>ToLat</th>\n",
       "      <th>ToLong</th>\n",
       "      <th>RunwayWaitTimeInSeconds</th>\n",
       "      <th>OtherDepartures</th>\n",
       "      <th>FlightDuration</th>\n",
       "      <th>DayType</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dewpoint</th>\n",
       "      <th>RelativeHumidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>SnowLevel</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>PeakWindGust</th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>ConditionCode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL</td>\n",
       "      <td>ABC573</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>SFO</td>\n",
       "      <td>2019-12-24 00:06:22.204</td>\n",
       "      <td>2019-12-24 02:09:21.282</td>\n",
       "      <td>2019-12-24 06:46:17.404</td>\n",
       "      <td>2019-12-24 06:48:36.247</td>\n",
       "      <td>33.644024</td>\n",
       "      <td>-84.422336</td>\n",
       "      <td>37.621674</td>\n",
       "      <td>-122.376037</td>\n",
       "      <td>7379</td>\n",
       "      <td>1</td>\n",
       "      <td>16616</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>54.86</td>\n",
       "      <td>11.7</td>\n",
       "      <td>93.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Light Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A13B66</td>\n",
       "      <td>JetBlue Airways</td>\n",
       "      <td>WAL</td>\n",
       "      <td>2019-12-24 00:34:21.210</td>\n",
       "      <td>2019-12-24 16:30:21.212</td>\n",
       "      <td>2019-12-24 17:47:38.693</td>\n",
       "      <td>2019-12-24 17:49:17.903</td>\n",
       "      <td>33.635777</td>\n",
       "      <td>-84.416773</td>\n",
       "      <td>38.068139</td>\n",
       "      <td>-75.513452</td>\n",
       "      <td>57360</td>\n",
       "      <td>1</td>\n",
       "      <td>4637</td>\n",
       "      <td>Christmas</td>\n",
       "      <td>54.86</td>\n",
       "      <td>11.7</td>\n",
       "      <td>93.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1012.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Light Rain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A44D3F</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2020-10-19 01:13:53.937</td>\n",
       "      <td>2020-10-19 01:15:59.356</td>\n",
       "      <td>2020-10-19 03:05:43.827</td>\n",
       "      <td>2020-10-19 03:08:58.907</td>\n",
       "      <td>33.645816</td>\n",
       "      <td>-84.438171</td>\n",
       "      <td>35.390885</td>\n",
       "      <td>-97.588952</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>6584</td>\n",
       "      <td>Regular</td>\n",
       "      <td>59.54</td>\n",
       "      <td>11.9</td>\n",
       "      <td>80.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A3F133</td>\n",
       "      <td>Delta Air Lines</td>\n",
       "      <td>GRR</td>\n",
       "      <td>2020-10-19 11:39:27.973</td>\n",
       "      <td>2020-10-19 13:13:43.158</td>\n",
       "      <td>2020-10-19 14:38:29.470</td>\n",
       "      <td>2020-10-19 16:07:09.267</td>\n",
       "      <td>33.641743</td>\n",
       "      <td>-84.438772</td>\n",
       "      <td>42.879295</td>\n",
       "      <td>-85.521379</td>\n",
       "      <td>5656</td>\n",
       "      <td>2</td>\n",
       "      <td>5086</td>\n",
       "      <td>Regular</td>\n",
       "      <td>53.06</td>\n",
       "      <td>9.8</td>\n",
       "      <td>87.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL</td>\n",
       "      <td>A260ED</td>\n",
       "      <td>Southwest Airlines</td>\n",
       "      <td>HOU</td>\n",
       "      <td>2020-10-19 12:05:21.766</td>\n",
       "      <td>2020-10-19 12:07:13.023</td>\n",
       "      <td>2020-10-19 13:59:24.776</td>\n",
       "      <td>2020-10-19 17:31:00.279</td>\n",
       "      <td>33.645412</td>\n",
       "      <td>-84.437331</td>\n",
       "      <td>29.643860</td>\n",
       "      <td>-95.272091</td>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>6731</td>\n",
       "      <td>Regular</td>\n",
       "      <td>55.94</td>\n",
       "      <td>10.5</td>\n",
       "      <td>83.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1024.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>From</th>\n      <th>Icao</th>\n      <th>Op</th>\n      <th>To</th>\n      <th>StartTime</th>\n      <th>LiftOffTime</th>\n      <th>TouchDownTime</th>\n      <th>StopTime</th>\n      <th>FromLat</th>\n      <th>FromLong</th>\n      <th>ToLat</th>\n      <th>ToLong</th>\n      <th>RunwayWaitTimeInSeconds</th>\n      <th>OtherDepartures</th>\n      <th>FlightDuration</th>\n      <th>DayType</th>\n      <th>Temperature</th>\n      <th>Dewpoint</th>\n      <th>RelativeHumidity</th>\n      <th>Precipitation</th>\n      <th>SnowLevel</th>\n      <th>WindDirection</th>\n      <th>WindSpeed</th>\n      <th>PeakWindGust</th>\n      <th>AirPressure</th>\n      <th>Sunshine</th>\n      <th>ConditionCode</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ATL</td>\n      <td>ABC573</td>\n      <td>Delta Air Lines</td>\n      <td>SFO</td>\n      <td>2019-12-24 00:06:22.204</td>\n      <td>2019-12-24 02:09:21.282</td>\n      <td>2019-12-24 06:46:17.404</td>\n      <td>2019-12-24 06:48:36.247</td>\n      <td>33.644024</td>\n      <td>-84.422336</td>\n      <td>37.621674</td>\n      <td>-122.376037</td>\n      <td>7379</td>\n      <td>1</td>\n      <td>16616</td>\n      <td>Christmas</td>\n      <td>54.86</td>\n      <td>11.7</td>\n      <td>93.9</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>12.2</td>\n      <td>0.0</td>\n      <td>1012.5</td>\n      <td>0.0</td>\n      <td>Light Rain</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ATL</td>\n      <td>A13B66</td>\n      <td>JetBlue Airways</td>\n      <td>WAL</td>\n      <td>2019-12-24 00:34:21.210</td>\n      <td>2019-12-24 16:30:21.212</td>\n      <td>2019-12-24 17:47:38.693</td>\n      <td>2019-12-24 17:49:17.903</td>\n      <td>33.635777</td>\n      <td>-84.416773</td>\n      <td>38.068139</td>\n      <td>-75.513452</td>\n      <td>57360</td>\n      <td>1</td>\n      <td>4637</td>\n      <td>Christmas</td>\n      <td>54.86</td>\n      <td>11.7</td>\n      <td>93.9</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>10.0</td>\n      <td>12.2</td>\n      <td>0.0</td>\n      <td>1012.5</td>\n      <td>0.0</td>\n      <td>Light Rain</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ATL</td>\n      <td>A44D3F</td>\n      <td>Delta Air Lines</td>\n      <td>OKC</td>\n      <td>2020-10-19 01:13:53.937</td>\n      <td>2020-10-19 01:15:59.356</td>\n      <td>2020-10-19 03:05:43.827</td>\n      <td>2020-10-19 03:08:58.907</td>\n      <td>33.645816</td>\n      <td>-84.438171</td>\n      <td>35.390885</td>\n      <td>-97.588952</td>\n      <td>126</td>\n      <td>0</td>\n      <td>6584</td>\n      <td>Regular</td>\n      <td>59.54</td>\n      <td>11.9</td>\n      <td>80.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>90.0</td>\n      <td>4.5</td>\n      <td>0.0</td>\n      <td>1023.8</td>\n      <td>0.0</td>\n      <td>Fair</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ATL</td>\n      <td>A3F133</td>\n      <td>Delta Air Lines</td>\n      <td>GRR</td>\n      <td>2020-10-19 11:39:27.973</td>\n      <td>2020-10-19 13:13:43.158</td>\n      <td>2020-10-19 14:38:29.470</td>\n      <td>2020-10-19 16:07:09.267</td>\n      <td>33.641743</td>\n      <td>-84.438772</td>\n      <td>42.879295</td>\n      <td>-85.521379</td>\n      <td>5656</td>\n      <td>2</td>\n      <td>5086</td>\n      <td>Regular</td>\n      <td>53.06</td>\n      <td>9.8</td>\n      <td>87.8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>80.0</td>\n      <td>7.1</td>\n      <td>0.0</td>\n      <td>1024.0</td>\n      <td>0.0</td>\n      <td>Fair</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ATL</td>\n      <td>A260ED</td>\n      <td>Southwest Airlines</td>\n      <td>HOU</td>\n      <td>2020-10-19 12:05:21.766</td>\n      <td>2020-10-19 12:07:13.023</td>\n      <td>2020-10-19 13:59:24.776</td>\n      <td>2020-10-19 17:31:00.279</td>\n      <td>33.645412</td>\n      <td>-84.437331</td>\n      <td>29.643860</td>\n      <td>-95.272091</td>\n      <td>112</td>\n      <td>3</td>\n      <td>6731</td>\n      <td>Regular</td>\n      <td>55.94</td>\n      <td>10.5</td>\n      <td>83.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>8.3</td>\n      <td>0.0</td>\n      <td>1024.4</td>\n      <td>0.0</td>\n      <td>Fair</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Atlanta \n",
    "import numpy as np\n",
    "keys = {'dwpt' : 'Dewpoint', 'rhum' : 'RelativeHumidity', 'prcp' : 'Precipitation', 'snow' : 'SnowLevel', 'wdir' : 'WindDirection', 'wspd' : 'WindSpeed', 'wpgt' : 'PeakWindGust', 'pres' : 'AirPressure', 'tsun' : 'Sunshine', 'coco' : 'ConditionCode'}\n",
    "\n",
    "for key in keys:\n",
    "  print(key)\n",
    "  dfpWeather8Atl[keys[key]] = np.vectorize(weather2, otypes=[\"O\"]) (dfpWeather8Atl['StartTime'], dfpWeather8Atl['LiftOffTime'], dfpWeather8Atl['FromLat'], dfpWeather8Atl['FromLong'], key)\n",
    "  \n",
    "print(dfpWeather8Atl.columns)\n",
    "print(dfpWeather8Atl.info())\n",
    "dfpWeather8Atl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ed1c27fa-6a50-4ce7-bc72-9989818d3885",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "bytes_to_write = dfpWeather8Atl.to_csv(None, sep='|', index=False).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open('s3://<BUCKET_NAME>/flights-csv/full-data/ATL.csv', 'wb') as f:\n",
    "    f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "473c2bfc-4c2b-4753-8eef-3960db9e8e1c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Code for merging 2 dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c5468042-e03f-4a1b-933c-845ad4ab550c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge two dictionaries\n",
    "\n",
    "# In Python 3.9.0 or greater (released 17 October 2020): PEP-584, discussed here, was implemented and provides the simplest method:\n",
    "\n",
    "# z = x | y          # NOTE: 3.9+ ONLY\n",
    "# In Python 3.5 or greater:\n",
    "\n",
    "# z = {**x, **y}\n",
    "# In Python 2, (or 3.4 or lower) write a function:\n",
    "\n",
    "# def merge_two_dicts(x, y):\n",
    "#     z = x.copy()   # start with x's keys and values\n",
    "#     z.update(y)    # modifies z with y's keys and values & returns None\n",
    "#     return z\n",
    "# and now:\n",
    "\n",
    "# z = merge_two_dicts(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "b8459b27-044f-405a-8ae4-e4d89b1d8605",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### For Debugging: Loop through each row to see what kind of data is causing problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ad4bf570-7891-476a-b80f-2a5f48b5ab2c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Actual Start time = 2021-03-13 19:14:18.183363\n",
       "Processing airport LAX\n",
       "Size of LAX flights = 29411\n",
       "Estimated Time = 48 minutes\n",
       "time\n",
       "(2018, 10, 3, 17, 2018, 10, 3, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 13, 2018, 10, 3, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 2, 2018, 10, 3, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 2, 23, 2018, 10, 3, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 3, 2018, 10, 3, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 0, 2018, 10, 3, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 21, 2018, 10, 3, 22, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 3, 2018, 10, 3, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 12, 2018, 10, 3, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 2, 23, 2018, 10, 3, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 3, 12, 2018, 10, 3, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 24, 23, 2018, 10, 25, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 20, 2018, 10, 25, 21, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 12, 2018, 10, 25, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 24, 23, 2018, 10, 25, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 13, 2018, 10, 25, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 6, 2018, 10, 25, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 13, 2018, 10, 25, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 24, 23, 2018, 10, 25, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 18, 2018, 10, 25, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 5, 2018, 11, 3, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 18, 2018, 11, 3, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 17, 2018, 11, 3, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 1, 2018, 11, 3, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 2, 2018, 11, 3, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 1, 2018, 11, 3, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 4, 2018, 11, 3, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 1, 2018, 11, 3, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 13, 2018, 11, 3, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 13, 2018, 11, 3, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 5, 2018, 11, 3, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 20, 2018, 11, 3, 21, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 4, 2018, 11, 3, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 3, 2018, 11, 3, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 4, 2018, 11, 3, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 18, 2018, 11, 3, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 2, 2018, 11, 3, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 3, 2018, 11, 3, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 3, 13, 2018, 11, 3, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 12, 2018, 11, 11, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 19, 2018, 11, 11, 20, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 14, 2018, 11, 11, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 0, 2018, 11, 11, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 6, 2018, 11, 11, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 13, 2018, 11, 11, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 14, 2018, 11, 11, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 16, 2018, 11, 11, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 4, 2018, 11, 11, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 2, 2018, 11, 11, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 11, 2018, 11, 11, 12, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 13, 2018, 11, 11, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 6, 2018, 11, 11, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 14, 2018, 11, 11, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 3, 2018, 11, 11, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 20, 2018, 11, 11, 21, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 4, 2018, 11, 11, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 13, 2018, 11, 11, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 11, 19, 2018, 11, 11, 20, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 4, 2018, 11, 28, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 16, 2018, 11, 28, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 27, 23, 2018, 11, 28, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 15, 2018, 11, 28, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 2, 2018, 11, 28, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 0, 2018, 11, 28, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 1, 2018, 11, 28, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 15, 2018, 11, 28, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 13, 2018, 11, 28, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 0, 2018, 11, 28, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 4, 2018, 11, 28, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 18, 2018, 11, 28, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 18, 2018, 11, 28, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 1, 2018, 11, 28, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 4, 2018, 11, 28, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 15, 2018, 11, 28, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 27, 23, 2018, 11, 28, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 18, 2018, 11, 28, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 1, 2018, 11, 28, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 8, 2018, 11, 28, 9, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 20, 2018, 11, 28, 21, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 16, 2018, 11, 28, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 28, 3, 2018, 11, 28, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 5, 2018, 11, 29, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 1, 2018, 11, 29, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 3, 2018, 11, 29, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 2, 2018, 11, 29, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 18, 2018, 11, 29, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 15, 2018, 11, 29, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 17, 2018, 11, 29, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 3, 2018, 11, 29, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 15, 2018, 11, 29, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 7, 2018, 11, 29, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 6, 2018, 11, 29, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 7, 2018, 11, 29, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 9, 2018, 11, 29, 10, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 16, 2018, 11, 29, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 0, 2018, 11, 29, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 12, 2018, 11, 29, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 3, 2018, 11, 29, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 11, 29, 4, 2018, 11, 29, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 16, 2018, 12, 13, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 7, 2018, 12, 13, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 1, 2018, 12, 13, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 18, 2018, 12, 13, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 2, 2018, 12, 13, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 5, 2018, 12, 13, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 3, 2018, 12, 13, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 7, 2018, 12, 13, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 8, 2018, 12, 13, 9, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 20, 2018, 12, 13, 21, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 12, 2018, 12, 13, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 4, 2018, 12, 13, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 12, 2018, 12, 13, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 3, 2018, 12, 13, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 0, 2018, 12, 13, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 2, 2018, 12, 13, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 12, 23, 2018, 12, 13, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 16, 2018, 12, 13, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 7, 2018, 12, 13, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 12, 2018, 12, 13, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 5, 2018, 12, 13, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 19, 2018, 12, 13, 20, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 16, 2018, 12, 13, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 5, 2018, 12, 23, 6, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 9, 2018, 12, 23, 10, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 0, 2018, 12, 23, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 0, 2018, 12, 23, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 2, 2018, 12, 23, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 7, 2018, 12, 23, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 0, 2018, 12, 23, 1, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 6, 2018, 12, 23, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 14, 2018, 12, 23, 15, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 12, 2018, 12, 23, 13, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 18, 2018, 12, 23, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 7, 2018, 12, 23, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 6, 2018, 12, 23, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 7, 2018, 12, 23, 8, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 13, 2018, 12, 23, 14, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 6, 2018, 12, 23, 7, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 2, 2018, 12, 23, 3, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 18, 2018, 12, 23, 19, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\n",
       "seen key before\n",
       "(2018, 12, 23, 14, 2018, 12, 23, 15, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 19, 2019, 11, 14, 20, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 14, 2019, 11, 14, 15, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 5, 2019, 11, 14, 6, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 16, 2019, 11, 14, 17, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 13, 2019, 11, 14, 14, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 13, 2019, 11, 14, 14, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 14, 2019, 11, 14, 15, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 5, 2019, 11, 14, 6, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 7, 2019, 11, 14, 8, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 16, 2019, 11, 14, 17, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 14, 2019, 11, 14, 15, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 20, 2019, 11, 14, 21, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 5, 2019, 11, 14, 6, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 13, 2019, 11, 14, 14, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 16, 2019, 11, 14, 17, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 1, 2019, 11, 14, 2, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 7, 2019, 11, 14, 8, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 1, 2019, 11, 14, 2, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\n",
       "seen key before\n",
       "(2019, 11, 14, 1, 2019, 11, 14, 2, 33, -118)\n",
       "seen key before\n",
       "\n",
       "*** WARNING: skipped 4993020 bytes of output ***\n",
       "\n",
       "2020-12-10 17:00:00   0.5  -3.4  75.2   0.0  ...   NaN  1020.7   NaN   5.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 2, 2020, 12, 10, 3, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-10 03:00:00  -3.0  -5.5  83.1   0.0  ...   NaN  1023.4   NaN   5.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 20, 2020, 12, 10, 21, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-10 02:00:00  -2.0  -6.0  74.0   0.0  ...   NaN  1023.3   NaN   5.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-10 14:00:00  -3.5  -4.4  93.3   0.0  ...   NaN  1020.4   NaN   5.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 18, 2020, 12, 10, 19, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-10 19:00:00   1.0  -3.8  70.2   0.0  ...   NaN  1019.1   NaN   5.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 10, 19, 2020, 12, 10, 20, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 15, 2020, 12, 10, 16, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 15, 2020, 12, 10, 16, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 4, 2020, 12, 10, 5, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-10 05:00:00  -4.0  -7.0  80.0   0.0  ...   NaN  1021.8   NaN   5.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 10, 12, 2020, 12, 10, 13, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-10 13:00:00  -4.0  -5.9  86.8   0.0  ...   NaN  1020.5   NaN   5.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 20, 2020, 12, 10, 21, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 2, 2020, 12, 10, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 15, 2020, 12, 10, 16, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 2, 2020, 12, 10, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 19, 2020, 12, 10, 20, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 01:00:00  -5.6  -8.9  78.3   0.0  ...   NaN  1022.3   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 03:00:00  -5.0  -8.4  77.1   0.0  ...   NaN  1024.6   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 17, 2020, 12, 13, 18, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 18:00:00  -3.0  -8.4  66.8   0.0  ...   NaN  1029.1   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "            temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres  tsun  coco\n",
       "time                                                                           \n",
       "2020-12-13  -3.0  -7.9  69.2   0.0   NaN  320.0  15.0   NaN  1021.2   NaN   3.0\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 17:00:00  -4.0  -8.4  71.9   0.0  ...   NaN  1030.2   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 5, 2020, 12, 13, 6, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 06:00:00  -7.5  -9.9  83.4   0.0  ...   NaN  1026.9   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 5, 2020, 12, 13, 6, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 18, 2020, 12, 13, 19, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 19:00:00  -2.5  -8.3  64.9   0.0  ...   NaN  1027.8   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 15:00:00  -6.5  -9.9  76.7   0.0  ...   NaN  1029.9   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 20:00:00  -1.0  -8.4  57.8   0.0  ...   NaN  1026.4   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 16:00:00  -5.5  -8.9  77.4   0.0  ...   NaN  1030.0   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 04:00:00  -6.0  -8.9  80.0   0.0  ...   NaN  1025.5   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 18, 2020, 12, 13, 19, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 13:00:00  -7.5  -9.9  83.4   0.0  ...   NaN  1029.4   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 21, 2020, 12, 13, 22, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 22:00:00  -1.0  -8.9  55.9   0.0  ...   NaN  1024.3   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 13, 2020, 12, 13, 14, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 14:00:00  -7.0  -9.9  79.8   0.0  ...   NaN  1029.6   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 13, 18, 2020, 12, 13, 19, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 20, 2020, 12, 13, 21, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 21:00:00  -1.5  -8.3  60.4   0.0  ...   NaN  1025.1   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 17, 2020, 12, 13, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 20, 2020, 12, 13, 21, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 13, 2020, 12, 13, 14, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 1, 2020, 12, 13, 2, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-13 02:00:00  -4.5  -8.4  74.0   0.0  ...   NaN  1023.4   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 5, 2020, 12, 13, 6, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 13, 2020, 12, 13, 14, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 17, 2020, 12, 13, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 21, 2020, 12, 13, 22, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 20, 2020, 12, 13, 21, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 1, 2020, 12, 13, 2, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 03:00:00   4.6   0.1  72.9   0.0  ...   NaN  1018.5   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 12, 2020, 12, 22, 13, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 13:00:00   5.6  -1.0  62.9   0.0  ...   NaN  1010.7   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 05:00:00   5.6   0.6  70.5   0.0  ...   NaN  1015.6   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 3, 2020, 12, 22, 4, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 04:00:00   6.1   0.6  67.9   0.0  ...   NaN  1017.2   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 15:00:00   7.0  -0.9  57.0   0.0  ...   NaN  1010.0   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 18, 2020, 12, 22, 19, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 19:00:00   2.0  -2.9  70.2   0.0  ...   NaN  1013.2   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 17:00:00   6.6  -0.3  61.5   0.0  ...   NaN  1010.6   NaN   7.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 3, 2020, 12, 22, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 01:00:00   5.1   0.6  72.9   0.0  ...   NaN  1019.2   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 18:00:00   3.5  -1.5  70.2   0.0  ...   NaN  1012.1   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 1, 2020, 12, 22, 2, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 02:00:00   5.1   0.6  73.2   0.0  ...   NaN  1018.6   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\n",
       "            temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres  tsun  coco\n",
       "time                                                                           \n",
       "2020-12-22   5.0   0.1  70.5   0.0   NaN  212.0   0.0   NaN  1019.8   NaN   3.0\n",
       "(2020, 12, 22, 20, 2020, 12, 22, 21, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 21:00:00   1.5  -8.8  47.4   0.0  ...   NaN  1015.1   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 15, 2020, 12, 22, 16, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 16:00:00   5.6  -0.5  65.6   0.0  ...   NaN  1010.5   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 12, 2020, 12, 22, 13, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 20, 2020, 12, 22, 21, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 19, 2020, 12, 22, 20, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 20:00:00   1.0  -4.4  68.5   0.0  ...   NaN  1014.4   NaN  14.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 3, 2020, 12, 22, 4, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 5, 2020, 12, 22, 6, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 06:00:00   6.0   0.1  66.2   0.0  ...   NaN  1016.6   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 11, 2020, 12, 22, 12, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 12:00:00   6.0  -1.9  57.0   0.0  ...   NaN  1011.1   NaN   2.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 13, 2020, 12, 22, 14, 40, -111)\n",
       "                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\n",
       "time                                         ...                          \n",
       "2020-12-22 14:00:00   7.5  -0.9  55.7   0.0  ...   NaN  1010.4   NaN   3.0\n",
       "\n",
       "[1 rows x 11 columns]\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 20, 2020, 12, 22, 21, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\n",
       "seen key before\n",
       "(2020, 12, 22, 18, 2020, 12, 22, 19, 40, -111)\n",
       "seen key before\n",
       "/local_disk0/tmp/1615657111681-0/PythonShell.py:174: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "22029\n",
       "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "Int64Index: 22029 entries, 15172 to 283293\n",
       "Data columns (total 17 columns):\n",
       " #   Column                   Non-Null Count  Dtype         \n",
       "---  ------                   --------------  -----         \n",
       " 0   From                     22029 non-null  object        \n",
       " 1   Icao                     22029 non-null  object        \n",
       " 2   Op                       22029 non-null  object        \n",
       " 3   To                       22029 non-null  object        \n",
       " 4   StartTime                22029 non-null  object        \n",
       " 5   LiftOffTime              22029 non-null  object        \n",
       " 6   TouchDownTime            22029 non-null  object        \n",
       " 7   StopTime                 22029 non-null  object        \n",
       " 8   FromLat                  22029 non-null  float64       \n",
       " 9   FromLong                 22029 non-null  float64       \n",
       " 10  ToLat                    22029 non-null  float64       \n",
       " 11  ToLong                   22029 non-null  float64       \n",
       " 12  RunwayWaitTimeInSeconds  22029 non-null  int32         \n",
       " 13  OtherDepartures          22029 non-null  int32         \n",
       " 14  FlightDuration           22029 non-null  int32         \n",
       " 15  DayType                  22029 non-null  object        \n",
       " 16  WeatherTime              22027 non-null  datetime64[ns]\n",
       "dtypes: datetime64[ns](1), float64(4), int32(3), object(9)\n",
       "memory usage: 2.8+ MB\n",
       "None\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Actual Start time = 2021-03-13 19:14:18.183363\nProcessing airport LAX\nSize of LAX flights = 29411\nEstimated Time = 48 minutes\ntime\n(2018, 10, 3, 17, 2018, 10, 3, 18, 33, -118)\nseen key before\n(2018, 10, 3, 13, 2018, 10, 3, 14, 33, -118)\nseen key before\n(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\nseen key before\n(2018, 10, 3, 2, 2018, 10, 3, 3, 33, -118)\nseen key before\n(2018, 10, 2, 23, 2018, 10, 3, 0, 33, -118)\nseen key before\n(2018, 10, 3, 3, 2018, 10, 3, 4, 33, -118)\nseen key before\n(2018, 10, 3, 0, 2018, 10, 3, 1, 33, -118)\nseen key before\n(2018, 10, 3, 21, 2018, 10, 3, 22, 33, -118)\nseen key before\n(2018, 10, 3, 3, 2018, 10, 3, 4, 33, -118)\nseen key before\n(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\nseen key before\n(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\nseen key before\n(2018, 10, 3, 15, 2018, 10, 3, 16, 33, -118)\nseen key before\n(2018, 10, 3, 12, 2018, 10, 3, 13, 33, -118)\nseen key before\n(2018, 10, 2, 23, 2018, 10, 3, 0, 33, -118)\nseen key before\n(2018, 10, 3, 12, 2018, 10, 3, 13, 33, -118)\nseen key before\n(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\nseen key before\n(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\nseen key before\n(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 24, 23, 2018, 10, 25, 0, 33, -118)\nseen key before\n(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\nseen key before\n(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\nseen key before\n(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\nseen key before\n(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 20, 2018, 10, 25, 21, 33, -118)\nseen key before\n(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\nseen key before\n(2018, 10, 25, 4, 2018, 10, 25, 5, 33, -118)\nseen key before\n(2018, 10, 25, 12, 2018, 10, 25, 13, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\nseen key before\n(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\nseen key before\n(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\nseen key before\n(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 24, 23, 2018, 10, 25, 0, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 13, 2018, 10, 25, 14, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 25, 6, 2018, 10, 25, 7, 33, -118)\nseen key before\n(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\nseen key before\n(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 25, 13, 2018, 10, 25, 14, 33, -118)\nseen key before\n(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 24, 23, 2018, 10, 25, 0, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\nseen key before\n(2018, 10, 25, 15, 2018, 10, 25, 16, 33, -118)\nseen key before\n(2018, 10, 25, 0, 2018, 10, 25, 1, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 2, 2018, 10, 25, 3, 33, -118)\nseen key before\n(2018, 10, 25, 18, 2018, 10, 25, 19, 33, -118)\nseen key before\n(2018, 10, 25, 16, 2018, 10, 25, 17, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 25, 5, 2018, 10, 25, 6, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 10, 25, 14, 2018, 10, 25, 15, 33, -118)\nseen key before\n(2018, 10, 25, 1, 2018, 10, 25, 2, 33, -118)\nseen key before\n(2018, 10, 25, 17, 2018, 10, 25, 18, 33, -118)\nseen key before\n(2018, 10, 25, 3, 2018, 10, 25, 4, 33, -118)\nseen key before\n(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\nseen key before\n(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\nseen key before\n(2018, 11, 3, 5, 2018, 11, 3, 6, 33, -118)\nseen key before\n(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\nseen key before\n(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\nseen key before\n(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\nseen key before\n(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\nseen key before\n(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\nseen key before\n(2018, 11, 3, 18, 2018, 11, 3, 19, 33, -118)\nseen key before\n(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\nseen key before\n(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\nseen key before\n(2018, 11, 3, 12, 2018, 11, 3, 13, 33, -118)\nseen key before\n(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\nseen key before\n(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\nseen key before\n(2018, 11, 3, 17, 2018, 11, 3, 18, 33, -118)\nseen key before\n(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\nseen key before\n(2018, 11, 3, 1, 2018, 11, 3, 2, 33, -118)\nseen key before\n(2018, 11, 3, 2, 2018, 11, 3, 3, 33, -118)\nseen key before\n(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\nseen key before\n(2018, 11, 3, 1, 2018, 11, 3, 2, 33, -118)\nseen key before\n(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\nseen key before\n(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\nseen key before\n(2018, 11, 3, 4, 2018, 11, 3, 5, 33, -118)\nseen key before\n(2018, 11, 3, 16, 2018, 11, 3, 17, 33, -118)\nseen key before\n(2018, 11, 3, 1, 2018, 11, 3, 2, 33, -118)\nseen key before\n(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\nseen key before\n(2018, 11, 3, 13, 2018, 11, 3, 14, 33, -118)\nseen key before\n(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\nseen key before\n(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\nseen key before\n(2018, 11, 3, 13, 2018, 11, 3, 14, 33, -118)\nseen key before\n(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\nseen key before\n(2018, 11, 3, 15, 2018, 11, 3, 16, 33, -118)\nseen key before\n(2018, 11, 3, 5, 2018, 11, 3, 6, 33, -118)\nseen key before\n(2018, 11, 3, 20, 2018, 11, 3, 21, 33, -118)\nseen key before\n(2018, 11, 3, 4, 2018, 11, 3, 5, 33, -118)\nseen key before\n(2018, 11, 3, 3, 2018, 11, 3, 4, 33, -118)\nseen key before\n(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\nseen key before\n(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\nseen key before\n(2018, 11, 3, 4, 2018, 11, 3, 5, 33, -118)\nseen key before\n(2018, 11, 3, 18, 2018, 11, 3, 19, 33, -118)\nseen key before\n(2018, 11, 3, 2, 2018, 11, 3, 3, 33, -118)\nseen key before\n(2018, 11, 2, 23, 2018, 11, 3, 0, 33, -118)\nseen key before\n(2018, 11, 3, 14, 2018, 11, 3, 15, 33, -118)\nseen key before\n(2018, 11, 3, 3, 2018, 11, 3, 4, 33, -118)\nseen key before\n(2018, 11, 3, 13, 2018, 11, 3, 14, 33, -118)\nseen key before\n(2018, 11, 11, 12, 2018, 11, 11, 13, 33, -118)\nseen key before\n(2018, 11, 11, 19, 2018, 11, 11, 20, 33, -118)\nseen key before\n(2018, 11, 11, 14, 2018, 11, 11, 15, 33, -118)\nseen key before\n(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\nseen key before\n(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\nseen key before\n(2018, 11, 11, 0, 2018, 11, 11, 1, 33, -118)\nseen key before\n(2018, 11, 11, 6, 2018, 11, 11, 7, 33, -118)\nseen key before\n(2018, 11, 11, 13, 2018, 11, 11, 14, 33, -118)\nseen key before\n(2018, 11, 11, 14, 2018, 11, 11, 15, 33, -118)\nseen key before\n(2018, 11, 11, 16, 2018, 11, 11, 17, 33, -118)\nseen key before\n(2018, 11, 11, 4, 2018, 11, 11, 5, 33, -118)\nseen key before\n(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\nseen key before\n(2018, 11, 11, 2, 2018, 11, 11, 3, 33, -118)\nseen key before\n(2018, 11, 11, 11, 2018, 11, 11, 12, 33, -118)\nseen key before\n(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\nseen key before\n(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\nseen key before\n(2018, 11, 11, 13, 2018, 11, 11, 14, 33, -118)\nseen key before\n(2018, 11, 11, 7, 2018, 11, 11, 8, 33, -118)\nseen key before\n(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\nseen key before\n(2018, 11, 11, 6, 2018, 11, 11, 7, 33, -118)\nseen key before\n(2018, 11, 11, 14, 2018, 11, 11, 15, 33, -118)\nseen key before\n(2018, 11, 11, 3, 2018, 11, 11, 4, 33, -118)\nseen key before\n(2018, 11, 11, 15, 2018, 11, 11, 16, 33, -118)\nseen key before\n(2018, 11, 11, 20, 2018, 11, 11, 21, 33, -118)\nseen key before\n(2018, 11, 11, 4, 2018, 11, 11, 5, 33, -118)\nseen key before\n(2018, 11, 11, 13, 2018, 11, 11, 14, 33, -118)\nseen key before\n(2018, 11, 11, 19, 2018, 11, 11, 20, 33, -118)\nseen key before\n(2018, 11, 28, 4, 2018, 11, 28, 5, 33, -118)\nseen key before\n(2018, 11, 28, 16, 2018, 11, 28, 17, 33, -118)\nseen key before\n(2018, 11, 27, 23, 2018, 11, 28, 0, 33, -118)\nseen key before\n(2018, 11, 28, 15, 2018, 11, 28, 16, 33, -118)\nseen key before\n(2018, 11, 28, 2, 2018, 11, 28, 3, 33, -118)\nseen key before\n(2018, 11, 28, 0, 2018, 11, 28, 1, 33, -118)\nseen key before\n(2018, 11, 28, 1, 2018, 11, 28, 2, 33, -118)\nseen key before\n(2018, 11, 28, 15, 2018, 11, 28, 16, 33, -118)\nseen key before\n(2018, 11, 28, 13, 2018, 11, 28, 14, 33, -118)\nseen key before\n(2018, 11, 28, 0, 2018, 11, 28, 1, 33, -118)\nseen key before\n(2018, 11, 28, 4, 2018, 11, 28, 5, 33, -118)\nseen key before\n(2018, 11, 28, 18, 2018, 11, 28, 19, 33, -118)\nseen key before\n(2018, 11, 28, 18, 2018, 11, 28, 19, 33, -118)\nseen key before\n(2018, 11, 28, 1, 2018, 11, 28, 2, 33, -118)\nseen key before\n(2018, 11, 28, 4, 2018, 11, 28, 5, 33, -118)\nseen key before\n(2018, 11, 28, 15, 2018, 11, 28, 16, 33, -118)\nseen key before\n(2018, 11, 27, 23, 2018, 11, 28, 0, 33, -118)\nseen key before\n(2018, 11, 28, 18, 2018, 11, 28, 19, 33, -118)\nseen key before\n(2018, 11, 28, 1, 2018, 11, 28, 2, 33, -118)\nseen key before\n(2018, 11, 28, 8, 2018, 11, 28, 9, 33, -118)\nseen key before\n(2018, 11, 28, 20, 2018, 11, 28, 21, 33, -118)\nseen key before\n(2018, 11, 28, 16, 2018, 11, 28, 17, 33, -118)\nseen key before\n(2018, 11, 28, 3, 2018, 11, 28, 4, 33, -118)\nseen key before\n(2018, 11, 29, 5, 2018, 11, 29, 6, 33, -118)\nseen key before\n(2018, 11, 29, 1, 2018, 11, 29, 2, 33, -118)\nseen key before\n(2018, 11, 29, 3, 2018, 11, 29, 4, 33, -118)\nseen key before\n(2018, 11, 29, 2, 2018, 11, 29, 3, 33, -118)\nseen key before\n(2018, 11, 29, 18, 2018, 11, 29, 19, 33, -118)\nseen key before\n(2018, 11, 29, 15, 2018, 11, 29, 16, 33, -118)\nseen key before\n(2018, 11, 29, 17, 2018, 11, 29, 18, 33, -118)\nseen key before\n(2018, 11, 29, 3, 2018, 11, 29, 4, 33, -118)\nseen key before\n(2018, 11, 29, 15, 2018, 11, 29, 16, 33, -118)\nseen key before\n(2018, 11, 29, 7, 2018, 11, 29, 8, 33, -118)\nseen key before\n(2018, 11, 29, 6, 2018, 11, 29, 7, 33, -118)\nseen key before\n(2018, 11, 29, 7, 2018, 11, 29, 8, 33, -118)\nseen key before\n(2018, 11, 29, 9, 2018, 11, 29, 10, 33, -118)\nseen key before\n(2018, 11, 29, 16, 2018, 11, 29, 17, 33, -118)\nseen key before\n(2018, 11, 29, 0, 2018, 11, 29, 1, 33, -118)\nseen key before\n(2018, 11, 29, 12, 2018, 11, 29, 13, 33, -118)\nseen key before\n(2018, 11, 29, 3, 2018, 11, 29, 4, 33, -118)\nseen key before\n(2018, 11, 29, 4, 2018, 11, 29, 5, 33, -118)\nseen key before\n(2018, 12, 13, 16, 2018, 12, 13, 17, 33, -118)\nseen key before\n(2018, 12, 13, 7, 2018, 12, 13, 8, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 1, 2018, 12, 13, 2, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 18, 2018, 12, 13, 19, 33, -118)\nseen key before\n(2018, 12, 13, 2, 2018, 12, 13, 3, 33, -118)\nseen key before\n(2018, 12, 13, 5, 2018, 12, 13, 6, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 3, 2018, 12, 13, 4, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 7, 2018, 12, 13, 8, 33, -118)\nseen key before\n(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 8, 2018, 12, 13, 9, 33, -118)\nseen key before\n(2018, 12, 13, 20, 2018, 12, 13, 21, 33, -118)\nseen key before\n(2018, 12, 13, 12, 2018, 12, 13, 13, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 4, 2018, 12, 13, 5, 33, -118)\nseen key before\n(2018, 12, 13, 12, 2018, 12, 13, 13, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 3, 2018, 12, 13, 4, 33, -118)\nseen key before\n(2018, 12, 13, 0, 2018, 12, 13, 1, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 2, 2018, 12, 13, 3, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 12, 23, 2018, 12, 13, 0, 33, -118)\nseen key before\n(2018, 12, 13, 16, 2018, 12, 13, 17, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 7, 2018, 12, 13, 8, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 12, 2018, 12, 13, 13, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 13, 2018, 12, 13, 14, 33, -118)\nseen key before\n(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 15, 2018, 12, 13, 16, 33, -118)\nseen key before\n(2018, 12, 13, 5, 2018, 12, 13, 6, 33, -118)\nseen key before\n(2018, 12, 13, 19, 2018, 12, 13, 20, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 16, 2018, 12, 13, 17, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\nseen key before\n(2018, 12, 13, 14, 2018, 12, 13, 15, 33, -118)\nseen key before\n(2018, 12, 13, 6, 2018, 12, 13, 7, 33, -118)\nseen key before\n(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\nseen key before\n(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\nseen key before\n(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\nseen key before\n(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\nseen key before\n(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\nseen key before\n(2018, 12, 23, 5, 2018, 12, 23, 6, 33, -118)\nseen key before\n(2018, 12, 23, 9, 2018, 12, 23, 10, 33, -118)\nseen key before\n(2018, 12, 23, 0, 2018, 12, 23, 1, 33, -118)\nseen key before\n(2018, 12, 23, 0, 2018, 12, 23, 1, 33, -118)\nseen key before\n(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\nseen key before\n(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\nseen key before\n(2018, 12, 23, 2, 2018, 12, 23, 3, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\nseen key before\n(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\nseen key before\n(2018, 12, 23, 7, 2018, 12, 23, 8, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 23, 0, 2018, 12, 23, 1, 33, -118)\nseen key before\n(2018, 12, 23, 6, 2018, 12, 23, 7, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\nseen key before\n(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\nseen key before\n(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\nseen key before\n(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\nseen key before\n(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\nseen key before\n(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\nseen key before\n(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\nseen key before\n(2018, 12, 23, 14, 2018, 12, 23, 15, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\nseen key before\n(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\nseen key before\n(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\nseen key before\n(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\nseen key before\n(2018, 12, 23, 12, 2018, 12, 23, 13, 33, -118)\nseen key before\n(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\nseen key before\n(2018, 12, 23, 18, 2018, 12, 23, 19, 33, -118)\nseen key before\n(2018, 12, 23, 7, 2018, 12, 23, 8, 33, -118)\nseen key before\n(2018, 12, 23, 6, 2018, 12, 23, 7, 33, -118)\nseen key before\n(2018, 12, 23, 1, 2018, 12, 23, 2, 33, -118)\nseen key before\n(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\nseen key before\n(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\nseen key before\n(2018, 12, 23, 7, 2018, 12, 23, 8, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\nseen key before\n(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\nseen key before\n(2018, 12, 23, 15, 2018, 12, 23, 16, 33, -118)\nseen key before\n(2018, 12, 23, 4, 2018, 12, 23, 5, 33, -118)\nseen key before\n(2018, 12, 23, 13, 2018, 12, 23, 14, 33, -118)\nseen key before\n(2018, 12, 23, 6, 2018, 12, 23, 7, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\nseen key before\n(2018, 12, 23, 2, 2018, 12, 23, 3, 33, -118)\nseen key before\n(2018, 12, 23, 16, 2018, 12, 23, 17, 33, -118)\nseen key before\n(2018, 12, 23, 3, 2018, 12, 23, 4, 33, -118)\nseen key before\n(2018, 12, 23, 18, 2018, 12, 23, 19, 33, -118)\nseen key before\n(2018, 12, 23, 17, 2018, 12, 23, 18, 33, -118)\nseen key before\n(2018, 12, 22, 23, 2018, 12, 23, 0, 33, -118)\nseen key before\n(2018, 12, 23, 14, 2018, 12, 23, 15, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\nseen key before\n(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\nseen key before\n(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\nseen key before\n(2019, 11, 14, 19, 2019, 11, 14, 20, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\nseen key before\n(2019, 11, 14, 14, 2019, 11, 14, 15, 33, -118)\nseen key before\n(2019, 11, 14, 5, 2019, 11, 14, 6, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 14, 16, 2019, 11, 14, 17, 33, -118)\nseen key before\n(2019, 11, 14, 13, 2019, 11, 14, 14, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 14, 13, 2019, 11, 14, 14, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 14, 14, 2019, 11, 14, 15, 33, -118)\nseen key before\n(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\nseen key before\n(2019, 11, 14, 5, 2019, 11, 14, 6, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 14, 7, 2019, 11, 14, 8, 33, -118)\nseen key before\n(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\nseen key before\n(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\nseen key before\n(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\nseen key before\n(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 3, 2019, 11, 14, 4, 33, -118)\nseen key before\n(2019, 11, 14, 16, 2019, 11, 14, 17, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 14, 2019, 11, 14, 15, 33, -118)\nseen key before\n(2019, 11, 14, 20, 2019, 11, 14, 21, 33, -118)\nseen key before\n(2019, 11, 14, 5, 2019, 11, 14, 6, 33, -118)\nseen key before\n(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\nseen key before\n(2019, 11, 14, 0, 2019, 11, 14, 1, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 13, 2019, 11, 14, 14, 33, -118)\nseen key before\n(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 4, 2019, 11, 14, 5, 33, -118)\nseen key before\n(2019, 11, 14, 16, 2019, 11, 14, 17, 33, -118)\nseen key before\n(2019, 11, 14, 1, 2019, 11, 14, 2, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 7, 2019, 11, 14, 8, 33, -118)\nseen key before\n(2019, 11, 14, 17, 2019, 11, 14, 18, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 13, 23, 2019, 11, 14, 0, 33, -118)\nseen key before\n(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\nseen key before\n(2019, 11, 14, 1, 2019, 11, 14, 2, 33, -118)\nseen key before\n(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\nseen key before\n(2019, 11, 14, 2, 2019, 11, 14, 3, 33, -118)\nseen key before\n(2019, 11, 14, 6, 2019, 11, 14, 7, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 18, 2019, 11, 14, 19, 33, -118)\nseen key before\n(2019, 11, 14, 15, 2019, 11, 14, 16, 33, -118)\nseen key before\n(2019, 11, 14, 1, 2019, 11, 14, 2, 33, -118)\nseen key before\n\n*** WARNING: skipped 4993020 bytes of output ***\n\n2020-12-10 17:00:00   0.5  -3.4  75.2   0.0  ...   NaN  1020.7   NaN   5.0\n\n[1 rows x 11 columns]\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\nseen key before\n(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\nseen key before\n(2020, 12, 10, 2, 2020, 12, 10, 3, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-10 03:00:00  -3.0  -5.5  83.1   0.0  ...   NaN  1023.4   NaN   5.0\n\n[1 rows x 11 columns]\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 20, 2020, 12, 10, 21, 40, -111)\nseen key before\n(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\nseen key before\n(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-10 02:00:00  -2.0  -6.0  74.0   0.0  ...   NaN  1023.3   NaN   5.0\n\n[1 rows x 11 columns]\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\nseen key before\n(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-10 14:00:00  -3.5  -4.4  93.3   0.0  ...   NaN  1020.4   NaN   5.0\n\n[1 rows x 11 columns]\n(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\nseen key before\n(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 18, 2020, 12, 10, 19, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-10 19:00:00   1.0  -3.8  70.2   0.0  ...   NaN  1019.1   NaN   5.0\n\n[1 rows x 11 columns]\n(2020, 12, 10, 19, 2020, 12, 10, 20, 40, -111)\nseen key before\n(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 15, 2020, 12, 10, 16, 40, -111)\nseen key before\n(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\nseen key before\n(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\nseen key before\n(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\nseen key before\n(2020, 12, 10, 15, 2020, 12, 10, 16, 40, -111)\nseen key before\n(2020, 12, 10, 4, 2020, 12, 10, 5, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-10 05:00:00  -4.0  -7.0  80.0   0.0  ...   NaN  1021.8   NaN   5.0\n\n[1 rows x 11 columns]\n(2020, 12, 10, 12, 2020, 12, 10, 13, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-10 13:00:00  -4.0  -5.9  86.8   0.0  ...   NaN  1020.5   NaN   5.0\n\n[1 rows x 11 columns]\n(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\nseen key before\n(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 20, 2020, 12, 10, 21, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\nseen key before\n(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\nseen key before\n(2020, 12, 10, 2, 2020, 12, 10, 3, 40, -111)\nseen key before\n(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\nseen key before\n(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\nseen key before\n(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\nseen key before\n(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\nseen key before\n(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\nseen key before\n(2020, 12, 10, 17, 2020, 12, 10, 18, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\nseen key before\n(2020, 12, 10, 15, 2020, 12, 10, 16, 40, -111)\nseen key before\n(2020, 12, 10, 14, 2020, 12, 10, 15, 40, -111)\nseen key before\n(2020, 12, 10, 2, 2020, 12, 10, 3, 40, -111)\nseen key before\n(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\nseen key before\n(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\nseen key before\n(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\nseen key before\n(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\nseen key before\n(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\nseen key before\n(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\nseen key before\n(2020, 12, 10, 3, 2020, 12, 10, 4, 40, -111)\nseen key before\n(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 13, 2020, 12, 10, 14, 40, -111)\nseen key before\n(2020, 12, 10, 19, 2020, 12, 10, 20, 40, -111)\nseen key before\n(2020, 12, 9, 23, 2020, 12, 10, 0, 40, -111)\nseen key before\n(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\nseen key before\n(2020, 12, 10, 0, 2020, 12, 10, 1, 40, -111)\nseen key before\n(2020, 12, 10, 16, 2020, 12, 10, 17, 40, -111)\nseen key before\n(2020, 12, 10, 1, 2020, 12, 10, 2, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 01:00:00  -5.6  -8.9  78.3   0.0  ...   NaN  1022.3   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 03:00:00  -5.0  -8.4  77.1   0.0  ...   NaN  1024.6   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 17, 2020, 12, 13, 18, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 18:00:00  -3.0  -8.4  66.8   0.0  ...   NaN  1029.1   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\n            temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres  tsun  coco\ntime                                                                           \n2020-12-13  -3.0  -7.9  69.2   0.0   NaN  320.0  15.0   NaN  1021.2   NaN   3.0\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 17:00:00  -4.0  -8.4  71.9   0.0  ...   NaN  1030.2   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 5, 2020, 12, 13, 6, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 06:00:00  -7.5  -9.9  83.4   0.0  ...   NaN  1026.9   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 5, 2020, 12, 13, 6, 40, -111)\nseen key before\n(2020, 12, 13, 18, 2020, 12, 13, 19, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 19:00:00  -2.5  -8.3  64.9   0.0  ...   NaN  1027.8   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 15:00:00  -6.5  -9.9  76.7   0.0  ...   NaN  1029.9   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 20:00:00  -1.0  -8.4  57.8   0.0  ...   NaN  1026.4   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 16:00:00  -5.5  -8.9  77.4   0.0  ...   NaN  1030.0   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 04:00:00  -6.0  -8.9  80.0   0.0  ...   NaN  1025.5   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\nseen key before\n(2020, 12, 13, 18, 2020, 12, 13, 19, 40, -111)\nseen key before\n(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 13:00:00  -7.5  -9.9  83.4   0.0  ...   NaN  1029.4   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\nseen key before\n(2020, 12, 13, 21, 2020, 12, 13, 22, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 22:00:00  -1.0  -8.9  55.9   0.0  ...   NaN  1024.3   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\nseen key before\n(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\nseen key before\n(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\nseen key before\n(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\nseen key before\n(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 13, 2020, 12, 13, 14, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 14:00:00  -7.0  -9.9  79.8   0.0  ...   NaN  1029.6   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 13, 18, 2020, 12, 13, 19, 40, -111)\nseen key before\n(2020, 12, 13, 20, 2020, 12, 13, 21, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 21:00:00  -1.5  -8.3  60.4   0.0  ...   NaN  1025.1   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\nseen key before\n(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\nseen key before\n(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\nseen key before\n(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 17, 2020, 12, 13, 18, 40, -111)\nseen key before\n(2020, 12, 13, 20, 2020, 12, 13, 21, 40, -111)\nseen key before\n(2020, 12, 13, 13, 2020, 12, 13, 14, 40, -111)\nseen key before\n(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\nseen key before\n(2020, 12, 13, 1, 2020, 12, 13, 2, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-13 02:00:00  -4.5  -8.4  74.0   0.0  ...   NaN  1023.4   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 5, 2020, 12, 13, 6, 40, -111)\nseen key before\n(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\nseen key before\n(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\nseen key before\n(2020, 12, 13, 13, 2020, 12, 13, 14, 40, -111)\nseen key before\n(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 2, 2020, 12, 13, 3, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 17, 2020, 12, 13, 18, 40, -111)\nseen key before\n(2020, 12, 12, 23, 2020, 12, 13, 0, 40, -111)\nseen key before\n(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 13, 15, 2020, 12, 13, 16, 40, -111)\nseen key before\n(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\nseen key before\n(2020, 12, 13, 19, 2020, 12, 13, 20, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 21, 2020, 12, 13, 22, 40, -111)\nseen key before\n(2020, 12, 13, 20, 2020, 12, 13, 21, 40, -111)\nseen key before\n(2020, 12, 13, 3, 2020, 12, 13, 4, 40, -111)\nseen key before\n(2020, 12, 13, 12, 2020, 12, 13, 13, 40, -111)\nseen key before\n(2020, 12, 13, 1, 2020, 12, 13, 2, 40, -111)\nseen key before\n(2020, 12, 13, 0, 2020, 12, 13, 1, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 13, 14, 2020, 12, 13, 15, 40, -111)\nseen key before\n(2020, 12, 13, 16, 2020, 12, 13, 17, 40, -111)\nseen key before\n(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 03:00:00   4.6   0.1  72.9   0.0  ...   NaN  1018.5   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 12, 2020, 12, 22, 13, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 13:00:00   5.6  -1.0  62.9   0.0  ...   NaN  1010.7   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 05:00:00   5.6   0.6  70.5   0.0  ...   NaN  1015.6   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 3, 2020, 12, 22, 4, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 04:00:00   6.1   0.6  67.9   0.0  ...   NaN  1017.2   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 15:00:00   7.0  -0.9  57.0   0.0  ...   NaN  1010.0   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 18, 2020, 12, 22, 19, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 19:00:00   2.0  -2.9  70.2   0.0  ...   NaN  1013.2   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 17:00:00   6.6  -0.3  61.5   0.0  ...   NaN  1010.6   NaN   7.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 3, 2020, 12, 22, 4, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 01:00:00   5.1   0.6  72.9   0.0  ...   NaN  1019.2   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\nseen key before\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\nseen key before\n(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 18:00:00   3.5  -1.5  70.2   0.0  ...   NaN  1012.1   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\nseen key before\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\nseen key before\n(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\nseen key before\n(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 1, 2020, 12, 22, 2, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 02:00:00   5.1   0.6  73.2   0.0  ...   NaN  1018.6   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\n            temp  dwpt  rhum  prcp  snow   wdir  wspd  wpgt    pres  tsun  coco\ntime                                                                           \n2020-12-22   5.0   0.1  70.5   0.0   NaN  212.0   0.0   NaN  1019.8   NaN   3.0\n(2020, 12, 22, 20, 2020, 12, 22, 21, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 21:00:00   1.5  -8.8  47.4   0.0  ...   NaN  1015.1   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 15, 2020, 12, 22, 16, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 16:00:00   5.6  -0.5  65.6   0.0  ...   NaN  1010.5   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\nseen key before\n(2020, 12, 22, 12, 2020, 12, 22, 13, 40, -111)\nseen key before\n(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\nseen key before\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\nseen key before\n(2020, 12, 22, 20, 2020, 12, 22, 21, 40, -111)\nseen key before\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\nseen key before\n(2020, 12, 22, 19, 2020, 12, 22, 20, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 20:00:00   1.0  -4.4  68.5   0.0  ...   NaN  1014.4   NaN  14.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 3, 2020, 12, 22, 4, 40, -111)\nseen key before\n(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\nseen key before\n(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 5, 2020, 12, 22, 6, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 06:00:00   6.0   0.1  66.2   0.0  ...   NaN  1016.6   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\nseen key before\n(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\nseen key before\n(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\nseen key before\n(2020, 12, 22, 14, 2020, 12, 22, 15, 40, -111)\nseen key before\n(2020, 12, 21, 23, 2020, 12, 22, 0, 40, -111)\nseen key before\n(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\nseen key before\n(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\nseen key before\n(2020, 12, 22, 11, 2020, 12, 22, 12, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 12:00:00   6.0  -1.9  57.0   0.0  ...   NaN  1011.1   NaN   2.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 16, 2020, 12, 22, 17, 40, -111)\nseen key before\n(2020, 12, 22, 13, 2020, 12, 22, 14, 40, -111)\n                     temp  dwpt  rhum  prcp  ...  wpgt    pres  tsun  coco\ntime                                         ...                          \n2020-12-22 14:00:00   7.5  -0.9  55.7   0.0  ...   NaN  1010.4   NaN   3.0\n\n[1 rows x 11 columns]\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 4, 2020, 12, 22, 5, 40, -111)\nseen key before\n(2020, 12, 22, 0, 2020, 12, 22, 1, 40, -111)\nseen key before\n(2020, 12, 22, 17, 2020, 12, 22, 18, 40, -111)\nseen key before\n(2020, 12, 22, 20, 2020, 12, 22, 21, 40, -111)\nseen key before\n(2020, 12, 22, 2, 2020, 12, 22, 3, 40, -111)\nseen key before\n(2020, 12, 22, 18, 2020, 12, 22, 19, 40, -111)\nseen key before\n/local_disk0/tmp/1615657111681-0/PythonShell.py:174: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;],\n      dtype=&#39;object&#39;)\n22029\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 22029 entries, 15172 to 283293\nData columns (total 17 columns):\n #   Column                   Non-Null Count  Dtype         \n---  ------                   --------------  -----         \n 0   From                     22029 non-null  object        \n 1   Icao                     22029 non-null  object        \n 2   Op                       22029 non-null  object        \n 3   To                       22029 non-null  object        \n 4   StartTime                22029 non-null  object        \n 5   LiftOffTime              22029 non-null  object        \n 6   TouchDownTime            22029 non-null  object        \n 7   StopTime                 22029 non-null  object        \n 8   FromLat                  22029 non-null  float64       \n 9   FromLong                 22029 non-null  float64       \n 10  ToLat                    22029 non-null  float64       \n 11  ToLong                   22029 non-null  float64       \n 12  RunwayWaitTimeInSeconds  22029 non-null  int32         \n 13  OtherDepartures          22029 non-null  int32         \n 14  FlightDuration           22029 non-null  int32         \n 15  DayType                  22029 non-null  object        \n 16  WeatherTime              22027 non-null  datetime64[ns]\ndtypes: datetime64[ns](1), float64(4), int32(3), object(9)\nmemory usage: 2.8+ MB\nNone\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For DEBUGGING\n",
    "# need rerun due to IndexError: 'LAX'\n",
    "# also run them in batches to save as much data as possible\n",
    "# need to run manually and  print out one call at a time to figure out why\n",
    "# build weather dict separately\n",
    "# num_batches = len(dfpWeather8Temp) // 2400 # 2400 flights ~ 10 minutes if uncached\n",
    "\n",
    "# dataset_size = 24001\n",
    "# batch_size = 3000\n",
    "# num_batches, remainder = dataset_size // batch_size, dataset_size % batch_size\n",
    "# ap = 'LAX-'\n",
    "\n",
    "# dfRand = pd.DataFrame(np.random.randint(0,100,size=(dataset_size, 4)), columns=list('ABCD'))\n",
    "# batches = []\n",
    "\n",
    "# if remainder > 0:\n",
    "#   num_batches += 1\n",
    "# for batch_num in range(num_batches):\n",
    "#   batch_name = ap + str(batch_num)\n",
    "#   batch = dfRand.loc[batch_num * batch_size : ((batch_num+1) * batch_size)-1:]\n",
    "#   batches.append(batch)\n",
    "  \n",
    "# next in line: 'PHL', 'LGA', 'EWR', 'MSP', 'MCO', 'BOS', 'TPA', 'MIA', 'IAD', 'FLL', 'DTW', 'IAH'\n",
    "\n",
    "rerun_airports = ['LAX', 'SLC']\n",
    "# weatherDictRerun = dict() # comment this out if wanna rerun\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import s3fs\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "stopwatch_start = datetime.now()\n",
    "print(f'Actual Start time = {stopwatch_start}')\n",
    "\n",
    "from meteostat import Point, Daily\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def weather2(startTime, liftOffTime, lat, long, key): \n",
    "#   start, end = startTime, liftOffTime \n",
    "  start, end = pd.to_datetime(startTime), pd.to_datetime(liftOffTime)\n",
    "  start = start - timedelta(hours=1)\n",
    "  end = start + timedelta(hours=1)\n",
    "  lookupKey = (start.year, start.month, start.day, start.hour, end.year, end.month, end.day, end.hour, int(lat), int(long))\n",
    "#   lookupKey = (start.year, start.month, start.day, start.hour, int(lat), int(long))\n",
    "  print(lookupKey)\n",
    "#   print(startTime)\n",
    "#   print(liftOffTime)\n",
    "#   print(lat)\n",
    "#   print(long)\n",
    "  \n",
    "  if lookupKey not in weatherDictRerun:\n",
    "    location = Point(lat, long)\n",
    "    \n",
    "    try:\n",
    "      data = Hourly(location, start, end)\n",
    "    except IndexError:\n",
    "      weatherDictRerun[lookupKey] = {}\n",
    "      return np.nan\n",
    "#       pass\n",
    "    else:\n",
    "#       data = Hourly(location, start, end)\n",
    "      data = data.fetch()\n",
    "\n",
    "      print(data)\n",
    "#       print(f'levels = {data.index.nlevels}')\n",
    "\n",
    "      if data.index.nlevels > 1:\n",
    "  #       print(f'levels = {data.index.nlevels}')\n",
    "  #       print(lookupKey)\n",
    "  #       print(data)\n",
    "        weatherDictRerun[lookupKey] = {}\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "      if len(data) > 1:\n",
    "        result = data.reset_index().loc[[0]].to_dict('list')\n",
    "      else:\n",
    "        result = data.reset_index().to_dict('list')\n",
    "\n",
    "      if (len(result['temp']) > 0 and result['temp'][0]):\n",
    "        result['temp'][0] = round((result['temp'][0] * 1.8) + 32, 2)\n",
    "\n",
    "      for var in ['snow', 'wpgt', 'tsun']:\n",
    "        if (len(result[var]) > 0 and np.isnan(result[var][0])):\n",
    "          result[var][0] = 0.0\n",
    "\n",
    "      #  Make sure the scheme data type for ConditionCode match as well. Either DoubleType or StringType\n",
    "      condition_codes = {1: 'Clear', 2: 'Fair', 3: 'Cloudy', \\\n",
    "                         4:\t'Overcast', 5: 'Fog', 6: 'Freezing Fog', \\\n",
    "                         7:\t'Light Rain', 8: 'Rain', 9:\t'Heavy Rain', \\\n",
    "                         10: 'Freezing Rain', 11: 'Heavy Freezing Rain', \\\n",
    "                         12: 'Sleet', 13: 'Heavy Sleet', 14: 'Light Snowfall', \\\n",
    "                         15: 'Snowfall', 16: 'Heavy Snowfall', 17: 'Rain Shower', \\\n",
    "                         18: 'Heavy Rain Shower', 19: 'Sleet Shower', 20: 'Heavy Sleet Shower', \\\n",
    "                         21: 'Snow Shower', 22: 'Heavy Snow Shower', 23: 'Lightning', \\\n",
    "                         24: 'Hail', 25: 'Thunderstorm', 26: 'Heavy Thunderstorm', 27: 'Storm'}\n",
    "\n",
    "      if ( (len(result['coco']) > 0) and (not np.isnan(result['coco'][0])) ):\n",
    "        if int(result['coco'][0]) in condition_codes:\n",
    "          result['coco'][0] = condition_codes[int(result['coco'][0])]\n",
    "        else:\n",
    "          result['coco'][0] = 'Unknown'\n",
    "\n",
    "      keys = ['time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']\n",
    "      results = [result[key][0] if (key in result and len(result[key]) > 0) else None for key in keys]\n",
    "      weatherDictRerun[lookupKey] = {keys[i] : results[i] for i in range(len(keys))}\n",
    "  else:\n",
    "    print('seen key before')\n",
    "    \n",
    "  return weatherDictRerun[lookupKey][key] if len(weatherDictRerun[lookupKey]) > 0 else np.nan\n",
    "\n",
    "\n",
    "for airport in rerun_airports:\n",
    "  \n",
    "  dfWeather8 = spark.read.options(delimiter='|', inferSchema='True', header='True')\\\n",
    "                      .csv('s3://<BUCKET_NAME>/flights-csv/full-data/full-data-280k.csv')\n",
    "  spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "  dfpWeather8 = dfWeather8.toPandas()\n",
    "  \n",
    "  print(f'Processing airport {airport}')\n",
    "  dfpWeather8Temp = dfpWeather8[dfpWeather8['From'] == airport]\n",
    "  print(f'Size of {airport} flights = {len(dfpWeather8Temp)}')\n",
    "  \n",
    "  est_uniq_days = dfpWeather8Temp['StartTime'].apply(lambda x: (pd.to_datetime(x) - timedelta(hours=1)).strftime('%Y-%m-%d-%H')).nunique()\n",
    "  print(f'Estimated Time = { est_uniq_days // 100 } minutes')\n",
    "  \n",
    "#   dataset_size = len(dfpWeather8Temp)\n",
    "#   batch_size = 3000\n",
    "#   num_batches, remainder = dataset_size // batch_size, dataset_size % batch_size\n",
    "\n",
    "#   batches = []\n",
    "#   batch_names = []\n",
    "\n",
    "#   if remainder > 0:\n",
    "#     num_batches += 1\n",
    "    \n",
    "#   for batch_num in range(num_batches):\n",
    "#     batch_name = airport + '-' + str(batch_num)\n",
    "#     print(f'Batch name = {batch_name}')\n",
    "#     batch_names.append(batch_name)\n",
    "    \n",
    "#     batch = dfpWeather8.loc[batch_num * batch_size : ((batch_num+1) * batch_size)-1:]\n",
    "#     batches.append(batch)\n",
    "  \n",
    "#   keys = {'time' : 'WeatherTime', 'temp' : 'Temperature', 'dwpt' : 'Dewpoint', 'rhum' : 'RelativeHumidity', 'prcp' : 'Precipitation', 'snow' : 'SnowLevel', 'wdir' : 'WindDirection', 'wspd' : 'WindSpeed', 'wpgt' : 'PeakWindGust', 'pres' : 'AirPressure', 'tsun' : 'Sunshine', 'coco' : 'ConditionCode'}\n",
    "#   keys = ['time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']\n",
    "#   desc = ['WeatherTime', 'Temperature', 'Dewpoint', 'RelativeHumidity', 'Precipitation', 'SnowLevel', 'WindDirection', 'WindSpeed', 'PeakWindGust', 'AirPressure', 'Sunshine', 'ConditionCode']\n",
    "  \n",
    "  keys = ['time']\n",
    "  desc = ['WeatherTime']\n",
    "  results = []\n",
    "  \n",
    "  for key in keys:\n",
    "    print(key)\n",
    "    # loop through each row, no vectorization\n",
    "    result = [weather2(row[0], row[1], row[2], row[3], key) for row in zip(dfpWeather8Temp['StartTime'], dfpWeather8Temp['LiftOffTime'], dfpWeather8Temp['FromLat'], dfpWeather8Temp['FromLong'])]\n",
    "    results.append(result)\n",
    "  \n",
    "  for desc, result in zip(desc, results):\n",
    "    dfpWeather8Temp[desc] = pd.Series(result).values\n",
    "  \n",
    "  print(dfpWeather8Temp.columns)\n",
    "  print(len(dfpWeather8Temp))\n",
    "  print(dfpWeather8Temp.info())\n",
    "  dfpWeather8Temp.head(20)\n",
    "#     for index, row in dfpWeather8Temp.iterrows():\n",
    "#       dfpWeather8Temp[keys[key]] = weather2(dfpWeather8Temp['StartTime'], dfpWeather8Temp['LiftOffTime'], dfpWeather8Temp['FromLat'], dfpWeather8Temp['FromLong'], key)\n",
    "#     batch[keys[key]] = np.vectorize(weather2, otypes=[\"O\"]) (batch['StartTime'], batch['LiftOffTime'], batch['FromLat'], batch['FromLong'], key)\n",
    "\n",
    "# access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "# secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "# sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "# sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "# bytes_to_write = dfpWeather8Temp.to_csv(None, sep='|', index=False).encode()\n",
    "# fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "# with fs.open(f's3://runway-wait-time-data/flights-csv/full-data/weather-by-airport-csv/{airport}.csv', 'wb') as f:\n",
    "#   f.write(bytes_to_write)\n",
    "\n",
    "# print(f'Done Processing airport {batch_name} csv')\n",
    "\n",
    "\n",
    "# # Serialize weather dict\n",
    "# access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "# secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "# sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "# sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "# bytes_to_write = pickle.dumps(weatherDict)\n",
    "# fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "\n",
    "# with fs.open(f's3://runway-wait-time-data/flights-csv/full-data/weather-by-airport-pickle/{airport}.pkl', 'wb') as f:\n",
    "#   f.write(bytes_to_write)  \n",
    "\n",
    "# print(f'Done Processing airport {airport} pickle')\n",
    "  \n",
    "  \n",
    "# stopwatch_end = datetime.now()\n",
    "# print(f'Actual End time = {stopwatch_end}')\n",
    "# print(f'Actual time elapsed = {(stopwatch_end - stopwatch_start).seconds / 60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2dc2c844-8920-4cc7-9bd0-14bb90743bcf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Use Pandas to process Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2ff460b7-f4f5-47e3-aabe-ab15e36d8c9c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Collecting s3fs\n",
       "  Downloading s3fs-0.5.2-py3-none-any.whl (22 kB)\n",
       "Collecting aiobotocore&gt;=1.0.1\n",
       "  Downloading aiobotocore-1.2.2.tar.gz (48 kB)\n",
       "Collecting fsspec&gt;=0.8.0\n",
       "  Downloading fsspec-0.8.7-py3-none-any.whl (103 kB)\n",
       "Collecting botocore&lt;1.19.53,&gt;=1.19.52\n",
       "  Downloading botocore-1.19.52-py2.py3-none-any.whl (7.2 MB)\n",
       "Collecting aiohttp&gt;=3.3.1\n",
       "  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\n",
       "Collecting wrapt&gt;=1.10.10\n",
       "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
       "Collecting aioitertools&gt;=0.5.1\n",
       "  Downloading aioitertools-0.7.1-py3-none-any.whl (20 kB)\n",
       "Collecting multidict&lt;7.0,&gt;=4.5\n",
       "  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\n",
       "Collecting typing-extensions&gt;=3.6.5\n",
       "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
       "Collecting async-timeout&lt;4.0,&gt;=3.0\n",
       "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
       "Collecting yarl&lt;2.0,&gt;=1.0\n",
       "  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\n",
       "Collecting attrs&gt;=17.3.0\n",
       "  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
       "Requirement already satisfied: chardet&lt;5.0,&gt;=2.0 in /usr/lib/python3/dist-packages (from aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (3.0.4)\n",
       "Requirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (0.10.0)\n",
       "Requirement already satisfied: urllib3&lt;1.27,&gt;=1.25.4 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.25.8)\n",
       "Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8.1)\n",
       "Collecting importlib-metadata\n",
       "  Downloading importlib_metadata-3.7.2-py3-none-any.whl (11 kB)\n",
       "Requirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.14.0)\n",
       "Requirement already satisfied: idna&gt;=2.0 in /databricks/python3/lib/python3.7/site-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8)\n",
       "Collecting zipp&gt;=0.5\n",
       "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
       "Building wheels for collected packages: aiobotocore, wrapt\n",
       "  Building wheel for aiobotocore (setup.py): started\n",
       "  Building wheel for aiobotocore (setup.py): finished with status &#39;done&#39;\n",
       "  Created wheel for aiobotocore: filename=aiobotocore-1.2.2-py3-none-any.whl size=45731 sha256=583f31bc84a1c7e98b5e95ade6467188a649a44e8175cef32c1213ed42753c98\n",
       "  Stored in directory: /home/root/.cache/pip/wheels/2c/46/86/839f72195fdae70cd5286a9824841c7ea9ca514f4ac2eb43eb\n",
       "  Building wheel for wrapt (setup.py): started\n",
       "  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n",
       "  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68705 sha256=1e6c22c71af0f7d57bdc3a09d316c02c55b571c906b6c0755522281fc46e8c84\n",
       "  Stored in directory: /home/root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\n",
       "Successfully built aiobotocore wrapt\n",
       "Installing collected packages: typing-extensions, multidict, zipp, yarl, attrs, async-timeout, wrapt, importlib-metadata, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n",
       "  Attempting uninstall: botocore\n",
       "    Found existing installation: botocore 1.15.0\n",
       "    Not uninstalling botocore at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f49a5e6f-0a3f-4212-a140-f2b2abce625e\n",
       "    Can&#39;t uninstall &#39;botocore&#39;. No files were found to uninstall.\n",
       "ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
       "boto3 1.12.0 requires botocore&lt;1.16.0,&gt;=1.15.0, but you have botocore 1.19.52 which is incompatible.\n",
       "Successfully installed aiobotocore-1.2.2 aiohttp-3.7.4.post0 aioitertools-0.7.1 async-timeout-3.0.1 attrs-20.3.0 botocore-1.19.52 fsspec-0.8.7 importlib-metadata-3.7.2 multidict-5.1.0 s3fs-0.5.2 typing-extensions-3.7.4.3 wrapt-1.12.1 yarl-1.6.3 zipp-3.4.1\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting s3fs\n  Downloading s3fs-0.5.2-py3-none-any.whl (22 kB)\nCollecting aiobotocore&gt;=1.0.1\n  Downloading aiobotocore-1.2.2.tar.gz (48 kB)\nCollecting fsspec&gt;=0.8.0\n  Downloading fsspec-0.8.7-py3-none-any.whl (103 kB)\nCollecting botocore&lt;1.19.53,&gt;=1.19.52\n  Downloading botocore-1.19.52-py2.py3-none-any.whl (7.2 MB)\nCollecting aiohttp&gt;=3.3.1\n  Downloading aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3 MB)\nCollecting wrapt&gt;=1.10.10\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\nCollecting aioitertools&gt;=0.5.1\n  Downloading aioitertools-0.7.1-py3-none-any.whl (20 kB)\nCollecting multidict&lt;7.0,&gt;=4.5\n  Downloading multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142 kB)\nCollecting typing-extensions&gt;=3.6.5\n  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nCollecting async-timeout&lt;4.0,&gt;=3.0\n  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\nCollecting yarl&lt;2.0,&gt;=1.0\n  Downloading yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294 kB)\nCollecting attrs&gt;=17.3.0\n  Downloading attrs-20.3.0-py2.py3-none-any.whl (49 kB)\nRequirement already satisfied: chardet&lt;5.0,&gt;=2.0 in /usr/lib/python3/dist-packages (from aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (3.0.4)\nRequirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (0.10.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.25.4 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.25.8)\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /databricks/python3/lib/python3.7/site-packages (from botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8.1)\nCollecting importlib-metadata\n  Downloading importlib_metadata-3.7.2-py3-none-any.whl (11 kB)\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.19.53,&gt;=1.19.52-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (1.14.0)\nRequirement already satisfied: idna&gt;=2.0 in /databricks/python3/lib/python3.7/site-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp&gt;=3.3.1-&gt;aiobotocore&gt;=1.0.1-&gt;s3fs) (2.8)\nCollecting zipp&gt;=0.5\n  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\nBuilding wheels for collected packages: aiobotocore, wrapt\n  Building wheel for aiobotocore (setup.py): started\n  Building wheel for aiobotocore (setup.py): finished with status &#39;done&#39;\n  Created wheel for aiobotocore: filename=aiobotocore-1.2.2-py3-none-any.whl size=45731 sha256=583f31bc84a1c7e98b5e95ade6467188a649a44e8175cef32c1213ed42753c98\n  Stored in directory: /home/root/.cache/pip/wheels/2c/46/86/839f72195fdae70cd5286a9824841c7ea9ca514f4ac2eb43eb\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status &#39;done&#39;\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp37-cp37m-linux_x86_64.whl size=68705 sha256=1e6c22c71af0f7d57bdc3a09d316c02c55b571c906b6c0755522281fc46e8c84\n  Stored in directory: /home/root/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6\nSuccessfully built aiobotocore wrapt\nInstalling collected packages: typing-extensions, multidict, zipp, yarl, attrs, async-timeout, wrapt, importlib-metadata, botocore, aioitertools, aiohttp, fsspec, aiobotocore, s3fs\n  Attempting uninstall: botocore\n    Found existing installation: botocore 1.15.0\n    Not uninstalling botocore at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f49a5e6f-0a3f-4212-a140-f2b2abce625e\n    Can&#39;t uninstall &#39;botocore&#39;. No files were found to uninstall.\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nboto3 1.12.0 requires botocore&lt;1.16.0,&gt;=1.15.0, but you have botocore 1.19.52 which is incompatible.\nSuccessfully installed aiobotocore-1.2.2 aiohttp-3.7.4.post0 aioitertools-0.7.1 async-timeout-3.0.1 attrs-20.3.0 botocore-1.19.52 fsspec-0.8.7 importlib-metadata-3.7.2 multidict-5.1.0 s3fs-0.5.2 typing-extensions-3.7.4.3 wrapt-1.12.1 yarl-1.6.3 zipp-3.4.1\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c7c51a27-8604-4731-816c-a3d59ac5407d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Python interpreter will be restarted.\n",
       "Collecting meteostat\n",
       "  Downloading meteostat-1.1.1.tar.gz (11 kB)\n",
       "Collecting pandas&gt;=1.1\n",
       "  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
       "Requirement already satisfied: pytz in /databricks/python3/lib/python3.7/site-packages (from meteostat) (2019.3)\n",
       "Requirement already satisfied: numpy in /databricks/python3/lib/python3.7/site-packages (from meteostat) (1.18.1)\n",
       "Requirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.7/site-packages (from pandas&gt;=1.1-&gt;meteostat) (2.8.1)\n",
       "Requirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=1.1-&gt;meteostat) (1.14.0)\n",
       "Building wheels for collected packages: meteostat\n",
       "  Building wheel for meteostat (setup.py): started\n",
       "  Building wheel for meteostat (setup.py): finished with status &#39;done&#39;\n",
       "  Created wheel for meteostat: filename=meteostat-1.1.1-py3-none-any.whl size=15528 sha256=0f58c494af80d61909d42ac7d98fdbf3925f0da99a769e416217bfe041d56782\n",
       "  Stored in directory: /home/root/.cache/pip/wheels/21/b0/11/b84ba37a06a41e37e26d99147327fb32af1662bf9b366dc616\n",
       "Successfully built meteostat\n",
       "Installing collected packages: pandas, meteostat\n",
       "  Attempting uninstall: pandas\n",
       "    Found existing installation: pandas 1.0.1\n",
       "    Not uninstalling pandas at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f49a5e6f-0a3f-4212-a140-f2b2abce625e\n",
       "    Can&#39;t uninstall &#39;pandas&#39;. No files were found to uninstall.\n",
       "Successfully installed meteostat-1.1.1 pandas-1.2.3\n",
       "Python interpreter will be restarted.\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting meteostat\n  Downloading meteostat-1.1.1.tar.gz (11 kB)\nCollecting pandas&gt;=1.1\n  Downloading pandas-1.2.3-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.7/site-packages (from meteostat) (2019.3)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.7/site-packages (from meteostat) (1.18.1)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.7/site-packages (from pandas&gt;=1.1-&gt;meteostat) (2.8.1)\nRequirement already satisfied: six&gt;=1.5 in /databricks/python3/lib/python3.7/site-packages (from python-dateutil&gt;=2.7.3-&gt;pandas&gt;=1.1-&gt;meteostat) (1.14.0)\nBuilding wheels for collected packages: meteostat\n  Building wheel for meteostat (setup.py): started\n  Building wheel for meteostat (setup.py): finished with status &#39;done&#39;\n  Created wheel for meteostat: filename=meteostat-1.1.1-py3-none-any.whl size=15528 sha256=0f58c494af80d61909d42ac7d98fdbf3925f0da99a769e416217bfe041d56782\n  Stored in directory: /home/root/.cache/pip/wheels/21/b0/11/b84ba37a06a41e37e26d99147327fb32af1662bf9b366dc616\nSuccessfully built meteostat\nInstalling collected packages: pandas, meteostat\n  Attempting uninstall: pandas\n    Found existing installation: pandas 1.0.1\n    Not uninstalling pandas at /databricks/python3/lib/python3.7/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-f49a5e6f-0a3f-4212-a140-f2b2abce625e\n    Can&#39;t uninstall &#39;pandas&#39;. No files were found to uninstall.\nSuccessfully installed meteostat-1.1.1 pandas-1.2.3\nPython interpreter will be restarted.\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pip install meteostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bfdc43e4-c454-4925-b1a2-8bf8455285ac",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Processing ATL.pkl\n",
       "Processing CLT.pkl\n",
       "Processing MDW.pkl\n",
       "Processing JFK.pkl\n",
       "Processing ORD.pkl\n",
       "Processing DFW.pkl\n",
       "Processing SEA.pkl\n",
       "Processing SFO.pkl\n",
       "Processing DEN.pkl\n",
       "Processing PHX.pkl\n",
       "Processing PDX.pkl\n",
       "Processing LAS.pkl\n",
       "Processing PHL.pkl\n",
       "Processing LGA.pkl\n",
       "Processing EWR.pkl\n",
       "Processing MSP.pkl\n",
       "Processing MCO.pkl\n",
       "Processing BOS.pkl\n",
       "Processing TPA.pkl\n",
       "Processing MIA.pkl\n",
       "Processing IAD.pkl\n",
       "Processing FLL.pkl\n",
       "Processing DTW.pkl\n",
       "Processing IAH.pkl\n",
       "Processing LAX.pkl\n",
       "Processing SLC.pkl\n",
       "Size of weather dictionary = 62992\n",
       "Actual Start time = 2021-03-14 03:12:11.557635\n",
       "Processing airport ATL\n",
       "Size of ATL flights before = 353\n",
       "Estimated Time = 2 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of ATL flights without nulls = 350\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport ATL csv\n",
       "Done Processing airport ATL pickle\n",
       "Processing airport CLT\n",
       "Size of CLT flights before = 635\n",
       "Estimated Time = 1 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of CLT flights without nulls = 0\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport CLT csv\n",
       "Done Processing airport CLT pickle\n",
       "Processing airport MDW\n",
       "Size of MDW flights before = 641\n",
       "Estimated Time = 4 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of MDW flights without nulls = 641\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport MDW csv\n",
       "Done Processing airport MDW pickle\n",
       "Processing airport JFK\n",
       "Size of JFK flights before = 11341\n",
       "Estimated Time = 36 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of JFK flights without nulls = 11341\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport JFK csv\n",
       "Done Processing airport JFK pickle\n",
       "Processing airport ORD\n",
       "Size of ORD flights before = 17181\n",
       "Estimated Time = 30 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of ORD flights without nulls = 17181\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport ORD csv\n",
       "Done Processing airport ORD pickle\n",
       "Processing airport DFW\n",
       "Size of DFW flights before = 21337\n",
       "Estimated Time = 28 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of DFW flights without nulls = 21062\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport DFW csv\n",
       "Done Processing airport DFW pickle\n",
       "Processing airport SEA\n",
       "Size of SEA flights before = 21213\n",
       "Estimated Time = 32 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of SEA flights without nulls = 21213\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport SEA csv\n",
       "Done Processing airport SEA pickle\n",
       "Processing airport SFO\n",
       "Size of SFO flights before = 23443\n",
       "Estimated Time = 47 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of SFO flights without nulls = 22959\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport SFO csv\n",
       "Done Processing airport SFO pickle\n",
       "Processing airport DEN\n",
       "Size of DEN flights before = 23493\n",
       "Estimated Time = 33 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of DEN flights without nulls = 23303\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport DEN csv\n",
       "Done Processing airport DEN pickle\n",
       "Processing airport PHX\n",
       "Size of PHX flights before = 25887\n",
       "Estimated Time = 48 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of PHX flights without nulls = 25601\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport PHX csv\n",
       "Done Processing airport PHX pickle\n",
       "Processing airport PDX\n",
       "Size of PDX flights before = 3800\n",
       "Estimated Time = 17 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of PDX flights without nulls = 3792\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport PDX csv\n",
       "Done Processing airport PDX pickle\n",
       "Processing airport LAS\n",
       "Size of LAS flights before = 23042\n",
       "Estimated Time = 48 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of LAS flights without nulls = 22910\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport LAS csv\n",
       "Done Processing airport LAS pickle\n",
       "Processing airport PHL\n",
       "Size of PHL flights before = 13725\n",
       "Estimated Time = 38 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of PHL flights without nulls = 13725\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport PHL csv\n",
       "Done Processing airport PHL pickle\n",
       "Processing airport LGA\n",
       "Size of LGA flights before = 10308\n",
       "Estimated Time = 33 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of LGA flights without nulls = 10308\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport LGA csv\n",
       "Done Processing airport LGA pickle\n",
       "Processing airport EWR\n",
       "Size of EWR flights before = 9401\n",
       "Estimated Time = 32 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of EWR flights without nulls = 9399\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport EWR csv\n",
       "Done Processing airport EWR pickle\n",
       "Processing airport MSP\n",
       "Size of MSP flights before = 6301\n",
       "Estimated Time = 16 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of MSP flights without nulls = 6301\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport MSP csv\n",
       "Done Processing airport MSP pickle\n",
       "Processing airport MCO\n",
       "Size of MCO flights before = 5767\n",
       "Estimated Time = 17 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of MCO flights without nulls = 5705\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport MCO csv\n",
       "Done Processing airport MCO pickle\n",
       "Processing airport BOS\n",
       "Size of BOS flights before = 5194\n",
       "Estimated Time = 20 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of BOS flights without nulls = 5194\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport BOS csv\n",
       "Done Processing airport BOS pickle\n",
       "Processing airport TPA\n",
       "Size of TPA flights before = 3928\n",
       "Estimated Time = 13 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of TPA flights without nulls = 3898\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport TPA csv\n",
       "Done Processing airport TPA pickle\n",
       "Processing airport MIA\n",
       "Size of MIA flights before = 2180\n",
       "Estimated Time = 8 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of MIA flights without nulls = 2180\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport MIA csv\n",
       "Done Processing airport MIA pickle\n",
       "Processing airport IAD\n",
       "Size of IAD flights before = 1998\n",
       "Estimated Time = 10 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of IAD flights without nulls = 1972\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport IAD csv\n",
       "Done Processing airport IAD pickle\n",
       "Processing airport FLL\n",
       "Size of FLL flights before = 759\n",
       "Estimated Time = 4 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of FLL flights without nulls = 751\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport FLL csv\n",
       "Done Processing airport FLL pickle\n",
       "Processing airport DTW\n",
       "Size of DTW flights before = 47\n",
       "Estimated Time = 0 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of DTW flights without nulls = 47\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport DTW csv\n",
       "Done Processing airport DTW pickle\n",
       "Processing airport IAH\n",
       "Size of IAH flights before = 42\n",
       "Estimated Time = 0 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of IAH flights without nulls = 41\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport IAH csv\n",
       "Done Processing airport IAH pickle\n",
       "Processing airport LAX\n",
       "Size of LAX flights before = 29411\n",
       "Estimated Time = 48 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of LAX flights without nulls = 29213\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport LAX csv\n",
       "Done Processing airport LAX pickle\n",
       "Processing airport SLC\n",
       "Size of SLC flights before = 22029\n",
       "Estimated Time = 39 minutes\n",
       "time\n",
       "/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \n",
       "A value is trying to be set on a copy of a slice from a DataFrame.\n",
       "Try using .loc[row_indexer,col_indexer] = value instead\n",
       "\n",
       "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
       "temp\n",
       "dwpt\n",
       "rhum\n",
       "prcp\n",
       "snow\n",
       "wdir\n",
       "wspd\n",
       "wpgt\n",
       "pres\n",
       "tsun\n",
       "coco\n",
       "Size of SLC flights without nulls = 22018\n",
       "Index([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n",
       "       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n",
       "       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n",
       "       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n",
       "       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "Done Processing airport SLC csv\n",
       "Done Processing airport SLC pickle\n",
       "Actual End time = 2021-03-14 03:30:06.794144\n",
       "Actual time elapsed = 17.916666666666668\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Processing ATL.pkl\nProcessing CLT.pkl\nProcessing MDW.pkl\nProcessing JFK.pkl\nProcessing ORD.pkl\nProcessing DFW.pkl\nProcessing SEA.pkl\nProcessing SFO.pkl\nProcessing DEN.pkl\nProcessing PHX.pkl\nProcessing PDX.pkl\nProcessing LAS.pkl\nProcessing PHL.pkl\nProcessing LGA.pkl\nProcessing EWR.pkl\nProcessing MSP.pkl\nProcessing MCO.pkl\nProcessing BOS.pkl\nProcessing TPA.pkl\nProcessing MIA.pkl\nProcessing IAD.pkl\nProcessing FLL.pkl\nProcessing DTW.pkl\nProcessing IAH.pkl\nProcessing LAX.pkl\nProcessing SLC.pkl\nSize of weather dictionary = 62992\nActual Start time = 2021-03-14 03:12:11.557635\nProcessing airport ATL\nSize of ATL flights before = 353\nEstimated Time = 2 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of ATL flights without nulls = 350\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport ATL csv\nDone Processing airport ATL pickle\nProcessing airport CLT\nSize of CLT flights before = 635\nEstimated Time = 1 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of CLT flights without nulls = 0\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport CLT csv\nDone Processing airport CLT pickle\nProcessing airport MDW\nSize of MDW flights before = 641\nEstimated Time = 4 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of MDW flights without nulls = 641\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport MDW csv\nDone Processing airport MDW pickle\nProcessing airport JFK\nSize of JFK flights before = 11341\nEstimated Time = 36 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of JFK flights without nulls = 11341\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport JFK csv\nDone Processing airport JFK pickle\nProcessing airport ORD\nSize of ORD flights before = 17181\nEstimated Time = 30 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of ORD flights without nulls = 17181\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport ORD csv\nDone Processing airport ORD pickle\nProcessing airport DFW\nSize of DFW flights before = 21337\nEstimated Time = 28 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of DFW flights without nulls = 21062\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport DFW csv\nDone Processing airport DFW pickle\nProcessing airport SEA\nSize of SEA flights before = 21213\nEstimated Time = 32 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of SEA flights without nulls = 21213\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport SEA csv\nDone Processing airport SEA pickle\nProcessing airport SFO\nSize of SFO flights before = 23443\nEstimated Time = 47 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of SFO flights without nulls = 22959\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport SFO csv\nDone Processing airport SFO pickle\nProcessing airport DEN\nSize of DEN flights before = 23493\nEstimated Time = 33 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of DEN flights without nulls = 23303\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport DEN csv\nDone Processing airport DEN pickle\nProcessing airport PHX\nSize of PHX flights before = 25887\nEstimated Time = 48 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of PHX flights without nulls = 25601\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport PHX csv\nDone Processing airport PHX pickle\nProcessing airport PDX\nSize of PDX flights before = 3800\nEstimated Time = 17 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of PDX flights without nulls = 3792\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport PDX csv\nDone Processing airport PDX pickle\nProcessing airport LAS\nSize of LAS flights before = 23042\nEstimated Time = 48 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of LAS flights without nulls = 22910\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport LAS csv\nDone Processing airport LAS pickle\nProcessing airport PHL\nSize of PHL flights before = 13725\nEstimated Time = 38 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of PHL flights without nulls = 13725\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport PHL csv\nDone Processing airport PHL pickle\nProcessing airport LGA\nSize of LGA flights before = 10308\nEstimated Time = 33 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of LGA flights without nulls = 10308\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport LGA csv\nDone Processing airport LGA pickle\nProcessing airport EWR\nSize of EWR flights before = 9401\nEstimated Time = 32 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of EWR flights without nulls = 9399\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport EWR csv\nDone Processing airport EWR pickle\nProcessing airport MSP\nSize of MSP flights before = 6301\nEstimated Time = 16 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of MSP flights without nulls = 6301\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport MSP csv\nDone Processing airport MSP pickle\nProcessing airport MCO\nSize of MCO flights before = 5767\nEstimated Time = 17 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of MCO flights without nulls = 5705\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport MCO csv\nDone Processing airport MCO pickle\nProcessing airport BOS\nSize of BOS flights before = 5194\nEstimated Time = 20 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of BOS flights without nulls = 5194\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport BOS csv\nDone Processing airport BOS pickle\nProcessing airport TPA\nSize of TPA flights before = 3928\nEstimated Time = 13 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of TPA flights without nulls = 3898\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport TPA csv\nDone Processing airport TPA pickle\nProcessing airport MIA\nSize of MIA flights before = 2180\nEstimated Time = 8 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of MIA flights without nulls = 2180\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport MIA csv\nDone Processing airport MIA pickle\nProcessing airport IAD\nSize of IAD flights before = 1998\nEstimated Time = 10 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of IAD flights without nulls = 1972\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport IAD csv\nDone Processing airport IAD pickle\nProcessing airport FLL\nSize of FLL flights before = 759\nEstimated Time = 4 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of FLL flights without nulls = 751\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport FLL csv\nDone Processing airport FLL pickle\nProcessing airport DTW\nSize of DTW flights before = 47\nEstimated Time = 0 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of DTW flights without nulls = 47\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport DTW csv\nDone Processing airport DTW pickle\nProcessing airport IAH\nSize of IAH flights before = 42\nEstimated Time = 0 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of IAH flights without nulls = 41\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport IAH csv\nDone Processing airport IAH pickle\nProcessing airport LAX\nSize of LAX flights before = 29411\nEstimated Time = 48 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of LAX flights without nulls = 29213\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport LAX csv\nDone Processing airport LAX pickle\nProcessing airport SLC\nSize of SLC flights before = 22029\nEstimated Time = 39 minutes\ntime\n/local_disk0/tmp/1615690971620-0/PythonShell.py:121: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\ntemp\ndwpt\nrhum\nprcp\nsnow\nwdir\nwspd\nwpgt\npres\ntsun\ncoco\nSize of SLC flights without nulls = 22018\nIndex([&#39;From&#39;, &#39;Icao&#39;, &#39;Op&#39;, &#39;To&#39;, &#39;StartTime&#39;, &#39;LiftOffTime&#39;, &#39;TouchDownTime&#39;,\n       &#39;StopTime&#39;, &#39;FromLat&#39;, &#39;FromLong&#39;, &#39;ToLat&#39;, &#39;ToLong&#39;,\n       &#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;DayType&#39;, &#39;WeatherTime&#39;, &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;,\n       &#39;Precipitation&#39;, &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;,\n       &#39;PeakWindGust&#39;, &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;ConditionCode&#39;],\n      dtype=&#39;object&#39;)\nDone Processing airport SLC csv\nDone Processing airport SLC pickle\nActual End time = 2021-03-14 03:30:06.794144\nActual time elapsed = 17.916666666666668\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "airports = ['ATL', 'CLT', 'MDW', 'JFK', 'ORD', 'DFW', 'SEA', 'SFO', 'DEN', 'PHX', 'PDX', 'LAS', 'PHL', 'LGA', 'EWR', 'MSP', 'MCO', 'BOS', 'TPA', 'MIA', 'IAD', 'FLL', 'DTW', 'IAH', 'LAX', 'SLC']\n",
    "\n",
    "\n",
    "# Deserialize weather dicts, combine all weather dict pickles\n",
    "import s3fs\n",
    "import pickle\n",
    "\n",
    "access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "\n",
    "weatherDictFull = dict()\n",
    "weatherDictTemp = dict()\n",
    "\n",
    "for airport in airports:\n",
    "  weatherDictTemp = weatherDictFull\n",
    "  with fs.open(f's3://<BUCKET_NAME>/flights-csv/full-data/weather-by-airport-pickle-3/{airport}.pkl', 'rb') as f:\n",
    "    print(f'Processing {airport}.pkl')\n",
    "    weatherAirportX = pickle.load(f)\n",
    "    weatherDictFull = {**weatherDictTemp, **weatherAirportX}\n",
    "  \n",
    "print(f'Size of weather dictionary = {len(weatherDictFull)}')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import s3fs\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "stopwatch_start = datetime.now()\n",
    "print(f'Actual Start time = {stopwatch_start}')\n",
    "\n",
    "from meteostat import Point, Daily\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def weather2(startTime, liftOffTime, lat, long, key, weatherAirportDict): \n",
    "  start, end = pd.to_datetime(startTime), pd.to_datetime(liftOffTime)\n",
    "  start = start - timedelta(hours=1)\n",
    "  end = start + timedelta(hours=1)\n",
    "  lookupKey = (start.year, start.month, start.day, start.hour, end.year, end.month, end.day, end.hour, int(lat), int(long))\n",
    "  \n",
    "  if lookupKey not in weatherDictFull:\n",
    "    location = Point(lat, long)\n",
    "    \n",
    "    try:\n",
    "      data = Hourly(location, start, end)\n",
    "    except IndexError:\n",
    "      weatherDictFull[lookupKey] = {}\n",
    "      weatherAirportDict[lookupKey] = weatherDictFull[lookupKey]\n",
    "      return np.nan\n",
    "    else:\n",
    "      data = data.fetch()   \n",
    "\n",
    "      if data.index.nlevels > 1:\n",
    "        weatherDictFull[lookupKey] = {}\n",
    "        weatherAirportDict[lookupKey] = weatherDictFull[lookupKey]\n",
    "        return np.nan\n",
    "\n",
    "      if len(data) > 1:\n",
    "        result = data.reset_index().loc[[0]].to_dict('list')\n",
    "      else:\n",
    "        result = data.reset_index().to_dict('list')\n",
    "\n",
    "      if (len(result['temp']) > 0 and result['temp'][0]):\n",
    "        result['temp'][0] = round((result['temp'][0] * 1.8) + 32, 2)\n",
    "\n",
    "      for var in ['snow', 'wpgt', 'tsun']:\n",
    "        if (len(result[var]) > 0 and np.isnan(result[var][0])):\n",
    "          result[var][0] = 0.0\n",
    "\n",
    "      condition_codes = {1: 'Clear', 2: 'Fair', 3: 'Cloudy', \\\n",
    "                         4:\t'Overcast', 5: 'Fog', 6: 'Freezing Fog', \\\n",
    "                         7:\t'Light Rain', 8: 'Rain', 9:\t'Heavy Rain', \\\n",
    "                         10: 'Freezing Rain', 11: 'Heavy Freezing Rain', \\\n",
    "                         12: 'Sleet', 13: 'Heavy Sleet', 14: 'Light Snowfall', \\\n",
    "                         15: 'Snowfall', 16: 'Heavy Snowfall', 17: 'Rain Shower', \\\n",
    "                         18: 'Heavy Rain Shower', 19: 'Sleet Shower', 20: 'Heavy Sleet Shower', \\\n",
    "                         21: 'Snow Shower', 22: 'Heavy Snow Shower', 23: 'Lightning', \\\n",
    "                         24: 'Hail', 25: 'Thunderstorm', 26: 'Heavy Thunderstorm', 27: 'Storm'}\n",
    "\n",
    "      if ( (len(result['coco']) > 0) and (not np.isnan(result['coco'][0])) ):\n",
    "        if int(result['coco'][0]) in condition_codes:\n",
    "          result['coco'][0] = condition_codes[int(result['coco'][0])]\n",
    "        else:\n",
    "          result['coco'][0] = 'Unknown'\n",
    "\n",
    "      keys = ['time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']\n",
    "      results = [result[key][0] if (key in result and len(result[key]) > 0) else None for key in keys]\n",
    "      weatherDictFull[lookupKey] = {keys[i] : results[i] for i in range(len(keys))}\n",
    "  \n",
    "  weatherAirportDict[lookupKey] = weatherDictFull[lookupKey]\n",
    "  return weatherDictFull[lookupKey][key] if len(weatherDictFull[lookupKey]) > 0 else np.nan\n",
    "\n",
    "\n",
    "for airport in airports:\n",
    "  \n",
    "  weatherAirportX = dict()\n",
    "  \n",
    "  dfWeather8 = spark.read.options(delimiter='|', inferSchema='True', header='True')\\\n",
    "                      .csv('s3://<BUCKET_NAME>/flights-csv/full-data/full-data-280k.csv')\n",
    "  spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "  dfpWeather8 = dfWeather8.toPandas()\n",
    "  \n",
    "  print(f'Processing airport {airport}')\n",
    "  dfpWeather8Temp = dfpWeather8[dfpWeather8['From'] == airport]\n",
    "  print(f'Size of {airport} flights before = {len(dfpWeather8Temp)}')\n",
    "  \n",
    "  est_uniq_days = dfpWeather8Temp['StartTime'].apply(lambda x: (pd.to_datetime(x) - timedelta(hours=1)).strftime('%Y-%m-%d-%H')).nunique()\n",
    "  print(f'Estimated Time = { est_uniq_days // 100 } minutes')\n",
    "  \n",
    "  keys = ['time', 'temp', 'dwpt', 'rhum', 'prcp', 'snow', 'wdir', 'wspd', 'wpgt', 'pres', 'tsun', 'coco']\n",
    "  descs = ['WeatherTime', 'Temperature', 'Dewpoint', 'RelativeHumidity', 'Precipitation', 'SnowLevel', 'WindDirection', 'WindSpeed', 'PeakWindGust', 'AirPressure', 'Sunshine', 'ConditionCode']\n",
    "\n",
    "  for key, desc in zip(keys, descs):\n",
    "    print(key)\n",
    "    dfpWeather8Temp[desc] = np.vectorize(weather2, otypes=[\"O\"]) (dfpWeather8Temp['StartTime'], dfpWeather8Temp['LiftOffTime'], dfpWeather8Temp['FromLat'], dfpWeather8Temp['FromLong'], key, weatherAirportX)\n",
    "  \n",
    "  dfpWeather8Temp2 = dfpWeather8Temp.dropna(how='any')\n",
    "  print(f'Size of {airport} flights without nulls = {len(dfpWeather8Temp2)}')\n",
    "  print(dfpWeather8Temp.columns)\n",
    "  \n",
    "  access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "  secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "  sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "  sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "  bytes_to_write = dfpWeather8Temp.to_csv(None, sep='|', index=False).encode()\n",
    "  fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "  with fs.open(f's3://<BUCKET_NAME>/flights-csv/full-data/weather-by-airport-csv-final/{airport}.csv', 'wb') as f:\n",
    "    f.write(bytes_to_write)\n",
    "  \n",
    "  print(f'Done Processing airport {airport} csv')\n",
    "  \n",
    "  # Serialize weather dict\n",
    "  access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "  secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "  sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "  sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "  \n",
    "  bytes_to_write = pickle.dumps(weatherAirportX)\n",
    "  fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "\n",
    "  with fs.open(f's3://<BUCKET_NAME>/flights-csv/full-data/weather-by-airport-pickle-final/{airport}.pkl', 'wb') as f:\n",
    "    f.write(bytes_to_write)  \n",
    "      \n",
    "  print(f'Done Processing airport {airport} pickle')\n",
    "  \n",
    "  \n",
    "stopwatch_end = datetime.now()\n",
    "print(f'Actual End time = {stopwatch_end}')\n",
    "print(f'Actual time elapsed = {(stopwatch_end - stopwatch_start).seconds / 60}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f2cbbddd-2431-460d-88cd-b804a14e2e8e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Finishing touch before splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "6286bd3b-573d-4cdb-9148-3b5e3eb7731d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Done importing airport ATL.csv\n",
       "Done importing airport CLT.csv\n",
       "Done importing airport MDW.csv\n",
       "Done importing airport JFK.csv\n",
       "Done importing airport ORD.csv\n",
       "Done importing airport DFW.csv\n",
       "Done importing airport SEA.csv\n",
       "Done importing airport SFO.csv\n",
       "Done importing airport DEN.csv\n",
       "Done importing airport PHX.csv\n",
       "Done importing airport PDX.csv\n",
       "Done importing airport LAS.csv\n",
       "Done importing airport PHL.csv\n",
       "Done importing airport LGA.csv\n",
       "Done importing airport EWR.csv\n",
       "Done importing airport MSP.csv\n",
       "Done importing airport MCO.csv\n",
       "Done importing airport BOS.csv\n",
       "Done importing airport TPA.csv\n",
       "Done importing airport MIA.csv\n",
       "Done importing airport IAD.csv\n",
       "Done importing airport FLL.csv\n",
       "Done importing airport DTW.csv\n",
       "Done importing airport IAH.csv\n",
       "Done importing airport LAX.csv\n",
       "Done importing airport SLC.csv\n",
       "Size of dfpWeather8 = 283456\n",
       "Size of complete dataset (all nulls removed) = 281664\n",
       "Index([&#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n",
       "       &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;, &#39;Precipitation&#39;,\n",
       "       &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;, &#39;PeakWindGust&#39;,\n",
       "       &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;From_ATL&#39;, &#39;From_BOS&#39;, &#39;From_CLT&#39;,\n",
       "       &#39;From_DEN&#39;, &#39;From_DFW&#39;, &#39;From_DTW&#39;, &#39;From_EWR&#39;, &#39;From_FLL&#39;, &#39;From_IAD&#39;,\n",
       "       &#39;From_IAH&#39;, &#39;From_JFK&#39;, &#39;From_LAS&#39;, &#39;From_LAX&#39;, &#39;From_LGA&#39;, &#39;From_MCO&#39;,\n",
       "       &#39;From_MDW&#39;, &#39;From_MIA&#39;, &#39;From_MSP&#39;, &#39;From_ORD&#39;, &#39;From_PDX&#39;, &#39;From_PHL&#39;,\n",
       "       &#39;From_PHX&#39;, &#39;From_SEA&#39;, &#39;From_SFO&#39;, &#39;From_SLC&#39;, &#39;From_TPA&#39;,\n",
       "       &#39;Op_Alaska Airlines&#39;, &#39;Op_American Airlines&#39;, &#39;Op_Delta Air Lines&#39;,\n",
       "       &#39;Op_JetBlue Airways&#39;, &#39;Op_Southwest Airlines&#39;, &#39;Op_United Airlines&#39;,\n",
       "       &#39;DayType_Christmas&#39;, &#39;DayType_Regular&#39;, &#39;DayType_Thanksgiving&#39;,\n",
       "       &#39;ConditionCode_Clear&#39;, &#39;ConditionCode_Cloudy&#39;, &#39;ConditionCode_Fair&#39;,\n",
       "       &#39;ConditionCode_Fog&#39;, &#39;ConditionCode_Freezing Rain&#39;,\n",
       "       &#39;ConditionCode_Heavy Freezing Rain&#39;, &#39;ConditionCode_Heavy Rain&#39;,\n",
       "       &#39;ConditionCode_Heavy Rain Shower&#39;, &#39;ConditionCode_Heavy Sleet&#39;,\n",
       "       &#39;ConditionCode_Heavy Snowfall&#39;, &#39;ConditionCode_Heavy Thunderstorm&#39;,\n",
       "       &#39;ConditionCode_Light Rain&#39;, &#39;ConditionCode_Light Snowfall&#39;,\n",
       "       &#39;ConditionCode_Overcast&#39;, &#39;ConditionCode_Rain&#39;,\n",
       "       &#39;ConditionCode_Rain Shower&#39;, &#39;ConditionCode_Sleet&#39;,\n",
       "       &#39;ConditionCode_Snow Shower&#39;, &#39;ConditionCode_Snowfall&#39;,\n",
       "       &#39;ConditionCode_Storm&#39;, &#39;ConditionCode_Thunderstorm&#39;,\n",
       "       &#39;ConditionCode_Unknown&#39;],\n",
       "      dtype=&#39;object&#39;)\n",
       "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "Int64Index: 281664 entries, 0 to 283455\n",
       "Data columns (total 70 columns):\n",
       " #   Column                             Non-Null Count   Dtype  \n",
       "---  ------                             --------------   -----  \n",
       " 0   RunwayWaitTimeInSeconds            281664 non-null  int32  \n",
       " 1   OtherDepartures                    281664 non-null  int32  \n",
       " 2   FlightDuration                     281664 non-null  int32  \n",
       " 3   Temperature                        281664 non-null  float64\n",
       " 4   Dewpoint                           281664 non-null  float64\n",
       " 5   RelativeHumidity                   281664 non-null  float64\n",
       " 6   Precipitation                      281664 non-null  float64\n",
       " 7   SnowLevel                          281664 non-null  float64\n",
       " 8   WindDirection                      281664 non-null  float64\n",
       " 9   WindSpeed                          281664 non-null  float64\n",
       " 10  PeakWindGust                       281664 non-null  float64\n",
       " 11  AirPressure                        281664 non-null  float64\n",
       " 12  Sunshine                           281664 non-null  float64\n",
       " 13  From_ATL                           281664 non-null  uint8  \n",
       " 14  From_BOS                           281664 non-null  uint8  \n",
       " 15  From_CLT                           281664 non-null  uint8  \n",
       " 16  From_DEN                           281664 non-null  uint8  \n",
       " 17  From_DFW                           281664 non-null  uint8  \n",
       " 18  From_DTW                           281664 non-null  uint8  \n",
       " 19  From_EWR                           281664 non-null  uint8  \n",
       " 20  From_FLL                           281664 non-null  uint8  \n",
       " 21  From_IAD                           281664 non-null  uint8  \n",
       " 22  From_IAH                           281664 non-null  uint8  \n",
       " 23  From_JFK                           281664 non-null  uint8  \n",
       " 24  From_LAS                           281664 non-null  uint8  \n",
       " 25  From_LAX                           281664 non-null  uint8  \n",
       " 26  From_LGA                           281664 non-null  uint8  \n",
       " 27  From_MCO                           281664 non-null  uint8  \n",
       " 28  From_MDW                           281664 non-null  uint8  \n",
       " 29  From_MIA                           281664 non-null  uint8  \n",
       " 30  From_MSP                           281664 non-null  uint8  \n",
       " 31  From_ORD                           281664 non-null  uint8  \n",
       " 32  From_PDX                           281664 non-null  uint8  \n",
       " 33  From_PHL                           281664 non-null  uint8  \n",
       " 34  From_PHX                           281664 non-null  uint8  \n",
       " 35  From_SEA                           281664 non-null  uint8  \n",
       " 36  From_SFO                           281664 non-null  uint8  \n",
       " 37  From_SLC                           281664 non-null  uint8  \n",
       " 38  From_TPA                           281664 non-null  uint8  \n",
       " 39  Op_Alaska Airlines                 281664 non-null  uint8  \n",
       " 40  Op_American Airlines               281664 non-null  uint8  \n",
       " 41  Op_Delta Air Lines                 281664 non-null  uint8  \n",
       " 42  Op_JetBlue Airways                 281664 non-null  uint8  \n",
       " 43  Op_Southwest Airlines              281664 non-null  uint8  \n",
       " 44  Op_United Airlines                 281664 non-null  uint8  \n",
       " 45  DayType_Christmas                  281664 non-null  uint8  \n",
       " 46  DayType_Regular                    281664 non-null  uint8  \n",
       " 47  DayType_Thanksgiving               281664 non-null  uint8  \n",
       " 48  ConditionCode_Clear                281664 non-null  uint8  \n",
       " 49  ConditionCode_Cloudy               281664 non-null  uint8  \n",
       " 50  ConditionCode_Fair                 281664 non-null  uint8  \n",
       " 51  ConditionCode_Fog                  281664 non-null  uint8  \n",
       " 52  ConditionCode_Freezing Rain        281664 non-null  uint8  \n",
       " 53  ConditionCode_Heavy Freezing Rain  281664 non-null  uint8  \n",
       " 54  ConditionCode_Heavy Rain           281664 non-null  uint8  \n",
       " 55  ConditionCode_Heavy Rain Shower    281664 non-null  uint8  \n",
       " 56  ConditionCode_Heavy Sleet          281664 non-null  uint8  \n",
       " 57  ConditionCode_Heavy Snowfall       281664 non-null  uint8  \n",
       " 58  ConditionCode_Heavy Thunderstorm   281664 non-null  uint8  \n",
       " 59  ConditionCode_Light Rain           281664 non-null  uint8  \n",
       " 60  ConditionCode_Light Snowfall       281664 non-null  uint8  \n",
       " 61  ConditionCode_Overcast             281664 non-null  uint8  \n",
       " 62  ConditionCode_Rain                 281664 non-null  uint8  \n",
       " 63  ConditionCode_Rain Shower          281664 non-null  uint8  \n",
       " 64  ConditionCode_Sleet                281664 non-null  uint8  \n",
       " 65  ConditionCode_Snow Shower          281664 non-null  uint8  \n",
       " 66  ConditionCode_Snowfall             281664 non-null  uint8  \n",
       " 67  ConditionCode_Storm                281664 non-null  uint8  \n",
       " 68  ConditionCode_Thunderstorm         281664 non-null  uint8  \n",
       " 69  ConditionCode_Unknown              281664 non-null  uint8  \n",
       "dtypes: float64(10), int32(3), uint8(57)\n",
       "memory usage: 42.2 MB\n",
       "None\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Done importing airport ATL.csv\nDone importing airport CLT.csv\nDone importing airport MDW.csv\nDone importing airport JFK.csv\nDone importing airport ORD.csv\nDone importing airport DFW.csv\nDone importing airport SEA.csv\nDone importing airport SFO.csv\nDone importing airport DEN.csv\nDone importing airport PHX.csv\nDone importing airport PDX.csv\nDone importing airport LAS.csv\nDone importing airport PHL.csv\nDone importing airport LGA.csv\nDone importing airport EWR.csv\nDone importing airport MSP.csv\nDone importing airport MCO.csv\nDone importing airport BOS.csv\nDone importing airport TPA.csv\nDone importing airport MIA.csv\nDone importing airport IAD.csv\nDone importing airport FLL.csv\nDone importing airport DTW.csv\nDone importing airport IAH.csv\nDone importing airport LAX.csv\nDone importing airport SLC.csv\nSize of dfpWeather8 = 283456\nSize of complete dataset (all nulls removed) = 281664\nIndex([&#39;RunwayWaitTimeInSeconds&#39;, &#39;OtherDepartures&#39;, &#39;FlightDuration&#39;,\n       &#39;Temperature&#39;, &#39;Dewpoint&#39;, &#39;RelativeHumidity&#39;, &#39;Precipitation&#39;,\n       &#39;SnowLevel&#39;, &#39;WindDirection&#39;, &#39;WindSpeed&#39;, &#39;PeakWindGust&#39;,\n       &#39;AirPressure&#39;, &#39;Sunshine&#39;, &#39;From_ATL&#39;, &#39;From_BOS&#39;, &#39;From_CLT&#39;,\n       &#39;From_DEN&#39;, &#39;From_DFW&#39;, &#39;From_DTW&#39;, &#39;From_EWR&#39;, &#39;From_FLL&#39;, &#39;From_IAD&#39;,\n       &#39;From_IAH&#39;, &#39;From_JFK&#39;, &#39;From_LAS&#39;, &#39;From_LAX&#39;, &#39;From_LGA&#39;, &#39;From_MCO&#39;,\n       &#39;From_MDW&#39;, &#39;From_MIA&#39;, &#39;From_MSP&#39;, &#39;From_ORD&#39;, &#39;From_PDX&#39;, &#39;From_PHL&#39;,\n       &#39;From_PHX&#39;, &#39;From_SEA&#39;, &#39;From_SFO&#39;, &#39;From_SLC&#39;, &#39;From_TPA&#39;,\n       &#39;Op_Alaska Airlines&#39;, &#39;Op_American Airlines&#39;, &#39;Op_Delta Air Lines&#39;,\n       &#39;Op_JetBlue Airways&#39;, &#39;Op_Southwest Airlines&#39;, &#39;Op_United Airlines&#39;,\n       &#39;DayType_Christmas&#39;, &#39;DayType_Regular&#39;, &#39;DayType_Thanksgiving&#39;,\n       &#39;ConditionCode_Clear&#39;, &#39;ConditionCode_Cloudy&#39;, &#39;ConditionCode_Fair&#39;,\n       &#39;ConditionCode_Fog&#39;, &#39;ConditionCode_Freezing Rain&#39;,\n       &#39;ConditionCode_Heavy Freezing Rain&#39;, &#39;ConditionCode_Heavy Rain&#39;,\n       &#39;ConditionCode_Heavy Rain Shower&#39;, &#39;ConditionCode_Heavy Sleet&#39;,\n       &#39;ConditionCode_Heavy Snowfall&#39;, &#39;ConditionCode_Heavy Thunderstorm&#39;,\n       &#39;ConditionCode_Light Rain&#39;, &#39;ConditionCode_Light Snowfall&#39;,\n       &#39;ConditionCode_Overcast&#39;, &#39;ConditionCode_Rain&#39;,\n       &#39;ConditionCode_Rain Shower&#39;, &#39;ConditionCode_Sleet&#39;,\n       &#39;ConditionCode_Snow Shower&#39;, &#39;ConditionCode_Snowfall&#39;,\n       &#39;ConditionCode_Storm&#39;, &#39;ConditionCode_Thunderstorm&#39;,\n       &#39;ConditionCode_Unknown&#39;],\n      dtype=&#39;object&#39;)\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 281664 entries, 0 to 283455\nData columns (total 70 columns):\n #   Column                             Non-Null Count   Dtype  \n---  ------                             --------------   -----  \n 0   RunwayWaitTimeInSeconds            281664 non-null  int32  \n 1   OtherDepartures                    281664 non-null  int32  \n 2   FlightDuration                     281664 non-null  int32  \n 3   Temperature                        281664 non-null  float64\n 4   Dewpoint                           281664 non-null  float64\n 5   RelativeHumidity                   281664 non-null  float64\n 6   Precipitation                      281664 non-null  float64\n 7   SnowLevel                          281664 non-null  float64\n 8   WindDirection                      281664 non-null  float64\n 9   WindSpeed                          281664 non-null  float64\n 10  PeakWindGust                       281664 non-null  float64\n 11  AirPressure                        281664 non-null  float64\n 12  Sunshine                           281664 non-null  float64\n 13  From_ATL                           281664 non-null  uint8  \n 14  From_BOS                           281664 non-null  uint8  \n 15  From_CLT                           281664 non-null  uint8  \n 16  From_DEN                           281664 non-null  uint8  \n 17  From_DFW                           281664 non-null  uint8  \n 18  From_DTW                           281664 non-null  uint8  \n 19  From_EWR                           281664 non-null  uint8  \n 20  From_FLL                           281664 non-null  uint8  \n 21  From_IAD                           281664 non-null  uint8  \n 22  From_IAH                           281664 non-null  uint8  \n 23  From_JFK                           281664 non-null  uint8  \n 24  From_LAS                           281664 non-null  uint8  \n 25  From_LAX                           281664 non-null  uint8  \n 26  From_LGA                           281664 non-null  uint8  \n 27  From_MCO                           281664 non-null  uint8  \n 28  From_MDW                           281664 non-null  uint8  \n 29  From_MIA                           281664 non-null  uint8  \n 30  From_MSP                           281664 non-null  uint8  \n 31  From_ORD                           281664 non-null  uint8  \n 32  From_PDX                           281664 non-null  uint8  \n 33  From_PHL                           281664 non-null  uint8  \n 34  From_PHX                           281664 non-null  uint8  \n 35  From_SEA                           281664 non-null  uint8  \n 36  From_SFO                           281664 non-null  uint8  \n 37  From_SLC                           281664 non-null  uint8  \n 38  From_TPA                           281664 non-null  uint8  \n 39  Op_Alaska Airlines                 281664 non-null  uint8  \n 40  Op_American Airlines               281664 non-null  uint8  \n 41  Op_Delta Air Lines                 281664 non-null  uint8  \n 42  Op_JetBlue Airways                 281664 non-null  uint8  \n 43  Op_Southwest Airlines              281664 non-null  uint8  \n 44  Op_United Airlines                 281664 non-null  uint8  \n 45  DayType_Christmas                  281664 non-null  uint8  \n 46  DayType_Regular                    281664 non-null  uint8  \n 47  DayType_Thanksgiving               281664 non-null  uint8  \n 48  ConditionCode_Clear                281664 non-null  uint8  \n 49  ConditionCode_Cloudy               281664 non-null  uint8  \n 50  ConditionCode_Fair                 281664 non-null  uint8  \n 51  ConditionCode_Fog                  281664 non-null  uint8  \n 52  ConditionCode_Freezing Rain        281664 non-null  uint8  \n 53  ConditionCode_Heavy Freezing Rain  281664 non-null  uint8  \n 54  ConditionCode_Heavy Rain           281664 non-null  uint8  \n 55  ConditionCode_Heavy Rain Shower    281664 non-null  uint8  \n 56  ConditionCode_Heavy Sleet          281664 non-null  uint8  \n 57  ConditionCode_Heavy Snowfall       281664 non-null  uint8  \n 58  ConditionCode_Heavy Thunderstorm   281664 non-null  uint8  \n 59  ConditionCode_Light Rain           281664 non-null  uint8  \n 60  ConditionCode_Light Snowfall       281664 non-null  uint8  \n 61  ConditionCode_Overcast             281664 non-null  uint8  \n 62  ConditionCode_Rain                 281664 non-null  uint8  \n 63  ConditionCode_Rain Shower          281664 non-null  uint8  \n 64  ConditionCode_Sleet                281664 non-null  uint8  \n 65  ConditionCode_Snow Shower          281664 non-null  uint8  \n 66  ConditionCode_Snowfall             281664 non-null  uint8  \n 67  ConditionCode_Storm                281664 non-null  uint8  \n 68  ConditionCode_Thunderstorm         281664 non-null  uint8  \n 69  ConditionCode_Unknown              281664 non-null  uint8  \ndtypes: float64(10), int32(3), uint8(57)\nmemory usage: 42.2 MB\nNone\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Merge all available airport csv\n",
    "processed_airports = ['CLT', 'MDW', 'JFK', 'ORD', 'DFW', 'SEA', 'SFO', 'DEN', 'PHX', 'PDX', 'LAS', 'PHL', 'LGA', 'EWR', 'MSP', 'MCO', 'BOS', 'TPA', 'MIA', 'IAD', 'FLL', 'DTW', 'IAH', 'LAX', 'SLC']\n",
    "\n",
    "access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "\n",
    "# Process ATL first\n",
    "dfWeather8 = spark.read.options(delimiter='|', inferSchema='True', header='True')\\\n",
    "                      .csv('s3://<BUCKET_NAME>/flights-csv/full-data/weather-by-airport-csv-final/ATL.csv')\n",
    "print(f'Done importing airport ATL.csv')\n",
    "\n",
    "# Process the rest of the airports\n",
    "for airport in processed_airports:\n",
    "  dfWeatherTemp = spark.read.options(delimiter='|', inferSchema='True', header='True')\\\n",
    "                      .csv(f's3://<BUCKET_NAME>/flights-csv/full-data/weather-by-airport-csv-final/{airport}.csv')\n",
    "  dfWeather8 = dfWeather8.union(dfWeatherTemp).dropDuplicates()\n",
    "  print(f'Done importing airport {airport}.csv')\n",
    "\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "dfpWeather8 = dfWeather8.toPandas()\n",
    "print(f'Size of dfpWeather8 = {len(dfpWeather8)}')\n",
    "\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "# Code for dummy variables, Do this as the veryy last step\n",
    "dfpComplete = pd.get_dummies(data=dfpWeather8, columns=['From', 'Op', 'DayType', 'ConditionCode'])\n",
    "dfpComplete = dfpComplete.dropna(how='any')\n",
    "dfpComplete.drop(['Icao', 'To', 'StartTime', 'LiftOffTime', 'TouchDownTime', 'StopTime', 'FromLat', 'FromLong', 'ToLat', 'ToLong', 'WeatherTime'], axis=1, inplace=True)\n",
    "# cols_at_front = ['RunwayWaitTimeInSeconds']\n",
    "# dfpComplete = dfpComplete[ [c for c in cols_at_front if c in dfpComplete] + [c for c in dfpComplete if c not in cols_at_front] ]\n",
    "print(f'Size of complete dataset (all nulls removed) = {len(dfpComplete)}') \n",
    "print(dfpComplete.columns)\n",
    "print(dfpComplete.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "c4c96904-6c19-4769-9066-89971911e3d2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-855734919694654&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-red-fg\"># Any last minute processing put here</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> dfpComplete <span class=\"ansi-blue-fg\">=</span> dfpComplete<span class=\"ansi-blue-fg\">[</span>dfpComplete<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;RunwayWaitTimeInSeconds&#39;</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">&lt;=</span> <span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">*</span><span class=\"ansi-cyan-fg\">3600</span><span class=\"ansi-blue-fg\">]</span>\n",
       "<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>dfpcomplete<span class=\"ansi-blue-fg\">.</span>head<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">NameError</span>: name &#39;dfpcomplete&#39; is not defined</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">NameError</span>                                 Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-855734919694654&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-red-fg\"># Any last minute processing put here</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      3</span> dfpComplete <span class=\"ansi-blue-fg\">=</span> dfpComplete<span class=\"ansi-blue-fg\">[</span>dfpComplete<span class=\"ansi-blue-fg\">[</span><span class=\"ansi-blue-fg\">&#39;RunwayWaitTimeInSeconds&#39;</span><span class=\"ansi-blue-fg\">]</span> <span class=\"ansi-blue-fg\">&lt;=</span> <span class=\"ansi-cyan-fg\">2</span><span class=\"ansi-blue-fg\">*</span><span class=\"ansi-cyan-fg\">3600</span><span class=\"ansi-blue-fg\">]</span>\n<span class=\"ansi-green-fg\">----&gt; 4</span><span class=\"ansi-red-fg\"> </span>dfpcomplete<span class=\"ansi-blue-fg\">.</span>head<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-red-fg\">NameError</span>: name &#39;dfpcomplete&#39; is not defined</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">NameError</span>: name &#39;dfpcomplete&#39; is not defined",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For testing\n",
    "# Any last minute processing put here\n",
    "dfpComplete = dfpComplete[dfpComplete['RunwayWaitTimeInSeconds'] <= 2*3600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "09eced90-6601-4f85-9080-643639582370",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "18726738-432f-4e67-9a3c-ce04b2bf94e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Done exporting complete-data.csv\n",
       "Size of training set = 173872\n",
       "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "Int64Index: 173872 entries, 135496 to 261685\n",
       "Data columns (total 70 columns):\n",
       " #   Column                             Non-Null Count   Dtype  \n",
       "---  ------                             --------------   -----  \n",
       " 0   RunwayWaitTimeInSeconds            173872 non-null  int32  \n",
       " 1   OtherDepartures                    173872 non-null  int32  \n",
       " 2   FlightDuration                     173872 non-null  int32  \n",
       " 3   Temperature                        173872 non-null  float64\n",
       " 4   Dewpoint                           173872 non-null  float64\n",
       " 5   RelativeHumidity                   173872 non-null  float64\n",
       " 6   Precipitation                      173872 non-null  float64\n",
       " 7   SnowLevel                          173872 non-null  float64\n",
       " 8   WindDirection                      173872 non-null  float64\n",
       " 9   WindSpeed                          173872 non-null  float64\n",
       " 10  PeakWindGust                       173872 non-null  float64\n",
       " 11  AirPressure                        173872 non-null  float64\n",
       " 12  Sunshine                           173872 non-null  float64\n",
       " 13  From_ATL                           173872 non-null  uint8  \n",
       " 14  From_BOS                           173872 non-null  uint8  \n",
       " 15  From_CLT                           173872 non-null  uint8  \n",
       " 16  From_DEN                           173872 non-null  uint8  \n",
       " 17  From_DFW                           173872 non-null  uint8  \n",
       " 18  From_DTW                           173872 non-null  uint8  \n",
       " 19  From_EWR                           173872 non-null  uint8  \n",
       " 20  From_FLL                           173872 non-null  uint8  \n",
       " 21  From_IAD                           173872 non-null  uint8  \n",
       " 22  From_IAH                           173872 non-null  uint8  \n",
       " 23  From_JFK                           173872 non-null  uint8  \n",
       " 24  From_LAS                           173872 non-null  uint8  \n",
       " 25  From_LAX                           173872 non-null  uint8  \n",
       " 26  From_LGA                           173872 non-null  uint8  \n",
       " 27  From_MCO                           173872 non-null  uint8  \n",
       " 28  From_MDW                           173872 non-null  uint8  \n",
       " 29  From_MIA                           173872 non-null  uint8  \n",
       " 30  From_MSP                           173872 non-null  uint8  \n",
       " 31  From_ORD                           173872 non-null  uint8  \n",
       " 32  From_PDX                           173872 non-null  uint8  \n",
       " 33  From_PHL                           173872 non-null  uint8  \n",
       " 34  From_PHX                           173872 non-null  uint8  \n",
       " 35  From_SEA                           173872 non-null  uint8  \n",
       " 36  From_SFO                           173872 non-null  uint8  \n",
       " 37  From_SLC                           173872 non-null  uint8  \n",
       " 38  From_TPA                           173872 non-null  uint8  \n",
       " 39  Op_Alaska Airlines                 173872 non-null  uint8  \n",
       " 40  Op_American Airlines               173872 non-null  uint8  \n",
       " 41  Op_Delta Air Lines                 173872 non-null  uint8  \n",
       " 42  Op_JetBlue Airways                 173872 non-null  uint8  \n",
       " 43  Op_Southwest Airlines              173872 non-null  uint8  \n",
       " 44  Op_United Airlines                 173872 non-null  uint8  \n",
       " 45  DayType_Christmas                  173872 non-null  uint8  \n",
       " 46  DayType_Regular                    173872 non-null  uint8  \n",
       " 47  DayType_Thanksgiving               173872 non-null  uint8  \n",
       " 48  ConditionCode_Clear                173872 non-null  uint8  \n",
       " 49  ConditionCode_Cloudy               173872 non-null  uint8  \n",
       " 50  ConditionCode_Fair                 173872 non-null  uint8  \n",
       " 51  ConditionCode_Fog                  173872 non-null  uint8  \n",
       " 52  ConditionCode_Freezing Rain        173872 non-null  uint8  \n",
       " 53  ConditionCode_Heavy Freezing Rain  173872 non-null  uint8  \n",
       " 54  ConditionCode_Heavy Rain           173872 non-null  uint8  \n",
       " 55  ConditionCode_Heavy Rain Shower    173872 non-null  uint8  \n",
       " 56  ConditionCode_Heavy Sleet          173872 non-null  uint8  \n",
       " 57  ConditionCode_Heavy Snowfall       173872 non-null  uint8  \n",
       " 58  ConditionCode_Heavy Thunderstorm   173872 non-null  uint8  \n",
       " 59  ConditionCode_Light Rain           173872 non-null  uint8  \n",
       " 60  ConditionCode_Light Snowfall       173872 non-null  uint8  \n",
       " 61  ConditionCode_Overcast             173872 non-null  uint8  \n",
       " 62  ConditionCode_Rain                 173872 non-null  uint8  \n",
       " 63  ConditionCode_Rain Shower          173872 non-null  uint8  \n",
       " 64  ConditionCode_Sleet                173872 non-null  uint8  \n",
       " 65  ConditionCode_Snow Shower          173872 non-null  uint8  \n",
       " 66  ConditionCode_Snowfall             173872 non-null  uint8  \n",
       " 67  ConditionCode_Storm                173872 non-null  uint8  \n",
       " 68  ConditionCode_Thunderstorm         173872 non-null  uint8  \n",
       " 69  ConditionCode_Unknown              173872 non-null  uint8  \n",
       "dtypes: float64(10), int32(3), uint8(57)\n",
       "memory usage: 26.0 MB\n",
       "None\n",
       "Done exporting train-data.csv\n",
       "Size of test set = 43469\n",
       "&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\n",
       "Int64Index: 43469 entries, 156934 to 47100\n",
       "Data columns (total 70 columns):\n",
       " #   Column                             Non-Null Count  Dtype  \n",
       "---  ------                             --------------  -----  \n",
       " 0   RunwayWaitTimeInSeconds            43469 non-null  int32  \n",
       " 1   OtherDepartures                    43469 non-null  int32  \n",
       " 2   FlightDuration                     43469 non-null  int32  \n",
       " 3   Temperature                        43469 non-null  float64\n",
       " 4   Dewpoint                           43469 non-null  float64\n",
       " 5   RelativeHumidity                   43469 non-null  float64\n",
       " 6   Precipitation                      43469 non-null  float64\n",
       " 7   SnowLevel                          43469 non-null  float64\n",
       " 8   WindDirection                      43469 non-null  float64\n",
       " 9   WindSpeed                          43469 non-null  float64\n",
       " 10  PeakWindGust                       43469 non-null  float64\n",
       " 11  AirPressure                        43469 non-null  float64\n",
       " 12  Sunshine                           43469 non-null  float64\n",
       " 13  From_ATL                           43469 non-null  uint8  \n",
       " 14  From_BOS                           43469 non-null  uint8  \n",
       " 15  From_CLT                           43469 non-null  uint8  \n",
       " 16  From_DEN                           43469 non-null  uint8  \n",
       " 17  From_DFW                           43469 non-null  uint8  \n",
       " 18  From_DTW                           43469 non-null  uint8  \n",
       " 19  From_EWR                           43469 non-null  uint8  \n",
       " 20  From_FLL                           43469 non-null  uint8  \n",
       " 21  From_IAD                           43469 non-null  uint8  \n",
       " 22  From_IAH                           43469 non-null  uint8  \n",
       " 23  From_JFK                           43469 non-null  uint8  \n",
       " 24  From_LAS                           43469 non-null  uint8  \n",
       " 25  From_LAX                           43469 non-null  uint8  \n",
       " 26  From_LGA                           43469 non-null  uint8  \n",
       " 27  From_MCO                           43469 non-null  uint8  \n",
       " 28  From_MDW                           43469 non-null  uint8  \n",
       " 29  From_MIA                           43469 non-null  uint8  \n",
       " 30  From_MSP                           43469 non-null  uint8  \n",
       " 31  From_ORD                           43469 non-null  uint8  \n",
       " 32  From_PDX                           43469 non-null  uint8  \n",
       " 33  From_PHL                           43469 non-null  uint8  \n",
       " 34  From_PHX                           43469 non-null  uint8  \n",
       " 35  From_SEA                           43469 non-null  uint8  \n",
       " 36  From_SFO                           43469 non-null  uint8  \n",
       " 37  From_SLC                           43469 non-null  uint8  \n",
       " 38  From_TPA                           43469 non-null  uint8  \n",
       " 39  Op_Alaska Airlines                 43469 non-null  uint8  \n",
       " 40  Op_American Airlines               43469 non-null  uint8  \n",
       " 41  Op_Delta Air Lines                 43469 non-null  uint8  \n",
       " 42  Op_JetBlue Airways                 43469 non-null  uint8  \n",
       " 43  Op_Southwest Airlines              43469 non-null  uint8  \n",
       " 44  Op_United Airlines                 43469 non-null  uint8  \n",
       " 45  DayType_Christmas                  43469 non-null  uint8  \n",
       " 46  DayType_Regular                    43469 non-null  uint8  \n",
       " 47  DayType_Thanksgiving               43469 non-null  uint8  \n",
       " 48  ConditionCode_Clear                43469 non-null  uint8  \n",
       " 49  ConditionCode_Cloudy               43469 non-null  uint8  \n",
       " 50  ConditionCode_Fair                 43469 non-null  uint8  \n",
       " 51  ConditionCode_Fog                  43469 non-null  uint8  \n",
       " 52  ConditionCode_Freezing Rain        43469 non-null  uint8  \n",
       " 53  ConditionCode_Heavy Freezing Rain  43469 non-null  uint8  \n",
       " 54  ConditionCode_Heavy Rain           43469 non-null  uint8  \n",
       " 55  ConditionCode_Heavy Rain Shower    43469 non-null  uint8  \n",
       " 56  ConditionCode_Heavy Sleet          43469 non-null  uint8  \n",
       " 57  ConditionCode_Heavy Snowfall       43469 non-null  uint8  \n",
       " 58  ConditionCode_Heavy Thunderstorm   43469 non-null  uint8  \n",
       " 59  ConditionCode_Light Rain           43469 non-null  uint8  \n",
       " 60  ConditionCode_Light Snowfall       43469 non-null  uint8  \n",
       " 61  ConditionCode_Overcast             43469 non-null  uint8  \n",
       " 62  ConditionCode_Rain                 43469 non-null  uint8  \n",
       " 63  ConditionCode_Rain Shower          43469 non-null  uint8  \n",
       " 64  ConditionCode_Sleet                43469 non-null  uint8  \n",
       " 65  ConditionCode_Snow Shower          43469 non-null  uint8  \n",
       " 66  ConditionCode_Snowfall             43469 non-null  uint8  \n",
       " 67  ConditionCode_Storm                43469 non-null  uint8  \n",
       " 68  ConditionCode_Thunderstorm         43469 non-null  uint8  \n",
       " 69  ConditionCode_Unknown              43469 non-null  uint8  \n",
       "dtypes: float64(10), int32(3), uint8(57)\n",
       "memory usage: 6.5 MB\n",
       "None\n",
       "Done exporting test-data.csv\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Done exporting complete-data.csv\nSize of training set = 173872\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 173872 entries, 135496 to 261685\nData columns (total 70 columns):\n #   Column                             Non-Null Count   Dtype  \n---  ------                             --------------   -----  \n 0   RunwayWaitTimeInSeconds            173872 non-null  int32  \n 1   OtherDepartures                    173872 non-null  int32  \n 2   FlightDuration                     173872 non-null  int32  \n 3   Temperature                        173872 non-null  float64\n 4   Dewpoint                           173872 non-null  float64\n 5   RelativeHumidity                   173872 non-null  float64\n 6   Precipitation                      173872 non-null  float64\n 7   SnowLevel                          173872 non-null  float64\n 8   WindDirection                      173872 non-null  float64\n 9   WindSpeed                          173872 non-null  float64\n 10  PeakWindGust                       173872 non-null  float64\n 11  AirPressure                        173872 non-null  float64\n 12  Sunshine                           173872 non-null  float64\n 13  From_ATL                           173872 non-null  uint8  \n 14  From_BOS                           173872 non-null  uint8  \n 15  From_CLT                           173872 non-null  uint8  \n 16  From_DEN                           173872 non-null  uint8  \n 17  From_DFW                           173872 non-null  uint8  \n 18  From_DTW                           173872 non-null  uint8  \n 19  From_EWR                           173872 non-null  uint8  \n 20  From_FLL                           173872 non-null  uint8  \n 21  From_IAD                           173872 non-null  uint8  \n 22  From_IAH                           173872 non-null  uint8  \n 23  From_JFK                           173872 non-null  uint8  \n 24  From_LAS                           173872 non-null  uint8  \n 25  From_LAX                           173872 non-null  uint8  \n 26  From_LGA                           173872 non-null  uint8  \n 27  From_MCO                           173872 non-null  uint8  \n 28  From_MDW                           173872 non-null  uint8  \n 29  From_MIA                           173872 non-null  uint8  \n 30  From_MSP                           173872 non-null  uint8  \n 31  From_ORD                           173872 non-null  uint8  \n 32  From_PDX                           173872 non-null  uint8  \n 33  From_PHL                           173872 non-null  uint8  \n 34  From_PHX                           173872 non-null  uint8  \n 35  From_SEA                           173872 non-null  uint8  \n 36  From_SFO                           173872 non-null  uint8  \n 37  From_SLC                           173872 non-null  uint8  \n 38  From_TPA                           173872 non-null  uint8  \n 39  Op_Alaska Airlines                 173872 non-null  uint8  \n 40  Op_American Airlines               173872 non-null  uint8  \n 41  Op_Delta Air Lines                 173872 non-null  uint8  \n 42  Op_JetBlue Airways                 173872 non-null  uint8  \n 43  Op_Southwest Airlines              173872 non-null  uint8  \n 44  Op_United Airlines                 173872 non-null  uint8  \n 45  DayType_Christmas                  173872 non-null  uint8  \n 46  DayType_Regular                    173872 non-null  uint8  \n 47  DayType_Thanksgiving               173872 non-null  uint8  \n 48  ConditionCode_Clear                173872 non-null  uint8  \n 49  ConditionCode_Cloudy               173872 non-null  uint8  \n 50  ConditionCode_Fair                 173872 non-null  uint8  \n 51  ConditionCode_Fog                  173872 non-null  uint8  \n 52  ConditionCode_Freezing Rain        173872 non-null  uint8  \n 53  ConditionCode_Heavy Freezing Rain  173872 non-null  uint8  \n 54  ConditionCode_Heavy Rain           173872 non-null  uint8  \n 55  ConditionCode_Heavy Rain Shower    173872 non-null  uint8  \n 56  ConditionCode_Heavy Sleet          173872 non-null  uint8  \n 57  ConditionCode_Heavy Snowfall       173872 non-null  uint8  \n 58  ConditionCode_Heavy Thunderstorm   173872 non-null  uint8  \n 59  ConditionCode_Light Rain           173872 non-null  uint8  \n 60  ConditionCode_Light Snowfall       173872 non-null  uint8  \n 61  ConditionCode_Overcast             173872 non-null  uint8  \n 62  ConditionCode_Rain                 173872 non-null  uint8  \n 63  ConditionCode_Rain Shower          173872 non-null  uint8  \n 64  ConditionCode_Sleet                173872 non-null  uint8  \n 65  ConditionCode_Snow Shower          173872 non-null  uint8  \n 66  ConditionCode_Snowfall             173872 non-null  uint8  \n 67  ConditionCode_Storm                173872 non-null  uint8  \n 68  ConditionCode_Thunderstorm         173872 non-null  uint8  \n 69  ConditionCode_Unknown              173872 non-null  uint8  \ndtypes: float64(10), int32(3), uint8(57)\nmemory usage: 26.0 MB\nNone\nDone exporting train-data.csv\nSize of test set = 43469\n&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nInt64Index: 43469 entries, 156934 to 47100\nData columns (total 70 columns):\n #   Column                             Non-Null Count  Dtype  \n---  ------                             --------------  -----  \n 0   RunwayWaitTimeInSeconds            43469 non-null  int32  \n 1   OtherDepartures                    43469 non-null  int32  \n 2   FlightDuration                     43469 non-null  int32  \n 3   Temperature                        43469 non-null  float64\n 4   Dewpoint                           43469 non-null  float64\n 5   RelativeHumidity                   43469 non-null  float64\n 6   Precipitation                      43469 non-null  float64\n 7   SnowLevel                          43469 non-null  float64\n 8   WindDirection                      43469 non-null  float64\n 9   WindSpeed                          43469 non-null  float64\n 10  PeakWindGust                       43469 non-null  float64\n 11  AirPressure                        43469 non-null  float64\n 12  Sunshine                           43469 non-null  float64\n 13  From_ATL                           43469 non-null  uint8  \n 14  From_BOS                           43469 non-null  uint8  \n 15  From_CLT                           43469 non-null  uint8  \n 16  From_DEN                           43469 non-null  uint8  \n 17  From_DFW                           43469 non-null  uint8  \n 18  From_DTW                           43469 non-null  uint8  \n 19  From_EWR                           43469 non-null  uint8  \n 20  From_FLL                           43469 non-null  uint8  \n 21  From_IAD                           43469 non-null  uint8  \n 22  From_IAH                           43469 non-null  uint8  \n 23  From_JFK                           43469 non-null  uint8  \n 24  From_LAS                           43469 non-null  uint8  \n 25  From_LAX                           43469 non-null  uint8  \n 26  From_LGA                           43469 non-null  uint8  \n 27  From_MCO                           43469 non-null  uint8  \n 28  From_MDW                           43469 non-null  uint8  \n 29  From_MIA                           43469 non-null  uint8  \n 30  From_MSP                           43469 non-null  uint8  \n 31  From_ORD                           43469 non-null  uint8  \n 32  From_PDX                           43469 non-null  uint8  \n 33  From_PHL                           43469 non-null  uint8  \n 34  From_PHX                           43469 non-null  uint8  \n 35  From_SEA                           43469 non-null  uint8  \n 36  From_SFO                           43469 non-null  uint8  \n 37  From_SLC                           43469 non-null  uint8  \n 38  From_TPA                           43469 non-null  uint8  \n 39  Op_Alaska Airlines                 43469 non-null  uint8  \n 40  Op_American Airlines               43469 non-null  uint8  \n 41  Op_Delta Air Lines                 43469 non-null  uint8  \n 42  Op_JetBlue Airways                 43469 non-null  uint8  \n 43  Op_Southwest Airlines              43469 non-null  uint8  \n 44  Op_United Airlines                 43469 non-null  uint8  \n 45  DayType_Christmas                  43469 non-null  uint8  \n 46  DayType_Regular                    43469 non-null  uint8  \n 47  DayType_Thanksgiving               43469 non-null  uint8  \n 48  ConditionCode_Clear                43469 non-null  uint8  \n 49  ConditionCode_Cloudy               43469 non-null  uint8  \n 50  ConditionCode_Fair                 43469 non-null  uint8  \n 51  ConditionCode_Fog                  43469 non-null  uint8  \n 52  ConditionCode_Freezing Rain        43469 non-null  uint8  \n 53  ConditionCode_Heavy Freezing Rain  43469 non-null  uint8  \n 54  ConditionCode_Heavy Rain           43469 non-null  uint8  \n 55  ConditionCode_Heavy Rain Shower    43469 non-null  uint8  \n 56  ConditionCode_Heavy Sleet          43469 non-null  uint8  \n 57  ConditionCode_Heavy Snowfall       43469 non-null  uint8  \n 58  ConditionCode_Heavy Thunderstorm   43469 non-null  uint8  \n 59  ConditionCode_Light Rain           43469 non-null  uint8  \n 60  ConditionCode_Light Snowfall       43469 non-null  uint8  \n 61  ConditionCode_Overcast             43469 non-null  uint8  \n 62  ConditionCode_Rain                 43469 non-null  uint8  \n 63  ConditionCode_Rain Shower          43469 non-null  uint8  \n 64  ConditionCode_Sleet                43469 non-null  uint8  \n 65  ConditionCode_Snow Shower          43469 non-null  uint8  \n 66  ConditionCode_Snowfall             43469 non-null  uint8  \n 67  ConditionCode_Storm                43469 non-null  uint8  \n 68  ConditionCode_Thunderstorm         43469 non-null  uint8  \n 69  ConditionCode_Unknown              43469 non-null  uint8  \ndtypes: float64(10), int32(3), uint8(57)\nmemory usage: 6.5 MB\nNone\nDone exporting test-data.csv\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "separator = ','\n",
    "isIndexNeeded = False\n",
    "\n",
    "access_key = dbutils.secrets.get(scope = 'aws', key = 'accessKey')\n",
    "secret_key = dbutils.secrets.get(scope = 'aws', key = 'secretAccessKey')\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)\n",
    "\n",
    "bytes_to_write = dfpComplete.to_csv(None, sep=separator, index=isIndexNeeded, header=False).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open(f's3://<BUCKET_NAME>/flights-csv/full-data/complete-data.csv', 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "  \n",
    "bytes_to_write = dfpComplete.to_csv(None, sep=separator, index=isIndexNeeded, header=True).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open(f's3://<BUCKET_NAME>/flights-csv/full-data/complete-data-with-header.csv', 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "\n",
    "print(f'Done exporting complete-data.csv')\n",
    "  \n",
    "# Split data into training and test sets\n",
    "\n",
    "# main paths, uncomment when ready\n",
    "train_data_path = 's3://<BUCKET_NAME>/flights-csv/train-data/train-data.csv'\n",
    "test_data_path = 's3://<BUCKET_NAME>/flights-csv/test-data/test-data.csv'\n",
    "train_data_path_with_header = 's3://<BUCKET_NAME>/flights-csv/train-data-with-header/train-data-with-header.csv'\n",
    "test_data_path_with_header = 's3://<BUCKET_NAME>/flights-csv/test-data-with-header/test-data-with-header.csv'\n",
    "\n",
    "# for experimentation\n",
    "train_data_path_backup = 's3://<BUCKET_NAME>/flights-csv/full-data/train-data/train-data.csv'\n",
    "test_data_path_backup = 's3://<BUCKET_NAME>/flights-csv/full-data/test-data/test-data.csv'\n",
    "train_data_path_backup_with_header = 's3://<BUCKET_NAME>/flights-csv/full-data/train-data-with-header/train-data-with-header.csv'\n",
    "test_data_path_backup_with_header = 's3://<BUCKET_NAME>/flights-csv/full-data/test-data-with-header/test-data-with-header.csv'\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(dfpComplete, test_size=0.2)\n",
    "\n",
    "# Export training set\n",
    "bytes_to_write = train_df.to_csv(None, sep=separator, index=isIndexNeeded, header=False).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open(train_data_path, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "  \n",
    "with fs.open(train_data_path_backup, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "\n",
    "bytes_to_write = train_df.to_csv(None, sep=separator, index=isIndexNeeded, header=True).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open(train_data_path_with_header, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "\n",
    "with fs.open(train_data_path_backup_with_header, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "  \n",
    "print(f'Size of training set = {len(train_df)}') \n",
    "print(train_df.info())\n",
    "print(f'Done exporting train-data.csv')  \n",
    "  \n",
    "# Export test set\n",
    "bytes_to_write = test_df.to_csv(None, sep=separator, index=isIndexNeeded, header=False).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open(test_data_path, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "\n",
    "with fs.open(test_data_path_backup, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "  \n",
    "bytes_to_write = test_df.to_csv(None, sep=separator, index=isIndexNeeded, header=True).encode()\n",
    "fs = s3fs.S3FileSystem(key=access_key, secret=secret_key)\n",
    "with fs.open(test_data_path_with_header, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "\n",
    "with fs.open(test_data_path_backup_with_header, 'wb') as f:\n",
    "  f.write(bytes_to_write)\n",
    "  \n",
    "print(f'Size of test set = {len(test_df)}')\n",
    "print(test_df.info())\n",
    "print(f'Done exporting test-data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "25885c44-afee-43e4-8b08-bad6ce97d399",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[14]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[14]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunwayWaitTimeInSeconds</th>\n",
       "      <th>OtherDepartures</th>\n",
       "      <th>FlightDuration</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dewpoint</th>\n",
       "      <th>RelativeHumidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>SnowLevel</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>PeakWindGust</th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>From_ATL</th>\n",
       "      <th>From_BOS</th>\n",
       "      <th>From_CLT</th>\n",
       "      <th>From_DEN</th>\n",
       "      <th>From_DFW</th>\n",
       "      <th>From_DTW</th>\n",
       "      <th>From_EWR</th>\n",
       "      <th>From_FLL</th>\n",
       "      <th>From_IAD</th>\n",
       "      <th>From_IAH</th>\n",
       "      <th>From_JFK</th>\n",
       "      <th>From_LAS</th>\n",
       "      <th>From_LAX</th>\n",
       "      <th>From_LGA</th>\n",
       "      <th>From_MCO</th>\n",
       "      <th>From_MDW</th>\n",
       "      <th>From_MIA</th>\n",
       "      <th>From_MSP</th>\n",
       "      <th>From_ORD</th>\n",
       "      <th>From_PDX</th>\n",
       "      <th>From_PHL</th>\n",
       "      <th>From_PHX</th>\n",
       "      <th>From_SEA</th>\n",
       "      <th>From_SFO</th>\n",
       "      <th>From_SLC</th>\n",
       "      <th>From_TPA</th>\n",
       "      <th>Op_Alaska Airlines</th>\n",
       "      <th>Op_American Airlines</th>\n",
       "      <th>Op_Delta Air Lines</th>\n",
       "      <th>Op_JetBlue Airways</th>\n",
       "      <th>Op_Southwest Airlines</th>\n",
       "      <th>Op_United Airlines</th>\n",
       "      <th>DayType_Christmas</th>\n",
       "      <th>DayType_Regular</th>\n",
       "      <th>DayType_Thanksgiving</th>\n",
       "      <th>ConditionCode_Clear</th>\n",
       "      <th>ConditionCode_Cloudy</th>\n",
       "      <th>ConditionCode_Fair</th>\n",
       "      <th>ConditionCode_Fog</th>\n",
       "      <th>ConditionCode_Freezing Rain</th>\n",
       "      <th>ConditionCode_Heavy Freezing Rain</th>\n",
       "      <th>ConditionCode_Heavy Rain</th>\n",
       "      <th>ConditionCode_Heavy Rain Shower</th>\n",
       "      <th>ConditionCode_Heavy Sleet</th>\n",
       "      <th>ConditionCode_Heavy Snowfall</th>\n",
       "      <th>ConditionCode_Heavy Thunderstorm</th>\n",
       "      <th>ConditionCode_Light Rain</th>\n",
       "      <th>ConditionCode_Light Snowfall</th>\n",
       "      <th>ConditionCode_Overcast</th>\n",
       "      <th>ConditionCode_Rain</th>\n",
       "      <th>ConditionCode_Rain Shower</th>\n",
       "      <th>ConditionCode_Sleet</th>\n",
       "      <th>ConditionCode_Snow Shower</th>\n",
       "      <th>ConditionCode_Snowfall</th>\n",
       "      <th>ConditionCode_Storm</th>\n",
       "      <th>ConditionCode_Thunderstorm</th>\n",
       "      <th>ConditionCode_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>12</td>\n",
       "      <td>2639</td>\n",
       "      <td>67.10</td>\n",
       "      <td>12.7</td>\n",
       "      <td>64.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5704</td>\n",
       "      <td>11</td>\n",
       "      <td>9890</td>\n",
       "      <td>58.28</td>\n",
       "      <td>9.9</td>\n",
       "      <td>73.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4792</td>\n",
       "      <td>12</td>\n",
       "      <td>3239</td>\n",
       "      <td>65.48</td>\n",
       "      <td>6.7</td>\n",
       "      <td>46.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1015.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>474</td>\n",
       "      <td>42</td>\n",
       "      <td>16800</td>\n",
       "      <td>51.44</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92</td>\n",
       "      <td>43</td>\n",
       "      <td>1146</td>\n",
       "      <td>66.74</td>\n",
       "      <td>-11.3</td>\n",
       "      <td>11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RunwayWaitTimeInSeconds</th>\n      <th>OtherDepartures</th>\n      <th>FlightDuration</th>\n      <th>Temperature</th>\n      <th>Dewpoint</th>\n      <th>RelativeHumidity</th>\n      <th>Precipitation</th>\n      <th>SnowLevel</th>\n      <th>WindDirection</th>\n      <th>WindSpeed</th>\n      <th>PeakWindGust</th>\n      <th>AirPressure</th>\n      <th>Sunshine</th>\n      <th>From_ATL</th>\n      <th>From_BOS</th>\n      <th>From_CLT</th>\n      <th>From_DEN</th>\n      <th>From_DFW</th>\n      <th>From_DTW</th>\n      <th>From_EWR</th>\n      <th>From_FLL</th>\n      <th>From_IAD</th>\n      <th>From_IAH</th>\n      <th>From_JFK</th>\n      <th>From_LAS</th>\n      <th>From_LAX</th>\n      <th>From_LGA</th>\n      <th>From_MCO</th>\n      <th>From_MDW</th>\n      <th>From_MIA</th>\n      <th>From_MSP</th>\n      <th>From_ORD</th>\n      <th>From_PDX</th>\n      <th>From_PHL</th>\n      <th>From_PHX</th>\n      <th>From_SEA</th>\n      <th>From_SFO</th>\n      <th>From_SLC</th>\n      <th>From_TPA</th>\n      <th>Op_Alaska Airlines</th>\n      <th>Op_American Airlines</th>\n      <th>Op_Delta Air Lines</th>\n      <th>Op_JetBlue Airways</th>\n      <th>Op_Southwest Airlines</th>\n      <th>Op_United Airlines</th>\n      <th>DayType_Christmas</th>\n      <th>DayType_Regular</th>\n      <th>DayType_Thanksgiving</th>\n      <th>ConditionCode_Clear</th>\n      <th>ConditionCode_Cloudy</th>\n      <th>ConditionCode_Fair</th>\n      <th>ConditionCode_Fog</th>\n      <th>ConditionCode_Freezing Rain</th>\n      <th>ConditionCode_Heavy Freezing Rain</th>\n      <th>ConditionCode_Heavy Rain</th>\n      <th>ConditionCode_Heavy Rain Shower</th>\n      <th>ConditionCode_Heavy Sleet</th>\n      <th>ConditionCode_Heavy Snowfall</th>\n      <th>ConditionCode_Heavy Thunderstorm</th>\n      <th>ConditionCode_Light Rain</th>\n      <th>ConditionCode_Light Snowfall</th>\n      <th>ConditionCode_Overcast</th>\n      <th>ConditionCode_Rain</th>\n      <th>ConditionCode_Rain Shower</th>\n      <th>ConditionCode_Sleet</th>\n      <th>ConditionCode_Snow Shower</th>\n      <th>ConditionCode_Snowfall</th>\n      <th>ConditionCode_Storm</th>\n      <th>ConditionCode_Thunderstorm</th>\n      <th>ConditionCode_Unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>32</td>\n      <td>12</td>\n      <td>2639</td>\n      <td>67.10</td>\n      <td>12.7</td>\n      <td>64.9</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>250.0</td>\n      <td>4.7</td>\n      <td>0.0</td>\n      <td>1019.1</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5704</td>\n      <td>11</td>\n      <td>9890</td>\n      <td>58.28</td>\n      <td>9.9</td>\n      <td>73.5</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>80.0</td>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>1015.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4792</td>\n      <td>12</td>\n      <td>3239</td>\n      <td>65.48</td>\n      <td>6.7</td>\n      <td>46.3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>250.0</td>\n      <td>9.1</td>\n      <td>0.0</td>\n      <td>1015.7</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>474</td>\n      <td>42</td>\n      <td>16800</td>\n      <td>51.44</td>\n      <td>-7.9</td>\n      <td>26.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>60.0</td>\n      <td>3.7</td>\n      <td>0.0</td>\n      <td>1018.5</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>92</td>\n      <td>43</td>\n      <td>1146</td>\n      <td>66.74</td>\n      <td>-11.3</td>\n      <td>11.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>70.0</td>\n      <td>9.4</td>\n      <td>0.0</td>\n      <td>1020.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfpComplete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a130d2a4-6d66-4046-ac4c-0b8319f071ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[15]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[15]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunwayWaitTimeInSeconds</th>\n",
       "      <th>OtherDepartures</th>\n",
       "      <th>FlightDuration</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dewpoint</th>\n",
       "      <th>RelativeHumidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>SnowLevel</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>PeakWindGust</th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>From_ATL</th>\n",
       "      <th>From_BOS</th>\n",
       "      <th>From_CLT</th>\n",
       "      <th>From_DEN</th>\n",
       "      <th>From_DFW</th>\n",
       "      <th>From_DTW</th>\n",
       "      <th>From_EWR</th>\n",
       "      <th>From_FLL</th>\n",
       "      <th>From_IAD</th>\n",
       "      <th>From_IAH</th>\n",
       "      <th>From_JFK</th>\n",
       "      <th>From_LAS</th>\n",
       "      <th>From_LAX</th>\n",
       "      <th>From_LGA</th>\n",
       "      <th>From_MCO</th>\n",
       "      <th>From_MDW</th>\n",
       "      <th>From_MIA</th>\n",
       "      <th>From_MSP</th>\n",
       "      <th>From_ORD</th>\n",
       "      <th>From_PDX</th>\n",
       "      <th>From_PHL</th>\n",
       "      <th>From_PHX</th>\n",
       "      <th>From_SEA</th>\n",
       "      <th>From_SFO</th>\n",
       "      <th>From_SLC</th>\n",
       "      <th>From_TPA</th>\n",
       "      <th>Op_Alaska Airlines</th>\n",
       "      <th>Op_American Airlines</th>\n",
       "      <th>Op_Delta Air Lines</th>\n",
       "      <th>Op_JetBlue Airways</th>\n",
       "      <th>Op_Southwest Airlines</th>\n",
       "      <th>Op_United Airlines</th>\n",
       "      <th>DayType_Christmas</th>\n",
       "      <th>DayType_Regular</th>\n",
       "      <th>DayType_Thanksgiving</th>\n",
       "      <th>ConditionCode_Clear</th>\n",
       "      <th>ConditionCode_Cloudy</th>\n",
       "      <th>ConditionCode_Fair</th>\n",
       "      <th>ConditionCode_Fog</th>\n",
       "      <th>ConditionCode_Freezing Rain</th>\n",
       "      <th>ConditionCode_Heavy Freezing Rain</th>\n",
       "      <th>ConditionCode_Heavy Rain</th>\n",
       "      <th>ConditionCode_Heavy Rain Shower</th>\n",
       "      <th>ConditionCode_Heavy Sleet</th>\n",
       "      <th>ConditionCode_Heavy Snowfall</th>\n",
       "      <th>ConditionCode_Heavy Thunderstorm</th>\n",
       "      <th>ConditionCode_Light Rain</th>\n",
       "      <th>ConditionCode_Light Snowfall</th>\n",
       "      <th>ConditionCode_Overcast</th>\n",
       "      <th>ConditionCode_Rain</th>\n",
       "      <th>ConditionCode_Rain Shower</th>\n",
       "      <th>ConditionCode_Sleet</th>\n",
       "      <th>ConditionCode_Snow Shower</th>\n",
       "      <th>ConditionCode_Snowfall</th>\n",
       "      <th>ConditionCode_Storm</th>\n",
       "      <th>ConditionCode_Thunderstorm</th>\n",
       "      <th>ConditionCode_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.0</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.0</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.0</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "      <td>173872.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2183.579259</td>\n",
       "      <td>23.587547</td>\n",
       "      <td>10982.529700</td>\n",
       "      <td>52.057781</td>\n",
       "      <td>2.027325</td>\n",
       "      <td>60.319624</td>\n",
       "      <td>0.085855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191.033410</td>\n",
       "      <td>11.473994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.055679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001294</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.094685</td>\n",
       "      <td>0.069747</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.029568</td>\n",
       "      <td>0.002030</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.030781</td>\n",
       "      <td>0.092148</td>\n",
       "      <td>0.093074</td>\n",
       "      <td>0.035911</td>\n",
       "      <td>0.021136</td>\n",
       "      <td>0.002910</td>\n",
       "      <td>0.008466</td>\n",
       "      <td>0.024662</td>\n",
       "      <td>0.062362</td>\n",
       "      <td>0.013447</td>\n",
       "      <td>0.046563</td>\n",
       "      <td>0.096611</td>\n",
       "      <td>0.066244</td>\n",
       "      <td>0.083015</td>\n",
       "      <td>0.082474</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.101178</td>\n",
       "      <td>0.271901</td>\n",
       "      <td>0.194246</td>\n",
       "      <td>0.057807</td>\n",
       "      <td>0.197018</td>\n",
       "      <td>0.177849</td>\n",
       "      <td>0.185188</td>\n",
       "      <td>0.741672</td>\n",
       "      <td>0.073140</td>\n",
       "      <td>0.105509</td>\n",
       "      <td>0.236387</td>\n",
       "      <td>0.397977</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.001725</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.068907</td>\n",
       "      <td>0.021562</td>\n",
       "      <td>0.091751</td>\n",
       "      <td>0.015632</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.007034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2161.403511</td>\n",
       "      <td>21.705544</td>\n",
       "      <td>11824.529866</td>\n",
       "      <td>16.187349</td>\n",
       "      <td>8.563100</td>\n",
       "      <td>24.537910</td>\n",
       "      <td>0.469123</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.893383</td>\n",
       "      <td>7.919899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.173373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035950</td>\n",
       "      <td>0.136837</td>\n",
       "      <td>0.046329</td>\n",
       "      <td>0.292780</td>\n",
       "      <td>0.254720</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.169392</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.172725</td>\n",
       "      <td>0.289236</td>\n",
       "      <td>0.290537</td>\n",
       "      <td>0.186070</td>\n",
       "      <td>0.143839</td>\n",
       "      <td>0.053868</td>\n",
       "      <td>0.091621</td>\n",
       "      <td>0.155093</td>\n",
       "      <td>0.241813</td>\n",
       "      <td>0.115178</td>\n",
       "      <td>0.210702</td>\n",
       "      <td>0.295429</td>\n",
       "      <td>0.248709</td>\n",
       "      <td>0.275906</td>\n",
       "      <td>0.275087</td>\n",
       "      <td>0.117271</td>\n",
       "      <td>0.301565</td>\n",
       "      <td>0.444941</td>\n",
       "      <td>0.395621</td>\n",
       "      <td>0.233379</td>\n",
       "      <td>0.397748</td>\n",
       "      <td>0.382387</td>\n",
       "      <td>0.388451</td>\n",
       "      <td>0.437716</td>\n",
       "      <td>0.260367</td>\n",
       "      <td>0.307209</td>\n",
       "      <td>0.424863</td>\n",
       "      <td>0.489482</td>\n",
       "      <td>0.199567</td>\n",
       "      <td>0.018727</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.041502</td>\n",
       "      <td>0.005362</td>\n",
       "      <td>0.012460</td>\n",
       "      <td>0.017124</td>\n",
       "      <td>0.253297</td>\n",
       "      <td>0.145248</td>\n",
       "      <td>0.288676</td>\n",
       "      <td>0.124048</td>\n",
       "      <td>0.035387</td>\n",
       "      <td>0.034233</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.033641</td>\n",
       "      <td>0.006345</td>\n",
       "      <td>0.032069</td>\n",
       "      <td>0.083573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>-5.440000</td>\n",
       "      <td>-24.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>980.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>467.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3868.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-4.300000</td>\n",
       "      <td>41.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1057.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>7096.000000</td>\n",
       "      <td>52.340000</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4091.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12201.000000</td>\n",
       "      <td>63.140000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>80.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7200.000000</td>\n",
       "      <td>335.000000</td>\n",
       "      <td>68375.000000</td>\n",
       "      <td>102.020000</td>\n",
       "      <td>26.600000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>80.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1041.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RunwayWaitTimeInSeconds</th>\n      <th>OtherDepartures</th>\n      <th>FlightDuration</th>\n      <th>Temperature</th>\n      <th>Dewpoint</th>\n      <th>RelativeHumidity</th>\n      <th>Precipitation</th>\n      <th>SnowLevel</th>\n      <th>WindDirection</th>\n      <th>WindSpeed</th>\n      <th>PeakWindGust</th>\n      <th>AirPressure</th>\n      <th>Sunshine</th>\n      <th>From_ATL</th>\n      <th>From_BOS</th>\n      <th>From_CLT</th>\n      <th>From_DEN</th>\n      <th>From_DFW</th>\n      <th>From_DTW</th>\n      <th>From_EWR</th>\n      <th>From_FLL</th>\n      <th>From_IAD</th>\n      <th>From_IAH</th>\n      <th>From_JFK</th>\n      <th>From_LAS</th>\n      <th>From_LAX</th>\n      <th>From_LGA</th>\n      <th>From_MCO</th>\n      <th>From_MDW</th>\n      <th>From_MIA</th>\n      <th>From_MSP</th>\n      <th>From_ORD</th>\n      <th>From_PDX</th>\n      <th>From_PHL</th>\n      <th>From_PHX</th>\n      <th>From_SEA</th>\n      <th>From_SFO</th>\n      <th>From_SLC</th>\n      <th>From_TPA</th>\n      <th>Op_Alaska Airlines</th>\n      <th>Op_American Airlines</th>\n      <th>Op_Delta Air Lines</th>\n      <th>Op_JetBlue Airways</th>\n      <th>Op_Southwest Airlines</th>\n      <th>Op_United Airlines</th>\n      <th>DayType_Christmas</th>\n      <th>DayType_Regular</th>\n      <th>DayType_Thanksgiving</th>\n      <th>ConditionCode_Clear</th>\n      <th>ConditionCode_Cloudy</th>\n      <th>ConditionCode_Fair</th>\n      <th>ConditionCode_Fog</th>\n      <th>ConditionCode_Freezing Rain</th>\n      <th>ConditionCode_Heavy Freezing Rain</th>\n      <th>ConditionCode_Heavy Rain</th>\n      <th>ConditionCode_Heavy Rain Shower</th>\n      <th>ConditionCode_Heavy Sleet</th>\n      <th>ConditionCode_Heavy Snowfall</th>\n      <th>ConditionCode_Heavy Thunderstorm</th>\n      <th>ConditionCode_Light Rain</th>\n      <th>ConditionCode_Light Snowfall</th>\n      <th>ConditionCode_Overcast</th>\n      <th>ConditionCode_Rain</th>\n      <th>ConditionCode_Rain Shower</th>\n      <th>ConditionCode_Sleet</th>\n      <th>ConditionCode_Snow Shower</th>\n      <th>ConditionCode_Snowfall</th>\n      <th>ConditionCode_Storm</th>\n      <th>ConditionCode_Thunderstorm</th>\n      <th>ConditionCode_Unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.0</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.0</td>\n      <td>173872.000000</td>\n      <td>173872.0</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n      <td>173872.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2183.579259</td>\n      <td>23.587547</td>\n      <td>10982.529700</td>\n      <td>52.057781</td>\n      <td>2.027325</td>\n      <td>60.319624</td>\n      <td>0.085855</td>\n      <td>0.0</td>\n      <td>191.033410</td>\n      <td>11.473994</td>\n      <td>0.0</td>\n      <td>1018.055679</td>\n      <td>0.0</td>\n      <td>0.001294</td>\n      <td>0.019089</td>\n      <td>0.002151</td>\n      <td>0.094685</td>\n      <td>0.069747</td>\n      <td>0.000213</td>\n      <td>0.029568</td>\n      <td>0.002030</td>\n      <td>0.007379</td>\n      <td>0.000092</td>\n      <td>0.030781</td>\n      <td>0.092148</td>\n      <td>0.093074</td>\n      <td>0.035911</td>\n      <td>0.021136</td>\n      <td>0.002910</td>\n      <td>0.008466</td>\n      <td>0.024662</td>\n      <td>0.062362</td>\n      <td>0.013447</td>\n      <td>0.046563</td>\n      <td>0.096611</td>\n      <td>0.066244</td>\n      <td>0.083015</td>\n      <td>0.082474</td>\n      <td>0.013947</td>\n      <td>0.101178</td>\n      <td>0.271901</td>\n      <td>0.194246</td>\n      <td>0.057807</td>\n      <td>0.197018</td>\n      <td>0.177849</td>\n      <td>0.185188</td>\n      <td>0.741672</td>\n      <td>0.073140</td>\n      <td>0.105509</td>\n      <td>0.236387</td>\n      <td>0.397977</td>\n      <td>0.041554</td>\n      <td>0.000351</td>\n      <td>0.000017</td>\n      <td>0.004049</td>\n      <td>0.001725</td>\n      <td>0.000029</td>\n      <td>0.000155</td>\n      <td>0.000293</td>\n      <td>0.068907</td>\n      <td>0.021562</td>\n      <td>0.091751</td>\n      <td>0.015632</td>\n      <td>0.001254</td>\n      <td>0.001173</td>\n      <td>0.000253</td>\n      <td>0.001133</td>\n      <td>0.000040</td>\n      <td>0.001029</td>\n      <td>0.007034</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2161.403511</td>\n      <td>21.705544</td>\n      <td>11824.529866</td>\n      <td>16.187349</td>\n      <td>8.563100</td>\n      <td>24.537910</td>\n      <td>0.469123</td>\n      <td>0.0</td>\n      <td>99.893383</td>\n      <td>7.919899</td>\n      <td>0.0</td>\n      <td>7.173373</td>\n      <td>0.0</td>\n      <td>0.035950</td>\n      <td>0.136837</td>\n      <td>0.046329</td>\n      <td>0.292780</td>\n      <td>0.254720</td>\n      <td>0.014586</td>\n      <td>0.169392</td>\n      <td>0.045012</td>\n      <td>0.085584</td>\n      <td>0.009592</td>\n      <td>0.172725</td>\n      <td>0.289236</td>\n      <td>0.290537</td>\n      <td>0.186070</td>\n      <td>0.143839</td>\n      <td>0.053868</td>\n      <td>0.091621</td>\n      <td>0.155093</td>\n      <td>0.241813</td>\n      <td>0.115178</td>\n      <td>0.210702</td>\n      <td>0.295429</td>\n      <td>0.248709</td>\n      <td>0.275906</td>\n      <td>0.275087</td>\n      <td>0.117271</td>\n      <td>0.301565</td>\n      <td>0.444941</td>\n      <td>0.395621</td>\n      <td>0.233379</td>\n      <td>0.397748</td>\n      <td>0.382387</td>\n      <td>0.388451</td>\n      <td>0.437716</td>\n      <td>0.260367</td>\n      <td>0.307209</td>\n      <td>0.424863</td>\n      <td>0.489482</td>\n      <td>0.199567</td>\n      <td>0.018727</td>\n      <td>0.004154</td>\n      <td>0.063503</td>\n      <td>0.041502</td>\n      <td>0.005362</td>\n      <td>0.012460</td>\n      <td>0.017124</td>\n      <td>0.253297</td>\n      <td>0.145248</td>\n      <td>0.288676</td>\n      <td>0.124048</td>\n      <td>0.035387</td>\n      <td>0.034233</td>\n      <td>0.015906</td>\n      <td>0.033641</td>\n      <td>0.006345</td>\n      <td>0.032069</td>\n      <td>0.083573</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>901.000000</td>\n      <td>-5.440000</td>\n      <td>-24.500000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>980.500000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>467.000000</td>\n      <td>9.000000</td>\n      <td>3868.000000</td>\n      <td>41.000000</td>\n      <td>-4.300000</td>\n      <td>41.300000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>110.000000</td>\n      <td>5.700000</td>\n      <td>0.0</td>\n      <td>1013.600000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1057.000000</td>\n      <td>18.000000</td>\n      <td>7096.000000</td>\n      <td>52.340000</td>\n      <td>1.400000</td>\n      <td>64.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>200.000000</td>\n      <td>10.100000</td>\n      <td>0.0</td>\n      <td>1018.100000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4091.000000</td>\n      <td>31.000000</td>\n      <td>12201.000000</td>\n      <td>63.140000</td>\n      <td>8.100000</td>\n      <td>80.900000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>270.000000</td>\n      <td>16.000000</td>\n      <td>0.0</td>\n      <td>1022.700000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7200.000000</td>\n      <td>335.000000</td>\n      <td>68375.000000</td>\n      <td>102.020000</td>\n      <td>26.600000</td>\n      <td>100.000000</td>\n      <td>14.100000</td>\n      <td>0.0</td>\n      <td>360.000000</td>\n      <td>80.200000</td>\n      <td>0.0</td>\n      <td>1041.500000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0087c555-3491-4b95-a6a7-f8ec7740455a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[16]: </div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[16]: </div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RunwayWaitTimeInSeconds</th>\n",
       "      <th>OtherDepartures</th>\n",
       "      <th>FlightDuration</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Dewpoint</th>\n",
       "      <th>RelativeHumidity</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>SnowLevel</th>\n",
       "      <th>WindDirection</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>PeakWindGust</th>\n",
       "      <th>AirPressure</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>From_ATL</th>\n",
       "      <th>From_BOS</th>\n",
       "      <th>From_CLT</th>\n",
       "      <th>From_DEN</th>\n",
       "      <th>From_DFW</th>\n",
       "      <th>From_DTW</th>\n",
       "      <th>From_EWR</th>\n",
       "      <th>From_FLL</th>\n",
       "      <th>From_IAD</th>\n",
       "      <th>From_IAH</th>\n",
       "      <th>From_JFK</th>\n",
       "      <th>From_LAS</th>\n",
       "      <th>From_LAX</th>\n",
       "      <th>From_LGA</th>\n",
       "      <th>From_MCO</th>\n",
       "      <th>From_MDW</th>\n",
       "      <th>From_MIA</th>\n",
       "      <th>From_MSP</th>\n",
       "      <th>From_ORD</th>\n",
       "      <th>From_PDX</th>\n",
       "      <th>From_PHL</th>\n",
       "      <th>From_PHX</th>\n",
       "      <th>From_SEA</th>\n",
       "      <th>From_SFO</th>\n",
       "      <th>From_SLC</th>\n",
       "      <th>From_TPA</th>\n",
       "      <th>Op_Alaska Airlines</th>\n",
       "      <th>Op_American Airlines</th>\n",
       "      <th>Op_Delta Air Lines</th>\n",
       "      <th>Op_JetBlue Airways</th>\n",
       "      <th>Op_Southwest Airlines</th>\n",
       "      <th>Op_United Airlines</th>\n",
       "      <th>DayType_Christmas</th>\n",
       "      <th>DayType_Regular</th>\n",
       "      <th>DayType_Thanksgiving</th>\n",
       "      <th>ConditionCode_Clear</th>\n",
       "      <th>ConditionCode_Cloudy</th>\n",
       "      <th>ConditionCode_Fair</th>\n",
       "      <th>ConditionCode_Fog</th>\n",
       "      <th>ConditionCode_Freezing Rain</th>\n",
       "      <th>ConditionCode_Heavy Freezing Rain</th>\n",
       "      <th>ConditionCode_Heavy Rain</th>\n",
       "      <th>ConditionCode_Heavy Rain Shower</th>\n",
       "      <th>ConditionCode_Heavy Sleet</th>\n",
       "      <th>ConditionCode_Heavy Snowfall</th>\n",
       "      <th>ConditionCode_Heavy Thunderstorm</th>\n",
       "      <th>ConditionCode_Light Rain</th>\n",
       "      <th>ConditionCode_Light Snowfall</th>\n",
       "      <th>ConditionCode_Overcast</th>\n",
       "      <th>ConditionCode_Rain</th>\n",
       "      <th>ConditionCode_Rain Shower</th>\n",
       "      <th>ConditionCode_Sleet</th>\n",
       "      <th>ConditionCode_Snow Shower</th>\n",
       "      <th>ConditionCode_Snowfall</th>\n",
       "      <th>ConditionCode_Storm</th>\n",
       "      <th>ConditionCode_Thunderstorm</th>\n",
       "      <th>ConditionCode_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.0</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.0</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.0</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.0</td>\n",
       "      <td>43469.000000</td>\n",
       "      <td>43469.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2180.175803</td>\n",
       "      <td>23.596126</td>\n",
       "      <td>10931.541006</td>\n",
       "      <td>52.079117</td>\n",
       "      <td>1.942525</td>\n",
       "      <td>59.970211</td>\n",
       "      <td>0.084971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.295613</td>\n",
       "      <td>11.467414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.055014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.020290</td>\n",
       "      <td>0.002439</td>\n",
       "      <td>0.093975</td>\n",
       "      <td>0.068187</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.028595</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.007799</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.030136</td>\n",
       "      <td>0.093170</td>\n",
       "      <td>0.093423</td>\n",
       "      <td>0.035197</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.002899</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.025581</td>\n",
       "      <td>0.061722</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.045136</td>\n",
       "      <td>0.099013</td>\n",
       "      <td>0.066300</td>\n",
       "      <td>0.082220</td>\n",
       "      <td>0.085026</td>\n",
       "      <td>0.014033</td>\n",
       "      <td>0.099956</td>\n",
       "      <td>0.274748</td>\n",
       "      <td>0.195565</td>\n",
       "      <td>0.056339</td>\n",
       "      <td>0.196278</td>\n",
       "      <td>0.177115</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>0.737606</td>\n",
       "      <td>0.074996</td>\n",
       "      <td>0.105708</td>\n",
       "      <td>0.236950</td>\n",
       "      <td>0.400676</td>\n",
       "      <td>0.041064</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.004486</td>\n",
       "      <td>0.001702</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.069176</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.088684</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.001058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000897</td>\n",
       "      <td>0.006947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2156.691355</td>\n",
       "      <td>21.695161</td>\n",
       "      <td>11770.985448</td>\n",
       "      <td>16.185241</td>\n",
       "      <td>8.568343</td>\n",
       "      <td>24.643036</td>\n",
       "      <td>0.466498</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.056522</td>\n",
       "      <td>7.905617</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.216754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035870</td>\n",
       "      <td>0.140993</td>\n",
       "      <td>0.049322</td>\n",
       "      <td>0.291797</td>\n",
       "      <td>0.252069</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.087966</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.170965</td>\n",
       "      <td>0.290674</td>\n",
       "      <td>0.291028</td>\n",
       "      <td>0.184281</td>\n",
       "      <td>0.141150</td>\n",
       "      <td>0.053761</td>\n",
       "      <td>0.093935</td>\n",
       "      <td>0.157885</td>\n",
       "      <td>0.240653</td>\n",
       "      <td>0.110256</td>\n",
       "      <td>0.207604</td>\n",
       "      <td>0.298683</td>\n",
       "      <td>0.248809</td>\n",
       "      <td>0.274702</td>\n",
       "      <td>0.278924</td>\n",
       "      <td>0.117628</td>\n",
       "      <td>0.299945</td>\n",
       "      <td>0.446392</td>\n",
       "      <td>0.396639</td>\n",
       "      <td>0.230578</td>\n",
       "      <td>0.397186</td>\n",
       "      <td>0.381770</td>\n",
       "      <td>0.390235</td>\n",
       "      <td>0.439941</td>\n",
       "      <td>0.263388</td>\n",
       "      <td>0.307466</td>\n",
       "      <td>0.425217</td>\n",
       "      <td>0.490041</td>\n",
       "      <td>0.198440</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.066828</td>\n",
       "      <td>0.041225</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.015166</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.253756</td>\n",
       "      <td>0.142162</td>\n",
       "      <td>0.284290</td>\n",
       "      <td>0.124987</td>\n",
       "      <td>0.033212</td>\n",
       "      <td>0.037127</td>\n",
       "      <td>0.020345</td>\n",
       "      <td>0.032514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.083062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>901.000000</td>\n",
       "      <td>-4.540000</td>\n",
       "      <td>-23.900000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>977.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3895.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>-4.400000</td>\n",
       "      <td>40.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>5.700000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1013.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1056.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7094.000000</td>\n",
       "      <td>52.520000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>63.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>10.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1018.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4079.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>12110.000000</td>\n",
       "      <td>63.140000</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>80.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7200.000000</td>\n",
       "      <td>325.000000</td>\n",
       "      <td>68384.000000</td>\n",
       "      <td>102.560000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>18.300000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>80.200000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1041.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RunwayWaitTimeInSeconds</th>\n      <th>OtherDepartures</th>\n      <th>FlightDuration</th>\n      <th>Temperature</th>\n      <th>Dewpoint</th>\n      <th>RelativeHumidity</th>\n      <th>Precipitation</th>\n      <th>SnowLevel</th>\n      <th>WindDirection</th>\n      <th>WindSpeed</th>\n      <th>PeakWindGust</th>\n      <th>AirPressure</th>\n      <th>Sunshine</th>\n      <th>From_ATL</th>\n      <th>From_BOS</th>\n      <th>From_CLT</th>\n      <th>From_DEN</th>\n      <th>From_DFW</th>\n      <th>From_DTW</th>\n      <th>From_EWR</th>\n      <th>From_FLL</th>\n      <th>From_IAD</th>\n      <th>From_IAH</th>\n      <th>From_JFK</th>\n      <th>From_LAS</th>\n      <th>From_LAX</th>\n      <th>From_LGA</th>\n      <th>From_MCO</th>\n      <th>From_MDW</th>\n      <th>From_MIA</th>\n      <th>From_MSP</th>\n      <th>From_ORD</th>\n      <th>From_PDX</th>\n      <th>From_PHL</th>\n      <th>From_PHX</th>\n      <th>From_SEA</th>\n      <th>From_SFO</th>\n      <th>From_SLC</th>\n      <th>From_TPA</th>\n      <th>Op_Alaska Airlines</th>\n      <th>Op_American Airlines</th>\n      <th>Op_Delta Air Lines</th>\n      <th>Op_JetBlue Airways</th>\n      <th>Op_Southwest Airlines</th>\n      <th>Op_United Airlines</th>\n      <th>DayType_Christmas</th>\n      <th>DayType_Regular</th>\n      <th>DayType_Thanksgiving</th>\n      <th>ConditionCode_Clear</th>\n      <th>ConditionCode_Cloudy</th>\n      <th>ConditionCode_Fair</th>\n      <th>ConditionCode_Fog</th>\n      <th>ConditionCode_Freezing Rain</th>\n      <th>ConditionCode_Heavy Freezing Rain</th>\n      <th>ConditionCode_Heavy Rain</th>\n      <th>ConditionCode_Heavy Rain Shower</th>\n      <th>ConditionCode_Heavy Sleet</th>\n      <th>ConditionCode_Heavy Snowfall</th>\n      <th>ConditionCode_Heavy Thunderstorm</th>\n      <th>ConditionCode_Light Rain</th>\n      <th>ConditionCode_Light Snowfall</th>\n      <th>ConditionCode_Overcast</th>\n      <th>ConditionCode_Rain</th>\n      <th>ConditionCode_Rain Shower</th>\n      <th>ConditionCode_Sleet</th>\n      <th>ConditionCode_Snow Shower</th>\n      <th>ConditionCode_Snowfall</th>\n      <th>ConditionCode_Storm</th>\n      <th>ConditionCode_Thunderstorm</th>\n      <th>ConditionCode_Unknown</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.0</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.0</td>\n      <td>43469.000000</td>\n      <td>43469.0</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n      <td>43469.0</td>\n      <td>43469.000000</td>\n      <td>43469.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>2180.175803</td>\n      <td>23.596126</td>\n      <td>10931.541006</td>\n      <td>52.079117</td>\n      <td>1.942525</td>\n      <td>59.970211</td>\n      <td>0.084971</td>\n      <td>0.0</td>\n      <td>190.295613</td>\n      <td>11.467414</td>\n      <td>0.0</td>\n      <td>1018.055014</td>\n      <td>0.0</td>\n      <td>0.001288</td>\n      <td>0.020290</td>\n      <td>0.002439</td>\n      <td>0.093975</td>\n      <td>0.068187</td>\n      <td>0.000115</td>\n      <td>0.028595</td>\n      <td>0.001702</td>\n      <td>0.007799</td>\n      <td>0.000207</td>\n      <td>0.030136</td>\n      <td>0.093170</td>\n      <td>0.093423</td>\n      <td>0.035197</td>\n      <td>0.020336</td>\n      <td>0.002899</td>\n      <td>0.008903</td>\n      <td>0.025581</td>\n      <td>0.061722</td>\n      <td>0.012308</td>\n      <td>0.045136</td>\n      <td>0.099013</td>\n      <td>0.066300</td>\n      <td>0.082220</td>\n      <td>0.085026</td>\n      <td>0.014033</td>\n      <td>0.099956</td>\n      <td>0.274748</td>\n      <td>0.195565</td>\n      <td>0.056339</td>\n      <td>0.196278</td>\n      <td>0.177115</td>\n      <td>0.187398</td>\n      <td>0.737606</td>\n      <td>0.074996</td>\n      <td>0.105708</td>\n      <td>0.236950</td>\n      <td>0.400676</td>\n      <td>0.041064</td>\n      <td>0.000414</td>\n      <td>0.000023</td>\n      <td>0.004486</td>\n      <td>0.001702</td>\n      <td>0.000092</td>\n      <td>0.000230</td>\n      <td>0.000046</td>\n      <td>0.069176</td>\n      <td>0.020635</td>\n      <td>0.088684</td>\n      <td>0.015873</td>\n      <td>0.001104</td>\n      <td>0.001380</td>\n      <td>0.000414</td>\n      <td>0.001058</td>\n      <td>0.0</td>\n      <td>0.000897</td>\n      <td>0.006947</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2156.691355</td>\n      <td>21.695161</td>\n      <td>11770.985448</td>\n      <td>16.185241</td>\n      <td>8.568343</td>\n      <td>24.643036</td>\n      <td>0.466498</td>\n      <td>0.0</td>\n      <td>100.056522</td>\n      <td>7.905617</td>\n      <td>0.0</td>\n      <td>7.216754</td>\n      <td>0.0</td>\n      <td>0.035870</td>\n      <td>0.140993</td>\n      <td>0.049322</td>\n      <td>0.291797</td>\n      <td>0.252069</td>\n      <td>0.010724</td>\n      <td>0.166667</td>\n      <td>0.041225</td>\n      <td>0.087966</td>\n      <td>0.014388</td>\n      <td>0.170965</td>\n      <td>0.290674</td>\n      <td>0.291028</td>\n      <td>0.184281</td>\n      <td>0.141150</td>\n      <td>0.053761</td>\n      <td>0.093935</td>\n      <td>0.157885</td>\n      <td>0.240653</td>\n      <td>0.110256</td>\n      <td>0.207604</td>\n      <td>0.298683</td>\n      <td>0.248809</td>\n      <td>0.274702</td>\n      <td>0.278924</td>\n      <td>0.117628</td>\n      <td>0.299945</td>\n      <td>0.446392</td>\n      <td>0.396639</td>\n      <td>0.230578</td>\n      <td>0.397186</td>\n      <td>0.381770</td>\n      <td>0.390235</td>\n      <td>0.439941</td>\n      <td>0.263388</td>\n      <td>0.307466</td>\n      <td>0.425217</td>\n      <td>0.490041</td>\n      <td>0.198440</td>\n      <td>0.020345</td>\n      <td>0.004796</td>\n      <td>0.066828</td>\n      <td>0.041225</td>\n      <td>0.009592</td>\n      <td>0.015166</td>\n      <td>0.006783</td>\n      <td>0.253756</td>\n      <td>0.142162</td>\n      <td>0.284290</td>\n      <td>0.124987</td>\n      <td>0.033212</td>\n      <td>0.037127</td>\n      <td>0.020345</td>\n      <td>0.032514</td>\n      <td>0.0</td>\n      <td>0.029940</td>\n      <td>0.083062</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>901.000000</td>\n      <td>-4.540000</td>\n      <td>-23.900000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>977.300000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>477.000000</td>\n      <td>9.000000</td>\n      <td>3895.000000</td>\n      <td>41.000000</td>\n      <td>-4.400000</td>\n      <td>40.600000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>110.000000</td>\n      <td>5.700000</td>\n      <td>0.0</td>\n      <td>1013.600000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>1056.000000</td>\n      <td>17.000000</td>\n      <td>7094.000000</td>\n      <td>52.520000</td>\n      <td>1.300000</td>\n      <td>63.700000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>200.000000</td>\n      <td>10.100000</td>\n      <td>0.0</td>\n      <td>1018.200000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>4079.000000</td>\n      <td>31.000000</td>\n      <td>12110.000000</td>\n      <td>63.140000</td>\n      <td>8.100000</td>\n      <td>80.600000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>270.000000</td>\n      <td>16.000000</td>\n      <td>0.0</td>\n      <td>1022.800000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>7200.000000</td>\n      <td>325.000000</td>\n      <td>68384.000000</td>\n      <td>102.560000</td>\n      <td>26.000000</td>\n      <td>100.000000</td>\n      <td>18.300000</td>\n      <td>0.0</td>\n      <td>360.000000</td>\n      <td>80.200000</td>\n      <td>0.0</td>\n      <td>1041.500000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.0</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "textData": null,
       "type": "htmlSandbox"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0055b751-6066-40db-a24b-513f14b1d673",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Use Spark UDF to process Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "efac69f2-9848-4db0-997a-c2b0ba489c2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-4120864101141667&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     38</span> <span class=\"ansi-red-fg\"># dfWeather3.show(20, truncate=False)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     39</span> \n",
       "<span class=\"ansi-green-fg\">---&gt; 40</span><span class=\"ansi-red-fg\"> </span>toParquet<span class=\"ansi-blue-fg\">(</span>dfWeather3<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">&lt;command-4120864101141633&gt;</span> in <span class=\"ansi-cyan-fg\">toParquet</span><span class=\"ansi-blue-fg\">(data_frame, bucket)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     17</span>   timestamp <span class=\"ansi-blue-fg\">=</span> datetime<span class=\"ansi-blue-fg\">.</span>datetime<span class=\"ansi-blue-fg\">.</span>utcnow<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span>tzinfo<span class=\"ansi-blue-fg\">=</span>pytz<span class=\"ansi-blue-fg\">.</span>utc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>astimezone<span class=\"ansi-blue-fg\">(</span>pytz<span class=\"ansi-blue-fg\">.</span>timezone<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;US/Pacific&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>strftime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;%Y-%m-%d-%H-%M&#39;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     18</span>   last_run_parquet_path <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">f&#39;{bucket}/{timestamp}&#39;</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 19</span><span class=\"ansi-red-fg\">   </span>data_frame<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span>last_run_parquet_path<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     20</span>   print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#39;Last run parquet path = \\&#39;{last_run_parquet_path}\\&#39;&#39;</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     21</span>   <span class=\"ansi-green-fg\">assert</span> file_exists<span class=\"ansi-blue-fg\">(</span>last_run_parquet_path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;Check output name again&#39;</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">parquet</span><span class=\"ansi-blue-fg\">(self, path, mode, partitionBy, compression)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    937</span>             self<span class=\"ansi-blue-fg\">.</span>partitionBy<span class=\"ansi-blue-fg\">(</span>partitionBy<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    938</span>         self<span class=\"ansi-blue-fg\">.</span>_set_opts<span class=\"ansi-blue-fg\">(</span>compression<span class=\"ansi-blue-fg\">=</span>compression<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 939</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    940</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    941</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.6</span><span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n",
       "<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n",
       "\n",
       "<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o577.parquet.\n",
       ": org.apache.spark.SparkException: Job aborted.\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:234)\n",
       "\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:116)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:114)\n",
       "\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:139)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:196)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:240)\n",
       "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:236)\n",
       "\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:192)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:158)\n",
       "\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:157)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:1018)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\n",
       "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:841)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n",
       "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:198)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1018)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:439)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:423)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:296)\n",
       "\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:903)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
       "\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
       "\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
       "\tat java.lang.reflect.Method.invoke(Method.java:498)\n",
       "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
       "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n",
       "\tat py4j.Gateway.invoke(Gateway.java:295)\n",
       "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
       "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
       "\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "Caused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 13 in stage 1.0 failed 4 times, most recent failure: Lost task 13.3 in stage 1.0 (TID 22, 10.207.224.17, executor 3): org.apache.spark.SparkException: Task failed while writing rows.\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:313)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:213)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$8(Executor.scala:677)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:680)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:748)\n",
       "Caused by: org.apache.spark.api.python.PythonException: &#39;IndexError: Too many levels: Index has only 1 level, not 2&#39;, from &lt;command-4120864101141672&gt;, line 14. Full traceback below:\n",
       "Traceback (most recent call last):\n",
       "  File &#34;&lt;command-4120864101141672&gt;&#34;, line 14, in weather\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 319, in __init__\n",
       "    self._resolve_point(loc.method, stations, loc.alt, loc.adapt_temp)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 277, in _resolve_point\n",
       "    data.index = data.index.droplevel(1)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in droplevel\n",
       "    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in &lt;genexpr&gt;\n",
       "    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1484, in _get_level_number\n",
       "    self._validate_index_level(level)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1476, in _validate_index_level\n",
       "    f&#34;Too many levels: Index has only 1 level, not {level + 1}&#34;\n",
       "IndexError: Too many levels: Index has only 1 level, not 2\n",
       "\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:603)\n",
       "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)\n",
       "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:556)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
       "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
       "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:732)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:291)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1615)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:300)\n",
       "\t... 10 more\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
       "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\n",
       "\tat scala.Option.foreach(Option.scala:407)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n",
       "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2333)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:203)\n",
       "\t... 34 more\n",
       "Caused by: org.apache.spark.SparkException: Task failed while writing rows.\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:313)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:213)\n",
       "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$8(Executor.scala:677)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:680)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\t... 1 more\n",
       "Caused by: org.apache.spark.api.python.PythonException: &#39;IndexError: Too many levels: Index has only 1 level, not 2&#39;, from &lt;command-4120864101141672&gt;, line 14. Full traceback below:\n",
       "Traceback (most recent call last):\n",
       "  File &#34;&lt;command-4120864101141672&gt;&#34;, line 14, in weather\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 319, in __init__\n",
       "    self._resolve_point(loc.method, stations, loc.alt, loc.adapt_temp)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 277, in _resolve_point\n",
       "    data.index = data.index.droplevel(1)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in droplevel\n",
       "    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in &lt;genexpr&gt;\n",
       "    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1484, in _get_level_number\n",
       "    self._validate_index_level(level)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1476, in _validate_index_level\n",
       "    f&#34;Too many levels: Index has only 1 level, not {level + 1}&#34;\n",
       "IndexError: Too many levels: Index has only 1 level, not 2\n",
       "\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:603)\n",
       "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)\n",
       "\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)\n",
       "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:556)\n",
       "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
       "\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
       "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n",
       "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
       "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:732)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:291)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1615)\n",
       "\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:300)\n",
       "\t... 10 more\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">Py4JJavaError</span>                             Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4120864101141667&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     38</span> <span class=\"ansi-red-fg\"># dfWeather3.show(20, truncate=False)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     39</span> \n<span class=\"ansi-green-fg\">---&gt; 40</span><span class=\"ansi-red-fg\"> </span>toParquet<span class=\"ansi-blue-fg\">(</span>dfWeather3<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">&lt;command-4120864101141633&gt;</span> in <span class=\"ansi-cyan-fg\">toParquet</span><span class=\"ansi-blue-fg\">(data_frame, bucket)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     17</span>   timestamp <span class=\"ansi-blue-fg\">=</span> datetime<span class=\"ansi-blue-fg\">.</span>datetime<span class=\"ansi-blue-fg\">.</span>utcnow<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>replace<span class=\"ansi-blue-fg\">(</span>tzinfo<span class=\"ansi-blue-fg\">=</span>pytz<span class=\"ansi-blue-fg\">.</span>utc<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>astimezone<span class=\"ansi-blue-fg\">(</span>pytz<span class=\"ansi-blue-fg\">.</span>timezone<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;US/Pacific&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>strftime<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;%Y-%m-%d-%H-%M&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     18</span>   last_run_parquet_path <span class=\"ansi-blue-fg\">=</span> <span class=\"ansi-blue-fg\">f&#39;{bucket}/{timestamp}&#39;</span>\n<span class=\"ansi-green-fg\">---&gt; 19</span><span class=\"ansi-red-fg\">   </span>data_frame<span class=\"ansi-blue-fg\">.</span>write<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span>last_run_parquet_path<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     20</span>   print<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">f&#39;Last run parquet path = \\&#39;{last_run_parquet_path}\\&#39;&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     21</span>   <span class=\"ansi-green-fg\">assert</span> file_exists<span class=\"ansi-blue-fg\">(</span>last_run_parquet_path<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">&#39;Check output name again&#39;</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/readwriter.py</span> in <span class=\"ansi-cyan-fg\">parquet</span><span class=\"ansi-blue-fg\">(self, path, mode, partitionBy, compression)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    937</span>             self<span class=\"ansi-blue-fg\">.</span>partitionBy<span class=\"ansi-blue-fg\">(</span>partitionBy<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    938</span>         self<span class=\"ansi-blue-fg\">.</span>_set_opts<span class=\"ansi-blue-fg\">(</span>compression<span class=\"ansi-blue-fg\">=</span>compression<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">--&gt; 939</span><span class=\"ansi-red-fg\">         </span>self<span class=\"ansi-blue-fg\">.</span>_jwrite<span class=\"ansi-blue-fg\">.</span>parquet<span class=\"ansi-blue-fg\">(</span>path<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    940</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    941</span>     <span class=\"ansi-blue-fg\">@</span>since<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-cyan-fg\">1.6</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    125</span>     <span class=\"ansi-green-fg\">def</span> deco<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    126</span>         <span class=\"ansi-green-fg\">try</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 127</span><span class=\"ansi-red-fg\">             </span><span class=\"ansi-green-fg\">return</span> f<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">*</span>a<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-blue-fg\">**</span>kw<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    128</span>         <span class=\"ansi-green-fg\">except</span> py4j<span class=\"ansi-blue-fg\">.</span>protocol<span class=\"ansi-blue-fg\">.</span>Py4JJavaError <span class=\"ansi-green-fg\">as</span> e<span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    129</span>             converted <span class=\"ansi-blue-fg\">=</span> convert_exception<span class=\"ansi-blue-fg\">(</span>e<span class=\"ansi-blue-fg\">.</span>java_exception<span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py</span> in <span class=\"ansi-cyan-fg\">get_return_value</span><span class=\"ansi-blue-fg\">(answer, gateway_client, target_id, name)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    326</span>                 raise Py4JJavaError(\n<span class=\"ansi-green-intense-fg ansi-bold\">    327</span>                     <span class=\"ansi-blue-fg\">&#34;An error occurred while calling {0}{1}{2}.\\n&#34;</span><span class=\"ansi-blue-fg\">.</span>\n<span class=\"ansi-green-fg\">--&gt; 328</span><span class=\"ansi-red-fg\">                     format(target_id, &#34;.&#34;, name), value)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">    329</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    330</span>                 raise Py4JError(\n\n<span class=\"ansi-red-fg\">Py4JJavaError</span>: An error occurred while calling o577.parquet.\n: org.apache.spark.SparkException: Job aborted.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:234)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:178)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:116)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:114)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:139)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:196)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:240)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:165)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:236)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:192)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:158)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:157)\n\tat org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:1018)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$5(SQLExecution.scala:116)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:248)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withCustomExecutionEnv$1(SQLExecution.scala:101)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:841)\n\tat org.apache.spark.sql.execution.SQLExecution$.withCustomExecutionEnv(SQLExecution.scala:77)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:198)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:1018)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:439)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:423)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:296)\n\tat org.apache.spark.sql.DataFrameWriter.parquet(DataFrameWriter.scala:903)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:380)\n\tat py4j.Gateway.invoke(Gateway.java:295)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:251)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.SparkException: Job aborted due to stage failure: Task 13 in stage 1.0 failed 4 times, most recent failure: Lost task 13.3 in stage 1.0 (TID 22, 10.207.224.17, executor 3): org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:313)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:213)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$8(Executor.scala:677)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:680)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: &#39;IndexError: Too many levels: Index has only 1 level, not 2&#39;, from &lt;command-4120864101141672&gt;, line 14. Full traceback below:\nTraceback (most recent call last):\n  File &#34;&lt;command-4120864101141672&gt;&#34;, line 14, in weather\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 319, in __init__\n    self._resolve_point(loc.method, stations, loc.alt, loc.adapt_temp)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 277, in _resolve_point\n    data.index = data.index.droplevel(1)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in droplevel\n    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in &lt;genexpr&gt;\n    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1484, in _get_level_number\n    self._validate_index_level(level)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1476, in _validate_index_level\n    f&#34;Too many levels: Index has only 1 level, not {level + 1}&#34;\nIndexError: Too many levels: Index has only 1 level, not 2\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:603)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:556)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:732)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:291)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1615)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:300)\n\t... 10 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2519)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2466)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2460)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2460)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1152)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1152)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2668)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2656)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:938)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2333)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:203)\n\t... 34 more\nCaused by: org.apache.spark.SparkException: Task failed while writing rows.\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:313)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$write$15(FileFormatWriter.scala:213)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:144)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:117)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$8(Executor.scala:677)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1581)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:680)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\nCaused by: org.apache.spark.api.python.PythonException: &#39;IndexError: Too many levels: Index has only 1 level, not 2&#39;, from &lt;command-4120864101141672&gt;, line 14. Full traceback below:\nTraceback (most recent call last):\n  File &#34;&lt;command-4120864101141672&gt;&#34;, line 14, in weather\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 319, in __init__\n    self._resolve_point(loc.method, stations, loc.alt, loc.adapt_temp)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 277, in _resolve_point\n    data.index = data.index.droplevel(1)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in droplevel\n    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1609, in &lt;genexpr&gt;\n    levnums = sorted(self._get_level_number(lev) for lev in level)[::-1]\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1484, in _get_level_number\n    self._validate_index_level(level)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-a3aa2911-8fee-4764-8320-2b42570cb950/lib/python3.7/site-packages/pandas/core/indexes/base.py&#34;, line 1476, in _validate_index_level\n    f&#34;Too many levels: Index has only 1 level, not {level + 1}&#34;\nIndexError: Too many levels: Index has only 1 level, not 2\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:603)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:84)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$2.read(PythonUDFRunner.scala:67)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:556)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:489)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:458)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage2.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:732)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.$anonfun$executeTask$2(FileFormatWriter.scala:291)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1615)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.executeTask(FileFormatWriter.scala:300)\n\t... 10 more\n</div>",
       "errorSummary": "org.apache.spark.SparkException: Job aborted.",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfWeather = spark.read.parquet(most_recent_parquet_path)\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "weather_schema = StructType([\n",
    "          StructField('WeatherTime', TimestampType(), False),\n",
    "          StructField('Temp', DoubleType(), False), # in F, converted from C\n",
    "          StructField('Dewpoint', DoubleType(), False), # in Celsius\n",
    "          StructField('RelHumidity', DoubleType(), False), # in %\n",
    "          StructField('Precipitation', DoubleType(), False), # in mm\n",
    "          StructField(\"Snow\", DoubleType(), False), # in mm\n",
    "          StructField(\"WindDirection\", DoubleType(), False), # in degrees\n",
    "          StructField(\"AvgWindSpeed\", DoubleType(), False), # in km/h\n",
    "          StructField(\"PeakWindGust\", DoubleType(), False), # in km/h\n",
    "          StructField(\"AirPressure\", DoubleType(), False), # avg sea-level air pressure in hPa\n",
    "          StructField(\"Sunshine\", DoubleType(), False), # one hour sunshine total in minutes\n",
    "          StructField(\"ConditionCode\", StringType(), False) # Weather condition code, HANDLE NaN - https://dev.meteostat.net/docs/formats.html#weather-condition-codes\n",
    "  ])\n",
    "\n",
    "weather_udf = udf(weather, weather_schema)\n",
    "dfWeather2 = dfWeather.withColumn(\"Weather\", weather_udf(dfWeather['StartTime'], dfWeather['LiftOffTime'], dfWeather['FromLat'], dfWeather['FromLong']))\n",
    "\n",
    "dfWeather3 = dfWeather2.withColumn('WeatherTime', dfWeather2['Weather'].getItem('WeatherTime'))\\\n",
    "      .withColumn('Temp', dfWeather2['Weather'].getItem('Temp'))\\\n",
    "      .withColumn('DewPoint', dfWeather2['Weather'].getItem('DewPoint'))\\\n",
    "      .withColumn('Relhumidity', dfWeather2['Weather'].getItem('RelHumidity'))\\\n",
    "      .withColumn('Precipitation', dfWeather2['Weather'].getItem('Precipitation'))\\\n",
    "      .withColumn('Snow', dfWeather2['Weather'].getItem('Snow'))\\\n",
    "      .withColumn('WindDirection', dfWeather2['Weather'].getItem('WindDirection'))\\\n",
    "      .withColumn('AvgWindSpeed', dfWeather2['Weather'].getItem('AvgWindSpeed'))\\\n",
    "      .withColumn('PeakWindGust', dfWeather2['Weather'].getItem('PeakWindGust'))\\\n",
    "      .withColumn('AirPressure', dfWeather2['Weather'].getItem('AirPressure'))\\\n",
    "      .withColumn('Sunshine', dfWeather2['Weather'].getItem('Sunshine'))\\\n",
    "      .withColumn('ConditionCode', dfWeather2['Weather'].getItem('ConditionCode'))\n",
    "\n",
    "\n",
    "# dfWeather3.show(20, truncate=False)\n",
    "\n",
    "toParquet(dfWeather3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f641247d-0851-4425-af30-09dce9eab4f1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "dfWeather3.where(F.col('From').isin({'SEA', 'LAX', 'SFO', 'DEN', 'DFW', 'ORD'}))\\\n",
    "          .select('From', 'To', 'StartTime', 'LiftOffTime', 'FromLat', 'FromLong', 'WeatherTime', 'Temp', 'RelHumidity', 'Precipitation', 'Snow', 'AvgWindSpeed', 'PeakWindGust', 'ConditionCode')\\\n",
    "          .show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8b8f7667-b386-4001-9156-b26e945276c8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n",
       "<span class=\"ansi-red-fg\">PythonException</span>                           Traceback (most recent call last)\n",
       "<span class=\"ansi-green-fg\">&lt;command-3846446104035318&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Convert condition codes to one-hot encoding</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">import</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">as</span> F\n",
       "<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>categ <span class=\"ansi-blue-fg\">=</span> dfWeather3<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;ConditionCode&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>distinct<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">.</span>flatMap<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>collect<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> exprs = [F.when(F.col(&#39;ConditionCode&#39;) == cat, 1).otherwise(0)\\\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>             .alias(str(cat)) for cat in categ]\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">rdd</span><span class=\"ansi-blue-fg\">(self)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     93</span>         &#34;&#34;&#34;\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     94</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>_lazy_rdd <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-fg\">---&gt; 95</span><span class=\"ansi-red-fg\">             </span>jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>javaToPython<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     96</span>             self<span class=\"ansi-blue-fg\">.</span>_lazy_rdd <span class=\"ansi-blue-fg\">=</span> RDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">,</span> BatchedSerializer<span class=\"ansi-blue-fg\">(</span>PickleSerializer<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">     97</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_lazy_rdd\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n",
       "<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n",
       "</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n",
       "<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n",
       "<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n",
       "\n",
       "<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n",
       "\n",
       "<span class=\"ansi-red-fg\">PythonException</span>: An exception was thrown from a UDF: &#39;TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of &#39;Index&#39;&#39;, from &lt;command-4120864101141672&gt;, line 14. Full traceback below:\n",
       "Traceback (most recent call last):\n",
       "  File &#34;&lt;command-4120864101141672&gt;&#34;, line 14, in weather\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 319, in __init__\n",
       "    self._resolve_point(loc.method, stations, loc.alt, loc.adapt_temp)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 270, in _resolve_point\n",
       "    pd.Grouper(level=&#39;time&#39;, freq=&#39;1H&#39;)).agg(&#39;first&#39;)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/frame.py&#34;, line 6727, in groupby\n",
       "    dropna=dropna,\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/groupby/groupby.py&#34;, line 568, in __init__\n",
       "    dropna=self.dropna,\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/groupby/grouper.py&#34;, line 719, in get_grouper\n",
       "    binner, grouper, obj = key._get_grouper(obj, validate=False)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/resample.py&#34;, line 1484, in _get_grouper\n",
       "    r = self._get_resampler(obj)\n",
       "  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/resample.py&#34;, line 1477, in _get_resampler\n",
       "    &#34;Only valid with DatetimeIndex, &#34;\n",
       "TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of &#39;Index&#39;\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">PythonException</span>                           Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-3846446104035318&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> <span class=\"ansi-red-fg\"># Convert condition codes to one-hot encoding</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      2</span> <span class=\"ansi-green-fg\">import</span> pyspark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">.</span>functions <span class=\"ansi-green-fg\">as</span> F\n<span class=\"ansi-green-fg\">----&gt; 3</span><span class=\"ansi-red-fg\"> </span>categ <span class=\"ansi-blue-fg\">=</span> dfWeather3<span class=\"ansi-blue-fg\">.</span>select<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;ConditionCode&#39;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>distinct<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>rdd<span class=\"ansi-blue-fg\">.</span>flatMap<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-green-fg\">lambda</span> x<span class=\"ansi-blue-fg\">:</span> x<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>collect<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      4</span> exprs = [F.when(F.col(&#39;ConditionCode&#39;) == cat, 1).otherwise(0)\\\n<span class=\"ansi-green-intense-fg ansi-bold\">      5</span>             .alias(str(cat)) for cat in categ]\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">rdd</span><span class=\"ansi-blue-fg\">(self)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     93</span>         &#34;&#34;&#34;\n<span class=\"ansi-green-intense-fg ansi-bold\">     94</span>         <span class=\"ansi-green-fg\">if</span> self<span class=\"ansi-blue-fg\">.</span>_lazy_rdd <span class=\"ansi-green-fg\">is</span> <span class=\"ansi-green-fg\">None</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">---&gt; 95</span><span class=\"ansi-red-fg\">             </span>jrdd <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>javaToPython<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     96</span>             self<span class=\"ansi-blue-fg\">.</span>_lazy_rdd <span class=\"ansi-blue-fg\">=</span> RDD<span class=\"ansi-blue-fg\">(</span>jrdd<span class=\"ansi-blue-fg\">,</span> self<span class=\"ansi-blue-fg\">.</span>sql_ctx<span class=\"ansi-blue-fg\">.</span>_sc<span class=\"ansi-blue-fg\">,</span> BatchedSerializer<span class=\"ansi-blue-fg\">(</span>PickleSerializer<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">     97</span>         <span class=\"ansi-green-fg\">return</span> self<span class=\"ansi-blue-fg\">.</span>_lazy_rdd\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">PythonException</span>: An exception was thrown from a UDF: &#39;TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of &#39;Index&#39;&#39;, from &lt;command-4120864101141672&gt;, line 14. Full traceback below:\nTraceback (most recent call last):\n  File &#34;&lt;command-4120864101141672&gt;&#34;, line 14, in weather\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 319, in __init__\n    self._resolve_point(loc.method, stations, loc.alt, loc.adapt_temp)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/meteostat/hourly.py&#34;, line 270, in _resolve_point\n    pd.Grouper(level=&#39;time&#39;, freq=&#39;1H&#39;)).agg(&#39;first&#39;)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/frame.py&#34;, line 6727, in groupby\n    dropna=dropna,\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/groupby/groupby.py&#34;, line 568, in __init__\n    dropna=self.dropna,\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/groupby/grouper.py&#34;, line 719, in get_grouper\n    binner, grouper, obj = key._get_grouper(obj, validate=False)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/resample.py&#34;, line 1484, in _get_grouper\n    r = self._get_resampler(obj)\n  File &#34;/local_disk0/.ephemeral_nfs/envs/pythonEnv-29912192-fa33-4d2e-9246-cf900b7f77e9/lib/python3.7/site-packages/pandas/core/resample.py&#34;, line 1477, in _get_resampler\n    &#34;Only valid with DatetimeIndex, &#34;\nTypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of &#39;Index&#39;\n</div>",
       "errorSummary": "<span class=\"ansi-red-fg\">PythonException</span>: An exception was thrown from a UDF: &#39;TypeError: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of &#39;Index&#39;&#39;, from &lt;command-4120864101141672&gt;, line 14. Full traceback below:",
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert condition codes to one-hot encoding\n",
    "import pyspark.sql.functions as F \n",
    "categ = dfWeather3.select('ConditionCode').distinct().rdd.flatMap(lambda x: x).collect()\n",
    "exprs = [F.when(F.col('ConditionCode') == cat, 1).otherwise(0)\\\n",
    "            .alias(str(cat)) for cat in categ]\n",
    "dfWeather4 = dfWeather3.select(dfWeather3.columns + exprs)\n",
    "\n",
    "dfWeather4.where(F.col('From').isin({'SEA', 'LAX', 'SFO', 'DEN', 'DFW', 'ORD'}))\\\n",
    "          .show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "9f7463c5-bbaf-4a15-82c9-5438e12461c9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Loi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "74e21088-c38e-4f77-a361-3d8cbf0fc1df",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[16]: 557701</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[16]: 557701</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfL1 = spark.read.parquet(most_recent_parquet_path)\n",
    "dfL1.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fef50e0b-8513-40d7-b296-231ba515493a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Ben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e17e55f8-45a3-45c6-996a-30b2af997b81",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">+----+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+---------+----------+---------+-----------+-----------------------+---------------+--------------+\n",
       "From|  Icao|                  Op| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|  FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|OtherDepartures|FlightDuration|\n",
       "+----+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+---------+----------+---------+-----------+-----------------------+---------------+--------------+\n",
       " ATL|A87C4F|     JetBlue Airways|BOS|2018-10-07 03:06:...|2018-10-07 11:08:...|2018-10-07 16:42:...|2018-10-07 16:43:...| 33.64777|-84.422119|42.356566| -71.011361|                  28916|              0|         19993|\n",
       " ATL|AC57F9|     Delta Air Lines|AKR|2018-10-07 00:38:...|2018-10-07 03:19:...|2018-10-07 14:35:...|2018-10-07 14:35:...|33.650608| -84.43869|  40.1912| -81.949518|                   9688|              0|         40575|\n",
       " ATL|A67CA6|     Spirit Airlines|NHK|2018-12-23 00:32:...|2018-12-23 01:34:...|2018-12-23 02:38:...|2018-12-23 13:13:...|33.633717|-84.441757|38.759033| -76.068382|                   3738|              1|          3820|\n",
       " ATL|A07341|   American Airlines|PHX|2018-12-23 00:40:...|2018-12-23 02:23:...|2018-12-23 06:13:...|2018-12-23 15:28:...|33.630718|-84.432289|33.440929|-112.008279|                   6194|              1|         13795|\n",
       " ATL|A0345F|REPUBLIC AIRLINE ...|DAY|2018-12-27 02:13:...|2018-12-27 03:04:...|2018-12-27 05:58:...|2018-12-27 16:30:...|33.647758| -84.42205| 40.16835|  -85.06665|                   3083|              0|         10447|\n",
       "+----+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+---------+----------+---------+-----------+-----------------------+---------------+--------------+\n",
       "only showing top 5 rows\n",
       "\n",
       "</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">+----+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+---------+----------+---------+-----------+-----------------------+---------------+--------------+\n|From|  Icao|                  Op| To|           StartTime|         LiftOffTime|       TouchDownTime|            StopTime|  FromLat|  FromLong|    ToLat|     ToLong|RunwayWaitTimeInSeconds|OtherDepartures|FlightDuration|\n+----+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+---------+----------+---------+-----------+-----------------------+---------------+--------------+\n| ATL|A87C4F|     JetBlue Airways|BOS|2018-10-07 03:06:...|2018-10-07 11:08:...|2018-10-07 16:42:...|2018-10-07 16:43:...| 33.64777|-84.422119|42.356566| -71.011361|                  28916|              0|         19993|\n| ATL|AC57F9|     Delta Air Lines|AKR|2018-10-07 00:38:...|2018-10-07 03:19:...|2018-10-07 14:35:...|2018-10-07 14:35:...|33.650608| -84.43869|  40.1912| -81.949518|                   9688|              0|         40575|\n| ATL|A67CA6|     Spirit Airlines|NHK|2018-12-23 00:32:...|2018-12-23 01:34:...|2018-12-23 02:38:...|2018-12-23 13:13:...|33.633717|-84.441757|38.759033| -76.068382|                   3738|              1|          3820|\n| ATL|A07341|   American Airlines|PHX|2018-12-23 00:40:...|2018-12-23 02:23:...|2018-12-23 06:13:...|2018-12-23 15:28:...|33.630718|-84.432289|33.440929|-112.008279|                   6194|              1|         13795|\n| ATL|A0345F|REPUBLIC AIRLINE ...|DAY|2018-12-27 02:13:...|2018-12-27 03:04:...|2018-12-27 05:58:...|2018-12-27 16:30:...|33.647758| -84.42205| 40.16835|  -85.06665|                   3083|              0|         10447|\n+----+------+--------------------+---+--------------------+--------------------+--------------------+--------------------+---------+----------+---------+-----------+-----------------------+---------------+--------------+\nonly showing top 5 rows\n\n</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dfB1 = spark.read.parquet(most_recent_parquet_path)\n",
    "dfB1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "fce76fa9-5ee4-48ce-9069-5091081611bd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[10]: 557701</div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\">Out[10]: 557701</div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import row_number,lit\n",
    "from pyspark.sql.window import Window\n",
    "w = Window().orderBy(lit('A'))\n",
    "dfB2 = dfB1.withColumn(\"row_num\", row_number().over(w))\n",
    "rowCount = dfB2.count()\n",
    "rowCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "da5b6344-8174-41c8-91c1-a9f73fdb6527",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainRows = int(rowCount * 0.8)\n",
    "testRows = rowCount - trainRows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df3a9f9c-203b-499d-96d0-727a1ccfd2ed",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainDf = dfB2.filter(F.col('row_num').between(0, trainRows)).select('FlightDuration', 'OtherDepartures', 'RunwayWaitTimeInSeconds')\n",
    "testDf = dfB2.filter(F.col('row_num').between(trainRows, testRows)).select('FlightDuration', 'OtherDepartures', 'RunwayWaitTimeInSeconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "37ea3856-ff73-4f1c-b922-ecad3c6bfeeb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "<div class=\"ansiout\"></div>",
       "datasetInfos": [],
       "removedWidgets": [],
       "type": "html"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s3TrainPath = 's3://<BUCKET_NAME>/flights-csv/train-data/'\n",
    "s3TestPath = 's3://<BUCKET_NAME>/flights-csv/test-data/'\n",
    "trainDf.write.format(\"csv\").save(s3TrainPath)\n",
    "testDf.write.format(\"csv\").save(s3TestPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "afa71540-8553-48f3-9973-f369e4cbc321",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Phong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d2c62a02-3f19-4074-ae20-b87768b444ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dfP1 = spark.read.parquet(most_recent_parquet_path)\n",
    "dfP1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f52d5b23-e13e-4351-8283-e55887f2ae48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookName": "Runway-Wait-Time",
   "notebookOrigID": 4120864101141618,
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
